{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_controller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = train_controller.train_controller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def analyzer(recall_at_k, node_degrees):\n",
    "    # Assuming recall_at_k is a 2D array where each row contains [node_index, recall_value]\n",
    "    # Assuming node_degrees is an array where each element is the degree of the corresponding node\n",
    "    \n",
    "    # First, let's find unique degrees\n",
    "    unique_degrees = set(node_degrees)\n",
    "    \n",
    "    # Create an empty list to store degree-recall pairs\n",
    "    degree_recall = []\n",
    "\n",
    "    # Loop through each unique degree\n",
    "    for degree in unique_degrees:\n",
    "        # Find indices of nodes with this degree\n",
    "        indices_with_degree = [i for i, deg in enumerate(node_degrees) if deg == degree]\n",
    "        \n",
    "        # Calculate average recall for nodes with this degree\n",
    "        avg_recall = np.mean([recall_at_k[i, 1] for i in indices_with_degree])\n",
    "        \n",
    "        # Append degree and average recall to the list\n",
    "        degree_recall.append((degree, avg_recall))\n",
    "\n",
    "    # Convert the list to a numpy array\n",
    "    degree_recall_array = np.array(degree_recall, dtype=[('degree', int), ('recall', float)])\n",
    "    \n",
    "    # Sort the array by degree\n",
    "    degree_recall_array = np.sort(degree_recall_array, order='degree')\n",
    "    \n",
    "    return degree_recall_array\n",
    "\n",
    "# Example data\n",
    "recall_at_k = np.array([[0, 0.1], [1, 0.5], [2, 0.3], [3, 0.7], [4, 0.9]])\n",
    "node_degrees = np.array([2, 3, 2, 1, 3])\n",
    "\n",
    "# Call the analyzer function with example data\n",
    "result = analyzer(recall_at_k, node_degrees)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def analyzer(recall_at_k, node_degrees):\n",
    "    # Assuming recall_at_k is a 2D array where each row contains [node_index, recall_value]\n",
    "    # Assuming node_degrees is an array where each element is the degree of the corresponding node\n",
    "    \n",
    "    # Find unique degrees\n",
    "    unique_degrees = np.unique(node_degrees)\n",
    "    \n",
    "    # Calculate average recalls for each unique degree using vectorized operations\n",
    "    sums = np.bincount(node_degrees, weights=recall_at_k[:, 1])\n",
    "    counts = np.bincount(node_degrees)\n",
    "    avg_recalls = sums / counts\n",
    "    \n",
    "    # Filter out NaN values (when counts is 0)\n",
    "    avg_recalls = avg_recalls[np.isfinite(avg_recalls)]\n",
    "    \n",
    "    # Stack unique_degrees and avg_recalls into a 2D array\n",
    "    degree_recall_array = np.column_stack((unique_degrees, avg_recalls))\n",
    "    \n",
    "    return degree_recall_array\n",
    "\n",
    "# Example data\n",
    "recall_at_k = np.array([[0, 0.1], [1, 0.5], [2, 0.3], [3, 0.7], [4, 0.9]])\n",
    "node_degrees = np.array([2, 3, 2, 1, 3])\n",
    "\n",
    "# Call the analyzer function with example data\n",
    "result = analyzer(recall_at_k, node_degrees)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train_controller\n",
    "\n",
    "a = train_controller.train_controller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "train loss:  414692.0\n",
      "epoch  1\n",
      "train loss:  392061.1875\n",
      "epoch  2\n",
      "train loss:  373600.125\n",
      "epoch  3\n",
      "train loss:  358476.15625\n",
      "epoch  4\n",
      "train loss:  345586.65625\n",
      "Validation Loss: 341377.875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a\u001b[39m.\u001b[39;49mtrain(epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,test_active\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/Projects/TuneUp/binA/train_controller.py:143\u001b[0m, in \u001b[0;36mtrain_controller.train\u001b[0;34m(self, model, V, data, train_edges, val_edges, optimizer, patience, epochs, test_active, save_path, save_name)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation Loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m test_active:\n\u001b[0;32m--> 143\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_transductive( z \u001b[39m=\u001b[39;49m z_train, model \u001b[39m=\u001b[39;49m model)\n\u001b[1;32m    144\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mrecall@50: \u001b[39m\u001b[39m\"\u001b[39m, res)\n\u001b[1;32m    146\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39m# Check if early stopping conditions are met\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39mif val_loss < best_val_loss:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m        break\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Projects/TuneUp/binA/train_controller.py:386\u001b[0m, in \u001b[0;36mtrain_controller.test_transductive\u001b[0;34m(self, z, model, nodes, val_edges, k, sample_ratio, neg_coef)\u001b[0m\n\u001b[1;32m    384\u001b[0m all_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([positive_scores, negative_scores])\n\u001b[1;32m    385\u001b[0m \u001b[39m# Indicate which edges are positive (1 for positive, 0 for negative)\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m positive_edge_indicator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor([\u001b[39m1\u001b[39;49m]\u001b[39m*\u001b[39;49mpositive_pairs\u001b[39m.\u001b[39;49msize(\u001b[39m1\u001b[39;49m) \u001b[39m+\u001b[39;49m [\u001b[39m0\u001b[39;49m]\u001b[39m*\u001b[39;49mnegative_pairs\u001b[39m.\u001b[39;49msize(\u001b[39m1\u001b[39;49m))\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    389\u001b[0m recall\u001b[39m=\u001b[39m calculate_recall_per_node(all_edges, all_scores, positive_edge_indicator, k,start_node)\n\u001b[1;32m    390\u001b[0m \u001b[39m# Report passed time\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "a.train(epochs=5,test_active=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TUI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
