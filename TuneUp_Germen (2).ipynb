{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rOfJ8lyD_f7l"
      },
      "source": [
        "### Pip Install Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n6zk_Iy_izf",
        "outputId": "8903abfd-1a9c-4075-f4a4-8926d77fd0d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spektral in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (1.3.0)\n",
            "Requirement already satisfied: joblib in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from spektral) (1.2.0)\n",
            "Requirement already satisfied: lxml in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from spektral) (4.9.2)\n",
            "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from spektral) (3.1)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from spektral) (1.23.5)\n",
            "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from spektral) (2.0.0)\n",
            "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from spektral) (2.28.2)\n",
            "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from spektral) (1.2.2)\n",
            "Requirement already satisfied: scipy in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from spektral) (1.10.1)\n",
            "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from spektral) (4.65.0)\n",
            "Requirement already satisfied: tensorflow-macos>=2.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from spektral) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (0.4.12)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (4.23.3)\n",
            "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (67.6.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (1.54.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (2.12.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorflow-macos>=2.5.0->spektral) (2.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from pandas->spektral) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from pandas->spektral) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from pandas->spektral) (2023.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests->spektral) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests->spektral) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests->spektral) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests->spektral) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from scikit-learn->spektral) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow-macos>=2.5.0->spektral) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from jax>=0.3.15->tensorflow-macos>=2.5.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (2.20.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-macos>=2.5.0->spektral) (3.2.2)\n",
            "Requirement already satisfied: ogb in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (1.3.6)\n",
            "Requirement already satisfied: torch>=1.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from ogb) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from ogb) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from ogb) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from ogb) (2.0.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from ogb) (1.26.15)\n",
            "Requirement already satisfied: outdated>=0.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from ogb) (0.2.2)\n",
            "Requirement already satisfied: setuptools>=44 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from outdated>=0.2.0->ogb) (67.6.1)\n",
            "Requirement already satisfied: littleutils in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from outdated>=0.2.0->ogb) (0.2.2)\n",
            "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from outdated>=0.2.0->ogb) (2.28.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from pandas>=0.24.0->ogb) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from pandas>=0.24.0->ogb) (2023.3)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from scikit-learn>=0.20.0->ogb) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (1.11.1)\n",
            "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (3.1)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch>=1.6.0->ogb) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->ogb) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests->outdated>=0.2.0->ogb) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Requirement already satisfied: torch_geometric in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (2.3.0)\n",
            "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch_geometric) (2.28.2)\n",
            "Requirement already satisfied: pyparsing in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from jinja2->torch_geometric) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/TUI/lib/python3.11/site-packages (from scikit-learn->torch_geometric) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install spektral\n",
        "! pip install ogb\n",
        "! pip install torch_geometric"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_if-SzYqHGkc"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AFd0sWJArntD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "from spektral.datasets.ogb import OGB\n",
        "from spektral.transforms import AdjToSpTensor, GCNFilter\n",
        "from ogb.nodeproppred import Evaluator, NodePropPredDataset\n",
        "\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "from itertools import product, combinations\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENUKDpqhHJWN",
        "outputId": "e7768260-7c80-4936-a66f-7925a4e21b24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x12a1ee370>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if torch.backends.mps.is_available():\n",
        "    device_name=       'mps'\n",
        "elif torch.cuda.is_available():\n",
        "    device_name= 'cuda' \n",
        "else:\n",
        "    device_name=  'cpu'\n",
        "device = torch.device(device_name)\n",
        "device = torch.device('cpu')\n",
        "train_edge_percentage = 0.5\n",
        "V_percentage = 0.95\n",
        "SEED = 42\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yQLn0tkcrntE"
      },
      "source": [
        "### Training Related Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Mke-cw8prntE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iV0jOcNYAVzV"
      },
      "source": [
        "## Dataset Related\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "X4eb8naE_mYc"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2OZPQxfI_oJ5"
      },
      "outputs": [],
      "source": [
        "# import ogbn ogbn-arxiv\n",
        "\n",
        "\n",
        "dataset_name = \"ogbn-arxiv\"\n",
        "ogb_dataset = NodePropPredDataset(dataset_name)\n",
        "dataset = OGB(ogb_dataset, transforms=[GCNFilter(), AdjToSpTensor()])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_1LBrrALs6"
      },
      "source": [
        "### Converting dataset from TF to Torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-CCwTpBEAAOQ"
      },
      "outputs": [],
      "source": [
        "# convert tf dataset to torch tensor\n",
        "\n",
        "\n",
        "\n",
        "# Get the node features, edge indices, and labels\n",
        "features = dataset[0].x\n",
        "edge_indices = dataset[0].a.indices\n",
        "labels = dataset[0].y\n",
        "\n",
        "# Convert TensorFlow tensors to PyTorch Tensors\n",
        "features_torch = torch.from_numpy(features)\n",
        "edge_indices_torch = torch.from_numpy(edge_indices.numpy().T).long()  # Transpose to fit PyG's edge_index format and convert to long\n",
        "labels_torch = torch.from_numpy(labels)\n",
        "\n",
        "# Create a PyTorch Geometric Data object\n",
        "data = Data(x=features_torch, edge_index=edge_indices_torch, y=labels_torch)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D_0S2hqTjRYc"
      },
      "source": [
        "### Applying dataset splits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bu46Zf3yjQxh"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # # # # #\n",
        "# Getting V and V_new\n",
        "# # # # # #\n",
        "\n",
        "# Assume that `data` is your PyTorch Geometric graph object.\n",
        "# data = ...\n",
        "\n",
        "# Get the number of nodes in your graph.\n",
        "num_nodes = data.num_nodes\n",
        "\n",
        "# Create a random permutation of indices [0, 1, 2, ..., num_nodes-1].\n",
        "perm = torch.randperm(num_nodes)\n",
        "\n",
        "# Calculate the index at which to split the permutation.\n",
        "split_idx = int(num_nodes * V_percentage)\n",
        "\n",
        "# Split the permutation into indices for V (95%) and V_new (5%).\n",
        "V = perm[:split_idx].to(device)\n",
        "V_new = perm[split_idx:].to(device)\n",
        "\n",
        "# V and V_new are now the indices of the nodes in the 95% and 5% splits, respectively.\n",
        "\n",
        "# ------> For node classification\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Wuhb_V5nqeMh"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# # # # # #\n",
        "# Splitting edges to training and validation edges\n",
        "# # # # # #\n",
        "\n",
        "\n",
        "\n",
        "# Assuming your data is in this format\n",
        "# data = Data(x=features_torch, edge_index=edge_indices_torch, y=labels_torch)\n",
        "\n",
        "# Get the number of edges\n",
        "num_edges = data.edge_index.size(1)\n",
        "\n",
        "# Create a list of indices representing the edges\n",
        "edge_indices = list(range(num_edges))\n",
        "\n",
        "# Shuffle the indices randomly\n",
        "random.shuffle(edge_indices)\n",
        "\n",
        "# Define the percentage of edges to be used for training\n",
        "num_train_edges = int(train_edge_percentage * num_edges)\n",
        "\n",
        "# Split the indices into two sets: for training and validation\n",
        "train_edge_indices = edge_indices[:num_train_edges]\n",
        "val_edge_indices = edge_indices[num_train_edges:]\n",
        "\n",
        "# Function to create a new edge_index tensor based on selected indices\n",
        "def create_edge_index_subset(edge_index, selected_indices):\n",
        "    return edge_index[:, selected_indices]\n",
        "\n",
        "# Create new edge_index tensors for training and validation\n",
        "E_train = create_edge_index_subset(data.edge_index, train_edge_indices)\n",
        "E_val = create_edge_index_subset(data.edge_index, val_edge_indices)\n",
        "E_all = data.edge_index.to(device)\n",
        "\n",
        "# Now, 'edge_index_train' contains the edges for the training set,\n",
        "# and 'edge_index_val' contains the edges for the validation set.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MmxBJg8YAipq"
      },
      "source": [
        "## Model Related\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0hIktgQmAr46"
      },
      "source": [
        "### Classical Backbone Model (GCN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NgPkgQAqAlq7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define a simple GNN model\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_features):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 256)\n",
        "        self.conv2 = GCNConv(256, 256)\n",
        "        self.conv3 = GCNConv(256, 256)\n",
        "\n",
        "        self.scoring = torch.nn.Sequential(\n",
        "            torch.nn.Linear(2 * 256, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, data, edge_index):\n",
        "        x = self.conv1(data.x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return x\n",
        "\n",
        "    def decode(self, z, indices):\n",
        "        start, end = indices\n",
        "        edge_features = torch.cat([z[start], z[end]], dim=1)\n",
        "        return self.scoring(edge_features).squeeze(-1)\n",
        "\n",
        "\n",
        "def bpr_loss(pos_logit, neg_logit):\n",
        "    return torch.log(F.sigmoid(pos_logit - neg_logit)).sum()\n",
        "    #return -F.logsigmoid(pos_logit - neg_logit).sum()\n",
        "    # Log in torch\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "coB84tUNBAT0"
      },
      "source": [
        "## Training, Validation Test\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ojvVNwRbBRmi"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0Kcc63SxBRAF"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def train(model,V, data, train_edges, val_edges, optimizer, patience=10, epochs = 1000, test_active = True):\n",
        "\n",
        "  # Define some initial best validation loss as infinity\n",
        "  best_val_loss = float('inf')\n",
        "  epochs_no_improve = 0\n",
        "\n",
        "  # Training loop\n",
        "  data, train_edges, val_edges = data.to(device), train_edges.to(device), val_edges.to(device)\n",
        "  for epoch in range(epochs):  # 1000 epochs\n",
        "      print(\"epoch \", epoch)\n",
        "\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      z_train = model(data, train_edges)  # embeddings for training edges\n",
        "      pos_edge_index = train_edges  # positive examples\n",
        "      neg_edge_index = negative_sampling(edge_index=pos_edge_index, num_nodes=z_train.size(0))  # negative examples\n",
        "\n",
        "      #print(\"pos_edge_index.shape: \", pos_edge_index.shape)\n",
        "      pos_logit = model.decode(z_train, pos_edge_index)\n",
        "      neg_logit = model.decode(z_train, neg_edge_index)\n",
        "\n",
        "      loss = bpr_loss(pos_logit, neg_logit)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      print(\"train loss: \", loss.item())\n",
        "\n",
        "      if test_active:\n",
        "        res = test(model, V, val_edges,z_train, 50)\n",
        "        print(\"recall@50: \", res)\n",
        "\n",
        "      # Validation:\n",
        "      if (epoch +1) % 5 == 0:\n",
        "        # validation function calls model.eval(), calculating both val loss & recall@50\n",
        "        val_loss, recall_50 = validation(model, data, val_edges, 50)\n",
        "        print(f'Validation Loss: {val_loss}, Recall@50: {recall_50}')\n",
        "\n",
        "        # Check if early stopping conditions are met\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == patience:\n",
        "                print(f'Early stopping triggered after {epoch+1} epochs.')\n",
        "                break\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BIxQmBXmBY7x"
      },
      "source": [
        "### Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cXaxPHRGBjgF"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def validation(model, nodes, val_edges, z, k=50):\n",
        "    #model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "\n",
        "        # Convert V to a boolean tensor for faster lookup.\n",
        "        v_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "        v_mask[nodes] = True\n",
        "\n",
        "        # Assume val_edges contains the validation edges (it should be a 2 x num_val_edges tensor)\n",
        "        # val_edges = ...\n",
        "\n",
        "        # Check if both nodes of each edge in val_edges are in V\n",
        "        source_nodes = val_edges[0, :]\n",
        "        target_nodes = val_edges[1, :]\n",
        "        can_exist_in_V = v_mask[source_nodes] & v_mask[target_nodes]\n",
        "\n",
        "        # Filter the edges that can exist in V\n",
        "        valid_edges_in_V = val_edges[:, can_exist_in_V]\n",
        "        positive_pairs = valid_edges_in_V\n",
        "\n",
        "        # --- Generating negative pairs ---\n",
        "\n",
        "        # Find the unique starting nodes in val_edges\n",
        "        start_nodes = torch.unique(val_edges[0, :])\n",
        "\n",
        "        # Generate all possible pairs from start_nodes to all nodes in V\n",
        "        all_possible_pairs = torch.tensor(list(product(start_nodes.tolist(), V.tolist())))\n",
        "\n",
        "        # Remove the existing edges in val_edges from all_possible_pairs to create the negative pairs\n",
        "        existing_pairs = valid_edges_in_V.t()\n",
        "        negative_pairs = []\n",
        "        for pair in all_possible_pairs:\n",
        "            if not any(torch.all(pair == existing_pair, dim=0) for existing_pair in existing_pairs):\n",
        "                negative_pairs.append(pair)\n",
        "\n",
        "        negative_pairs = torch.stack(negative_pairs).t()\n",
        "\n",
        "\n",
        "          # Negative examples for validation\n",
        "\n",
        "        pos_logit_val = model.decode(z, positive_pairs)\n",
        "        neg_logit_val = model.decode(z, negative_pairs)\n",
        "\n",
        "        val_loss = bpr_loss(pos_logit_val, neg_logit_val)\n",
        "\n",
        "    return val_loss.item()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aItXSzmQBehU"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oosXH877XuJg"
      },
      "outputs": [],
      "source": [
        "def test(model, nodes, val_edges, z, k=50):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "\n",
        "    # Take 5 samples from val_edges as positive examples\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Convert V to a boolean tensor for faster lookup.\n",
        "        v_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "        v_mask[nodes] = True\n",
        "        v_mask = v_mask.to(device)\n",
        "\n",
        "        # Assume val_edges contains the validation edges (it should be a 2 x num_val_edges tensor)\n",
        "        # val_edges = ...\n",
        "\n",
        "        # Check if both nodes of each edge in val_edges are in V\n",
        "        source_nodes = val_edges[0, :]\n",
        "        target_nodes = val_edges[1, :]\n",
        "        can_exist_in_V = v_mask[source_nodes] & v_mask[target_nodes]\n",
        "\n",
        "        # Filter the edges that can exist in V\n",
        "        valid_edges_in_V = val_edges[:, can_exist_in_V]\n",
        "        positive_pairs = valid_edges_in_V\n",
        "\n",
        "\n",
        "        # FOR MEMORY\n",
        "        positive_pairs = positive_pairs[:, torch.randint(valid_edges_in_V.size(1), (1,))]\n",
        "\n",
        "\n",
        "        # --- Generating negative pairs ---\n",
        "\n",
        "        # Find the unique starting nodes in val_edges\n",
        "        start_nodes = torch.unique(valid_edges_in_V[0, :]).to(device)\n",
        "\n",
        "        # Generate all possible pairs from start_nodes to all nodes in V\n",
        "        all_possible_pairs = torch.stack(torch.meshgrid(start_nodes, V), dim=-1).reshape(-1, 2).t().to(device)\n",
        "\n",
        "\n",
        "        # Remove the existing edges in val_edges from all_possible_pairs to create the negative pairs\n",
        "        existing_pairs = valid_edges_in_V.t()\n",
        "        existing_pairs = existing_pairs.to(device)\n",
        "\n",
        "        # Removing positive pairs that are generated accidentaly\n",
        "        negative_pairs = remove_common_edges(E_all=valid_edges_in_V,B=all_possible_pairs) # B - (A INTERSECTION B)\n",
        "\n",
        "        # Negative examples for validation\n",
        "        positive_scores = model.decode(z, positive_pairs)\n",
        "        negative_scores = model.decode(z, negative_pairs)\n",
        "\n",
        "        # Combine positive edges and negative scores\n",
        "        all_edges = torch.cat([valid_edges_in_V, negative_pairs], dim=1)\n",
        "        all_scores = torch.cat([positive_scores, negative_scores])\n",
        "        # Indicate which edges are positive (1 for positive, 0 for negative)\n",
        "        positive_edge_indicator = torch.tensor([1]*valid_edges_in_V.size(1) + [0]*negative_pairs.size(1)).to(device)\n",
        "\n",
        "\n",
        "        recall= calculate_recall_per_node(all_edges, all_scores, positive_edge_indicator, k)\n",
        "\n",
        "\n",
        "        return recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2Uiu70orntH"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Etz_l6DdBNNT"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cYraB198HlZN"
      },
      "source": [
        "### Recall calculation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OrBM-tpoBkC9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def calculate_recall_per_node(all_edges, all_scores, positive_edge_indicator, K):\n",
        "    \"\"\"\n",
        "    Calculate recall for each individual starting node using tensor operations on GPU.\n",
        "\n",
        "    Parameters:\n",
        "    - all_edges: Tensor of shape [2, num_edges], containing edges (source -> target).\n",
        "    - all_scores: Tensor of shape [num_edges], containing scores for each edge.\n",
        "    - positive_edge_indicator: Tensor of shape [num_edges], containing 1 for positive edges and 0 for negative edges.\n",
        "    - K: The number of top edges to consider for calculating recall.\n",
        "\n",
        "    Returns:\n",
        "    - recall_per_node: Dictionary with nodes as keys and recall as values.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"all_edges\")\n",
        "    print(all_edges.shape)\n",
        "\n",
        "    print(\"all_scores\")\n",
        "    print(all_scores.shape)\n",
        "\n",
        "    print(\"positive_edge_indicator\")\n",
        "    print(positive_edge_indicator.shape)\n",
        "\n",
        "\n",
        "\n",
        "    # Get unique start nodes\n",
        "    start_nodes = torch.unique(all_edges[0, :])\n",
        "\n",
        "    # Sort scores in descending order\n",
        "    sorted_indices = torch.argsort(all_scores, descending=True)\n",
        "\n",
        "    all_edges = all_edges[:, sorted_indices]\n",
        "    positive_edge_indicator = positive_edge_indicator[sorted_indices]\n",
        "\n",
        "\n",
        "    recall = 0\n",
        "    for start_node in start_nodes:\n",
        "      # Find all edges related to start_node\n",
        "      mask = all_edges[0,:] == start_node\n",
        "\n",
        "      filtered_indicators = positive_edge_indicator[mask]\n",
        "\n",
        "      positive_edge_indicator = torch.masked_select(positive_edge_indicator, torch.logical_not(mask))\n",
        "\n",
        "      recall = recall + filtered_indicators[:K].sum() / filtered_indicators.sum()\n",
        "\n",
        "    recall = recall / len(start_nodes)\n",
        "\n",
        "\n",
        "\n",
        "    # Create bins for each unique start node\n",
        "    #bins = torch.zeros_like(all_scores).scatter_(0, all_edges[0, :], 1).cumsum(0)\n",
        "\n",
        "    # Create a mask for top K elements in each bin\n",
        "    #top_k_mask = (bins <= K).gather(0, torch.argsort(bins.gather(0, sorted_indices)))\n",
        "\n",
        "    # Compute recalls by start node\n",
        "    #top_k_sorted_positive_indicators = positive_edge_indicator[sorted_indices][top_k_mask]\n",
        "    #recall = (top_k_sorted_positive_indicators.view(len(start_nodes), -1).sum(1) / K).cpu().numpy()\n",
        "\n",
        "    # Create recall_per_node dictionary\n",
        "    #recall_per_node = {node.item(): recall for node, recall in zip(start_nodes, recalls)}\n",
        "\n",
        "    return recall\n",
        "\n",
        "# Example usage remains the same\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ME7OGQAquvy7"
      },
      "source": [
        "### Find intersection, remove it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3C-qC2l-uz4A"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def remove_common_edges(E_all, B):\n",
        "    return B\n",
        "    # Compute the pairwise equality\n",
        "    pairwise_equality = torch.eq(E_all.unsqueeze(2), B.unsqueeze(1))\n",
        "\n",
        "    # Determine the columns where all rows are True (i.e., both elements in column are equal)\n",
        "    column_equality = torch.all(pairwise_equality, dim=0)\n",
        "\n",
        "    # Clear intermediate tensor\n",
        "    del pairwise_equality\n",
        "\n",
        "    # Use in-place operation to set intersection elements to 0\n",
        "    intersection = B[:, column_equality.any(dim=0)]\n",
        "    intersection[:] = 0\n",
        "\n",
        "    # Create a new tensor without intersection elements\n",
        "    B_without_intersection = B[:, ~column_equality.any(dim=0)].clone()\n",
        "\n",
        "    return B_without_intersection\n",
        "\n",
        "  # Display the intersection and B without intersection\n",
        "  #print(\"Intersection:\")\n",
        "  #print(intersection.cpu())\n",
        "  #print(\"B without intersection:\")\n",
        "  #print(B_without_intersection.cpu())\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AbVD1oCxrntH"
      },
      "source": [
        "### TuneUP: Synthesizing tail nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "co2V8MIBrntI",
        "outputId": "2fcec374-55c3-4b5e-dc1c-80ac284093d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n## USAGE:\\n\\n# percent: rate of edges to keep\\ndata_kept, data_dropped = random_edge_sampler(data, percent)\\n\\n## INPUT:\\nData(x=[169343, 128], edge_index=[2, 1335586], y=[169343, 1])\\n\\n## RETURNS:\\n(Data(edge_index=[2, 468243]), Data(edge_index=[2, 962188]))\\n\\n'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch_geometric.utils import degree\n",
        "\n",
        "def renormalize(edge_index, num_nodes):\n",
        "    # Convert to PyTorch tensor for calculation\n",
        "    edge_index = edge_index.clone().detach()\n",
        "\n",
        "    # Calculate degree and create Degree Matrix D\n",
        "    row, col = edge_index\n",
        "    deg = degree(row, num_nodes, dtype=edge_index.dtype)\n",
        "    deg_inv_sqrt = deg.pow(-0.5)\n",
        "    deg_inv_sqrt.masked_fill_(deg_inv_sqrt == float('inf'), 0)\n",
        "\n",
        "    # Renormalize\n",
        "    row, col = edge_index\n",
        "    edge_weight = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "    return edge_index, edge_weight\n",
        "\n",
        "\n",
        "def random_edge_sampler(data, percent):\n",
        "    edge_index = data.edge_index\n",
        "    num_nodes = data.num_nodes\n",
        "\n",
        "    num_edges = edge_index.size(1)\n",
        "    perm = torch.randperm(num_edges)\n",
        "    preserve_nnz = int(num_edges * percent)\n",
        "\n",
        "    # Indices for kept edges\n",
        "    kept_indices = perm[:preserve_nnz]\n",
        "    kept_edges = edge_index[:, kept_indices]\n",
        "    kept_edges, kept_weights = renormalize(kept_edges, num_nodes)\n",
        "    data_kept = Data(edge_index=kept_edges, edge_attr=kept_weights)\n",
        "\n",
        "    # Indices for dropped edges\n",
        "    dropped_indices = perm[preserve_nnz:]\n",
        "    dropped_edges = edge_index[:, dropped_indices]\n",
        "    dropped_edges, dropped_weights = renormalize(dropped_edges, num_nodes)\n",
        "    data_dropped = Data(edge_index=dropped_edges, edge_attr=dropped_weights)\n",
        "\n",
        "    return data_kept, data_dropped\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## USAGE:\n",
        "\n",
        "# percent: rate of edges to keep\n",
        "data_kept, data_dropped = random_edge_sampler(data, percent)\n",
        "\n",
        "## INPUT:\n",
        "Data(x=[169343, 128], edge_index=[2, 1335586], y=[169343, 1])\n",
        "\n",
        "## RETURNS:\n",
        "(Data(edge_index=[2, 468243]), Data(edge_index=[2, 962188]))\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x4bOCkDTrntI"
      },
      "source": [
        "# Execution\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qfv1uqEWsyrX"
      },
      "source": [
        "### To Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RrBCxZQ2syXU"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "i34DgA0KrntI",
        "outputId": "8da94dd6-a957-4193-f300-a9f6b6866f08"
      },
      "outputs": [],
      "source": [
        "model = GCN(128)\n",
        "\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "E_train = E_train.to(device)\n",
        "E_val = E_val.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.001)  # L2 regularization\n",
        "\n",
        "#train(model, V, data, train_edges=E_train, val_edges=E_val, optimizer=optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH2aqtDjrntI",
        "outputId": "ad5bbbfd-0d9e-480a-e39b-08de454a67c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([160875])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "V.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jC1XH2FwrntI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([169343])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "v_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "v_mask.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "H5RRyrpJrntI"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "169343"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ADFY2PxlrntI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import math\n",
        "# this ensures that the current MacOS version is at least 12.3+\n",
        "print(torch.backends.mps.is_available())\n",
        "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
        "print(torch.backends.mps.is_built())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ccesDB8mrntI"
      },
      "source": [
        "data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
