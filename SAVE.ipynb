{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING TEST\n",
    "\n",
    "def test(model, nodes, val_edges, z, k=50):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # add this line to set the device\n",
    "\n",
    "    # Take 5 samples from val_edges as positive examples\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # Convert V to a boolean tensor for faster lookup.\n",
    "        v_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "        v_mask[nodes] = True\n",
    "        v_mask = v_mask.to(device)\n",
    "\n",
    "        # Assume val_edges contains the validation edges (it should be a 2 x num_val_edges tensor)\n",
    "        # val_edges = ...\n",
    "\n",
    "        # Check if both nodes of each edge in val_edges are in V\n",
    "        source_nodes = val_edges[0, :]\n",
    "        target_nodes = val_edges[1, :]\n",
    "        can_exist_in_V = v_mask[source_nodes] & v_mask[target_nodes]\n",
    "\n",
    "        # Filter the edges that can exist in V\n",
    "        valid_edges_in_V = val_edges[:, can_exist_in_V]\n",
    "        positive_pairs = valid_edges_in_V\n",
    "\n",
    "\n",
    "        # FOR MEMORY\n",
    "        selected_pairs = positive_pairs[:, torch.randint(valid_edges_in_V.size(1), (1,))]\n",
    "\n",
    "\n",
    "        # --- Generating negative pairs ---\n",
    "\n",
    "        # Find the unique starting nodes in val_edges\n",
    "        start_nodes = torch.unique(selected_pairs[0, :]).to(device)\n",
    "\n",
    "        # Tour over start nodes\n",
    "\n",
    "        print(start_nodes)\n",
    "        print(\"+++++++++\")\n",
    "        # Generate all possible pairs from start_nodes to all nodes in V\n",
    "        all_possible_pairs = torch.stack(torch.meshgrid(start_nodes, V), dim=-1).reshape(-1, 2).t().to(device)\n",
    "\n",
    "\n",
    "        # Remove the existing edges in val_edges from all_possible_pairs to create the negative pairs\n",
    "        existing_pairs = positive_pairs.t()\n",
    "        existing_pairs = existing_pairs.to(device)\n",
    "\n",
    "        # Removing positive pairs that are generated accidentaly\n",
    "        negative_pairs = remove_common_edges(E_all=positive_pairs,B=all_possible_pairs) # B - (A INTERSECTION B)\n",
    "\n",
    "        # Negative examples for validation\n",
    "        positive_scores = model.decode(z, positive_pairs)\n",
    "        negative_scores = model.decode(z, negative_pairs)\n",
    "\n",
    "        # Combine positive edges and negative scores\n",
    "        all_edges = torch.cat([positive_pairs, negative_pairs], dim=1)\n",
    "        all_scores = torch.cat([positive_scores, negative_scores])\n",
    "        # Indicate which edges are positive (1 for positive, 0 for negative)\n",
    "        positive_edge_indicator = torch.tensor([1]*positive_pairs.size(1) + [0]*negative_pairs.size(1)).to(device)\n",
    "\n",
    "\n",
    "        recall= calculate_recall_per_node(all_edges, all_scores, positive_edge_indicator, k,start_nodes)\n",
    "\n",
    "\n",
    "        return recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def calculate_recall_per_node(all_edges, all_scores, positive_edge_indicator, K, start_nodes):\n",
    "    \"\"\"\n",
    "    Calculate recall for each individual starting node using tensor operations on GPU.\n",
    "\n",
    "    Parameters:\n",
    "    - all_edges: Tensor of shape [2, num_edges], containing edges (source -> target).\n",
    "    - all_scores: Tensor of shape [num_edges], containing scores for each edge.\n",
    "    - positive_edge_indicator: Tensor of shape [num_edges], containing 1 for positive edges and 0 for negative edges.\n",
    "    - K: The number of top edges to consider for calculating recall.\n",
    "\n",
    "    Returns:\n",
    "    - recall_per_node: Dictionary with nodes as keys and recall as values.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"all_edges\")\n",
    "    print(all_edges.shape)\n",
    "\n",
    "    print(\"all_scores\")\n",
    "    print(all_scores.shape)\n",
    "\n",
    "    print(\"positive_edge_indicator\")\n",
    "    print(positive_edge_indicator.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Sort scores in descending order\n",
    "    sorted_indices = torch.argsort(all_scores, descending=True)\n",
    "\n",
    "    all_edges = all_edges[:, sorted_indices]\n",
    "    positive_edge_indicator = positive_edge_indicator[sorted_indices]\n",
    "\n",
    "\n",
    "    recall = 0\n",
    "    for start_node in start_nodes:\n",
    "      # Find all edges related to start_node\n",
    "      mask = all_edges[0,:] == start_node\n",
    "\n",
    "      filtered_indicators = positive_edge_indicator[mask]\n",
    "\n",
    "      positive_edge_indicator = torch.masked_select(positive_edge_indicator, torch.logical_not(mask))\n",
    "\n",
    "      recall = recall + filtered_indicators[:K].sum() / filtered_indicators.sum()\n",
    "      print(filtered_indicators[:K].sum())\n",
    "      print(filtered_indicators.sum())\n",
    "\n",
    "    recall = recall / len(start_nodes)\n",
    "\n",
    "\n",
    "\n",
    "    # Create bins for each unique start node\n",
    "    #bins = torch.zeros_like(all_scores).scatter_(0, all_edges[0, :], 1).cumsum(0)\n",
    "\n",
    "    # Create a mask for top K elements in each bin\n",
    "    #top_k_mask = (bins <= K).gather(0, torch.argsort(bins.gather(0, sorted_indices)))\n",
    "\n",
    "    # Compute recalls by start node\n",
    "    #top_k_sorted_positive_indicators = positive_edge_indicator[sorted_indices][top_k_mask]\n",
    "    #recall = (top_k_sorted_positive_indicators.view(len(start_nodes), -1).sum(1) / K).cpu().numpy()\n",
    "\n",
    "    # Create recall_per_node dictionary\n",
    "    #recall_per_node = {node.item(): recall for node, recall in zip(start_nodes, recalls)}\n",
    "\n",
    "    return recall\n",
    "\n",
    "# Example usage remains the same\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
