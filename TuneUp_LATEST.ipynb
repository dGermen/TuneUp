{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rOfJ8lyD_f7l"
      },
      "source": [
        "### Pip Install Operations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n6zk_Iy_izf",
        "outputId": "204f4587-d634-4bfd-d13a-00d90c6f7e7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spektral\n",
            "  Downloading spektral-1.3.0-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from spektral) (1.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from spektral) (4.9.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from spektral) (3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spektral) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from spektral) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from spektral) (2.27.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from spektral) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from spektral) (1.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from spektral) (4.65.0)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from spektral) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.32.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->spektral) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->spektral) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->spektral) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2.0->spektral) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.2.0->spektral) (0.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (3.2.2)\n",
            "Installing collected packages: spektral\n",
            "Successfully installed spektral-1.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.22.4)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb) (1.26.15)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb) (2.27.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->ogb) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->ogb) (2.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7029 sha256=767bad851a73b36cae3063a5036678fedc6ed40ef11c8ece9f2c45cff23936c2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, outdated, ogb\n",
            "Successfully installed littleutils-0.2.2 ogb-1.3.6 outdated-0.2.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.27.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch_geometric\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910459 sha256=2ba52a51961df3e29d0444d6e5935a22414e60e0052f94b732fd194615d6ac28\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
            "Successfully built torch_geometric\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pdb (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pdb\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install spektral\n",
        "! pip install ogb\n",
        "! pip install torch_geometric\n",
        "! pip install pdb"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_if-SzYqHGkc"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFd0sWJArntD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "from spektral.datasets.ogb import OGB\n",
        "from spektral.transforms import AdjToSpTensor, GCNFilter\n",
        "from ogb.nodeproppred import Evaluator, NodePropPredDataset\n",
        "\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_geometric.utils import negative_sampling\n",
        "\n",
        "from itertools import product, combinations\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "import itertools\n",
        "\n",
        "import pdb\n",
        "\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENUKDpqhHJWN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train_edge_percentage = 0.5\n",
        "V_percentage = 0.95\n",
        "\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iV0jOcNYAVzV"
      },
      "source": [
        "## Dataset Related\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "D_0S2hqTjRYc"
      },
      "source": [
        "### Applying dataset splits\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OgXq4VRjLo9l"
      },
      "source": [
        "## TUNEUP"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yaVBssXkLz1s"
      },
      "source": [
        "### Overall fine-tune approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqC6SoS1MBMv"
      },
      "outputs": [],
      "source": [
        "def fine_tune(model, V, data, train_edges, val_edges, optimizer, drop_percent=0.2, patience=10, epochs = 1000, test_active = True):\n",
        "\n",
        "  # Define some initial best validation loss as infinity\n",
        "  best_val_loss = float('inf')\n",
        "  epochs_no_improve = 0\n",
        "\n",
        "  # Training loop\n",
        "  data, train_edges, val_edges = data.to(device), train_edges.to(device), val_edges.to(device)\n",
        "  for epoch in range(epochs):  # 1000 epochs\n",
        "      print(\"epoch \", epoch)\n",
        "\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Drop edges from the graph\n",
        "      data_kept, _ = random_edge_sampler(data, drop_percent)\n",
        "      kept_edges = data_kept.edge_index.to(device)  # Fetching the edge index from the kept data\n",
        "\n",
        "      z_train = model(data, kept_edges)  # embeddings for training edges\n",
        "\n",
        "\n",
        "      pos_edge_index = train_edges  # positive examples\n",
        "      neg_edge_index = negative_sampling(edge_index=pos_edge_index, num_nodes=z_train.size(0))  # negative examples\n",
        "\n",
        "      pos_logit = model.decode(z_train, pos_edge_index)\n",
        "      neg_logit = model.decode(z_train, neg_edge_index)\n",
        "\n",
        "      loss = bpr_loss(pos_logit, neg_logit)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      print(\"train loss: \", loss.item())\n",
        "\n",
        "\n",
        "\n",
        "      # Validation:\n",
        "      if (epoch +1) % 5 == 0:\n",
        "        # validation function calls model.eval(), calculating both val loss & recall@50\n",
        "        val_loss = validation(model, V, val_edges, z_train)\n",
        "        # append the val loss to the val_losses\n",
        "        val_losses.append(val_loss)\n",
        "        print(f'Validation Loss: {val_loss}')\n",
        "        if test_active:\n",
        "          res = test(model, V, val_edges,z_train, 50)\n",
        "          print(\"recall@50: \", res)\n",
        "\n",
        "        \"\"\"\n",
        "        # Check if early stopping conditions are met\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == patience:\n",
        "                print(f'Early stopping triggered after {epoch+1} epochs.')\n",
        "                break\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "      # save the model @ each 200 epochs\n",
        "      if (epoch +1) % 100 == 0:\n",
        "        save_all(model, train_losses, val_losses, epoch +1)\n",
        "\n",
        "  # save @ exit\n",
        "  save_all(model, train_losses, val_losses, epochs)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lz1IwUSMFDZ"
      },
      "source": [
        "### TUNEUP w/o syn-tails\n",
        "\n",
        "normal train + normal train again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkC0LBdrMMZd"
      },
      "outputs": [],
      "source": [
        "##########################\n",
        "##### TuneUp w/o syn-tails\n",
        "##########################\n",
        "\n",
        "def tune_up_wo_syn_tails(model,  V, data, train_edges, val_edges, optimizer, num_epochs_train, test_active_train, num_epochs_finetune, test_active_finetune):\n",
        "  # train the model\n",
        "  train(model, V, data, train_edges, val_edges, optimizer=optimizer, epochs=num_epochs_train, test_active=test_active_train)\n",
        "\n",
        "  # fine tune the model with  the same data\n",
        "  train(model, V, data, train_edges, val_edges, optimizer=optimizer, epochs=num_epochs_finetune, test_active=test_active_finetune)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2vCypBaJMO4e"
      },
      "source": [
        "### TUNEUP w/o curriculum\n",
        "\n",
        "interleave the 1st and 2nd stage preds.\n",
        "\n",
        "```\n",
        "for each epoch:\n",
        "  // 1st stage\n",
        "  Y = F(G)\n",
        "  loss  = loss(Y, Y_true)\n",
        "  loss.backprop()\n",
        "\n",
        "  // 2nd stage\n",
        "  G' <-- DropEdge(G)\n",
        "  Y = F(G')\n",
        "  loss  = loss(Y, Y_true)\n",
        "  loss.backprop()\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0Nzuy3ZMVzX"
      },
      "outputs": [],
      "source": [
        "def tune_up_wo_curriculum(model, V, data, train_edges, val_edges, optimizer, drop_percent=0.2, patience=10, epochs = 1000, test_active = True):\n",
        "\n",
        "  # Define some initial best validation loss as infinity\n",
        "  best_val_loss = float('inf')\n",
        "  epochs_no_improve = 0\n",
        "\n",
        "  # Training loop\n",
        "  data, train_edges, val_edges = data.to(device), train_edges.to(device), val_edges.to(device)\n",
        "  for epoch in range(epochs):  # 1000 epochs\n",
        "      print(\"epoch \", epoch)\n",
        "\n",
        "      model.train()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Stage 1: Train on the full graph\n",
        "      z_train_full = model(data, train_edges)  # embeddings for training edges on the full graph\n",
        "      pos_edge_index_full = train_edges  # positive examples on the full graph\n",
        "      neg_edge_index_full = negative_sampling(edge_index=pos_edge_index_full, num_nodes=z_train_full.size(0))  # negative examples\n",
        "      pos_logit_full = model.decode(z_train_full, pos_edge_index_full)\n",
        "      neg_logit_full = model.decode(z_train_full, neg_edge_index_full)\n",
        "      loss_full = bpr_loss(pos_logit_full, neg_logit_full) # calc loss\n",
        "      loss_full.backward() # backward pass\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "      # Stage 2: Drop edges and train the graph with dropped edges\n",
        "      data_kept, _ = random_edge_sampler(data, drop_percent)\n",
        "      kept_edges = data_kept.edge_index.to(device)  # Fetching the edge index from the kept data\n",
        "\n",
        "      z_train_kept = model(data, kept_edges)  # embeddings for training edges on the graph with dropped edges\n",
        "      pos_edge_index_kept = train_edges  # positive examples on the graph with dropped edges\n",
        "      neg_edge_index_kept = negative_sampling(edge_index=pos_edge_index_kept, num_nodes=z_train_full.size(0))  # negative examples\n",
        "      pos_logit_kept = model.decode(z_train_kept, pos_edge_index_kept)\n",
        "      neg_logit_kept = model.decode(z_train_kept, neg_edge_index_kept)\n",
        "      loss_kept = bpr_loss(pos_logit_kept, neg_logit_kept) # calc loss\n",
        "      loss_kept.backward() # backward pass\n",
        "      optimizer.step()\n",
        "\n",
        "      print(\"train loss: \", loss_full.item() + loss_kept.item())\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lkQatzh3MYKl"
      },
      "source": [
        "### TUNEUP (OURS)\n",
        "\n",
        "```\n",
        "// 1st stage\n",
        "for each epoch:\n",
        "  model.train()\n",
        "  Y = F(G)\n",
        "  loss  = loss(Y, Y_true)\n",
        "  loss.backprop()\n",
        "\n",
        "// 2nd stage\n",
        "for each epoch:\n",
        "  model.train()\n",
        "  G' <-- DropEdge(G)\n",
        "  Y = F(G')\n",
        "  loss  = loss(Y, Y_true)\n",
        "  loss.backprop()\n",
        "\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ2j_7RGMXsO"
      },
      "outputs": [],
      "source": [
        "def tune_up_ours(model,  V, data, train_edges, val_edges, optimizer, num_epochs_train, test_active_train, num_epochs_finetune, test_active_finetune):\n",
        "  # straightforward train\n",
        "  train(model, V, data, train_edges, val_edges, optimizer=optimizer, epochs=num_epochs_train, test_active=test_active_train)\n",
        "\n",
        "  # two-stage curriculum\n",
        "  fine_tune(model, V, data, train_edges, val_edges, optimizer=optimizer, drop_percent=0.2, patience=10, epochs = num_epochs_finetune, test_active = test_active_finetune)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# overall method for tuning up\n",
        "# takes mode = {TUNEUP, wo_syn_tails, wo_curriculum} \n",
        "def tune_up(model,  V, data, train_edges, val_edges, optimizer, num_epochs_train, test_active_train, num_epochs_finetune, test_active_finetune, mode):\n",
        "    if mode == \"TUNEUP\":\n",
        "        tune_up_ours(model,  V, data, train_edges, val_edges, optimizer, num_epochs_train, test_active_train, num_epochs_finetune, test_active_finetune)\n",
        "    if mode == \"wo_syn_tails\":\n",
        "        tune_up_wo_syn_tails(model,  V, data, train_edges, val_edges, optimizer, num_epochs_train, test_active_train, num_epochs_finetune, test_active_finetune)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Etz_l6DdBNNT"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rRCKIvAQ3B0c"
      },
      "source": [
        "### Model and loss saving"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cYraB198HlZN"
      },
      "source": [
        "### Recall calculation\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ME7OGQAquvy7"
      },
      "source": [
        "### Find intersection, remove it\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AbVD1oCxrntH"
      },
      "source": [
        "### TuneUP: Synthesizing tail nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "co2V8MIBrntI",
        "outputId": "3d87a878-f136-4693-d94a-0c0a426f4001"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n## USAGE:\\n\\n# percent: rate of edges to keep\\ndata_kept, data_dropped = random_edge_sampler(data, percent)\\n\\n## INPUT:\\nData(x=[169343, 128], edge_index=[2, 1335586], y=[169343, 1])\\n\\n## RETURNS:\\n(Data(edge_index=[2, 468243]), Data(edge_index=[2, 962188]))\\n\\n'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch_geometric.utils import degree\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "## USAGE:\n",
        "\n",
        "# percent: rate of edges to keep\n",
        "data_kept, data_dropped = random_edge_sampler(data, percent)\n",
        "\n",
        "## INPUT:\n",
        "Data(x=[169343, 128], edge_index=[2, 1335586], y=[169343, 1])\n",
        "\n",
        "## RETURNS:\n",
        "(Data(edge_index=[2, 468243]), Data(edge_index=[2, 962188]))\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x4bOCkDTrntI"
      },
      "source": [
        "# Execution\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qfv1uqEWsyrX"
      },
      "source": [
        "### To Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrBCxZQ2syXU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i34DgA0KrntI",
        "outputId": "40602242-d0c2-4bb8-d537-4275b7e50d97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch  0\n",
            "train loss:  532673.5\n",
            "epoch  1\n",
            "train loss:  488857.59375\n",
            "epoch  2\n",
            "train loss:  452074.8125\n",
            "epoch  3\n",
            "train loss:  422494.25\n",
            "epoch  4\n",
            "train loss:  400266.53125\n",
            "Validation Loss: 354749.3125\n",
            "epoch  5\n",
            "train loss:  382573.1875\n",
            "epoch  6\n",
            "train loss:  368171.3125\n",
            "epoch  7\n",
            "train loss:  355774.5\n",
            "epoch  8\n",
            "train loss:  344933.21875\n",
            "epoch  9\n",
            "train loss:  335604.9375\n",
            "Validation Loss: 303909.28125\n",
            "epoch  10\n",
            "train loss:  326827.375\n",
            "epoch  11\n",
            "train loss:  319304.71875\n",
            "epoch  12\n",
            "train loss:  311893.9375\n",
            "epoch  13\n",
            "train loss:  305553.375\n",
            "epoch  14\n",
            "train loss:  299533.5\n",
            "Validation Loss: 274728.59375\n",
            "epoch  15\n",
            "train loss:  293626.34375\n",
            "epoch  16\n",
            "train loss:  288425.09375\n",
            "epoch  17\n",
            "train loss:  283334.53125\n",
            "epoch  18\n",
            "train loss:  278404.5625\n",
            "epoch  19\n",
            "train loss:  273777.84375\n",
            "Validation Loss: 254521.234375\n",
            "epoch  20\n",
            "train loss:  269952.1875\n",
            "epoch  21\n",
            "train loss:  265963.84375\n",
            "epoch  22\n",
            "train loss:  261648.421875\n",
            "epoch  23\n",
            "train loss:  258479.34375\n",
            "epoch  24\n",
            "train loss:  254941.8125\n",
            "Validation Loss: 239385.296875\n",
            "epoch  25\n",
            "train loss:  251588.984375\n",
            "epoch  26\n",
            "train loss:  248376.046875\n",
            "epoch  27\n",
            "train loss:  245502.03125\n",
            "epoch  28\n",
            "train loss:  242675.296875\n",
            "epoch  29\n",
            "train loss:  239963.828125\n",
            "Validation Loss: 228868.75\n",
            "epoch  30\n",
            "train loss:  237791.15625\n",
            "epoch  31\n",
            "train loss:  234908.03125\n",
            "epoch  32\n",
            "train loss:  232807.53125\n",
            "epoch  33\n",
            "train loss:  231144.515625\n",
            "epoch  34\n",
            "train loss:  229172.703125\n",
            "Validation Loss: 220648.1875\n",
            "epoch  35\n",
            "train loss:  226962.578125\n",
            "epoch  36\n",
            "train loss:  225948.6875\n",
            "epoch  37\n",
            "train loss:  224452.859375\n",
            "epoch  38\n",
            "train loss:  223008.8125\n",
            "epoch  39\n",
            "train loss:  221339.796875\n",
            "Validation Loss: 215536.78125\n",
            "epoch  40\n",
            "train loss:  220392.125\n",
            "epoch  41\n",
            "train loss:  219043.5625\n",
            "epoch  42\n",
            "train loss:  217931.390625\n",
            "epoch  43\n",
            "train loss:  217374.640625\n",
            "epoch  44\n",
            "train loss:  216668.359375\n",
            "Validation Loss: 212956.34375\n",
            "epoch  45\n",
            "train loss:  216191.84375\n",
            "epoch  46\n",
            "train loss:  214614.984375\n",
            "epoch  47\n",
            "train loss:  214020.0\n",
            "epoch  48\n",
            "train loss:  213480.828125\n",
            "epoch  49\n",
            "train loss:  213583.25\n",
            "Validation Loss: 212274.21875\n",
            "epoch  50\n",
            "train loss:  212897.84375\n",
            "epoch  51\n",
            "train loss:  212213.71875\n",
            "epoch  52\n",
            "train loss:  211768.21875\n",
            "epoch  53\n",
            "train loss:  211895.640625\n",
            "epoch  54\n",
            "train loss:  211331.21875\n",
            "Validation Loss: 211464.40625\n",
            "epoch  55\n",
            "train loss:  211273.0625\n",
            "epoch  56\n",
            "train loss:  210977.5\n",
            "epoch  57\n",
            "train loss:  211807.09375\n",
            "epoch  58\n",
            "train loss:  210834.96875\n",
            "epoch  59\n",
            "train loss:  210790.4375\n",
            "Validation Loss: 211408.3125\n",
            "epoch  60\n",
            "train loss:  210426.140625\n",
            "epoch  61\n",
            "train loss:  210812.78125\n",
            "epoch  62\n",
            "train loss:  210285.46875\n",
            "epoch  63\n",
            "train loss:  210214.09375\n",
            "epoch  64\n",
            "train loss:  210519.59375\n",
            "Validation Loss: 212335.75\n",
            "epoch  65\n",
            "train loss:  209910.328125\n",
            "epoch  66\n",
            "train loss:  209332.96875\n",
            "epoch  67\n",
            "train loss:  209362.875\n",
            "epoch  68\n",
            "train loss:  210425.125\n",
            "epoch  69\n",
            "train loss:  209495.5625\n",
            "Validation Loss: 211970.65625\n",
            "epoch  70\n",
            "train loss:  208821.703125\n",
            "epoch  71\n",
            "train loss:  208088.109375\n",
            "epoch  72\n",
            "train loss:  209365.9375\n",
            "epoch  73\n",
            "train loss:  207912.484375\n",
            "epoch  74\n",
            "train loss:  208053.15625\n",
            "Validation Loss: 211874.6875\n",
            "epoch  75\n",
            "train loss:  209152.734375\n",
            "epoch  76\n",
            "train loss:  209482.8125\n",
            "epoch  77\n",
            "train loss:  208498.9375\n",
            "epoch  78\n",
            "train loss:  208661.546875\n",
            "epoch  79\n",
            "train loss:  208864.78125\n",
            "Validation Loss: 211411.75\n",
            "epoch  80\n",
            "train loss:  207611.375\n",
            "epoch  81\n",
            "train loss:  208644.953125\n",
            "epoch  82\n",
            "train loss:  208443.0625\n",
            "epoch  83\n",
            "train loss:  207685.28125\n",
            "epoch  84\n",
            "train loss:  207090.265625\n",
            "Validation Loss: 210528.625\n",
            "epoch  85\n",
            "train loss:  207639.703125\n",
            "epoch  86\n",
            "train loss:  207347.34375\n",
            "epoch  87\n",
            "train loss:  207729.9375\n",
            "epoch  88\n",
            "train loss:  207396.375\n",
            "epoch  89\n",
            "train loss:  208223.28125\n",
            "Validation Loss: 209093.59375\n",
            "epoch  90\n",
            "train loss:  206747.53125\n",
            "epoch  91\n",
            "train loss:  206366.34375\n",
            "epoch  92\n",
            "train loss:  206194.484375\n",
            "epoch  93\n",
            "train loss:  207412.875\n",
            "epoch  94\n",
            "train loss:  206853.671875\n",
            "Validation Loss: 208228.8125\n",
            "epoch  95\n",
            "train loss:  206162.125\n",
            "epoch  96\n",
            "train loss:  205962.0625\n",
            "epoch  97\n",
            "train loss:  206350.546875\n",
            "epoch  98\n",
            "train loss:  206094.34375\n",
            "epoch  99\n",
            "train loss:  207158.453125\n",
            "Validation Loss: 209857.40625\n",
            "epoch  100\n",
            "train loss:  205383.234375\n",
            "epoch  101\n",
            "train loss:  206183.03125\n",
            "epoch  102\n",
            "train loss:  205865.09375\n",
            "epoch  103\n",
            "train loss:  205551.125\n",
            "epoch  104\n",
            "train loss:  205797.75\n",
            "Validation Loss: 208497.0\n",
            "epoch  105\n",
            "train loss:  204740.328125\n",
            "epoch  106\n",
            "train loss:  205529.734375\n",
            "epoch  107\n",
            "train loss:  205998.046875\n",
            "epoch  108\n",
            "train loss:  203886.015625\n",
            "epoch  109\n",
            "train loss:  204804.59375\n",
            "Validation Loss: 207489.953125\n",
            "epoch  110\n",
            "train loss:  204690.53125\n",
            "epoch  111\n",
            "train loss:  205165.0\n",
            "epoch  112\n",
            "train loss:  204732.84375\n",
            "epoch  113\n",
            "train loss:  204065.6875\n",
            "epoch  114\n",
            "train loss:  204672.28125\n",
            "Validation Loss: 208398.625\n",
            "epoch  115\n",
            "train loss:  203723.890625\n",
            "epoch  116\n",
            "train loss:  203890.78125\n",
            "epoch  117\n",
            "train loss:  203237.25\n",
            "epoch  118\n",
            "train loss:  203641.3125\n",
            "epoch  119\n",
            "train loss:  203809.640625\n",
            "Validation Loss: 207708.921875\n",
            "epoch  120\n",
            "train loss:  204046.15625\n",
            "epoch  121\n",
            "train loss:  203448.359375\n",
            "epoch  122\n",
            "train loss:  203733.09375\n",
            "epoch  123\n",
            "train loss:  203011.84375\n",
            "epoch  124\n",
            "train loss:  203270.28125\n",
            "Validation Loss: 208065.234375\n",
            "epoch  125\n",
            "train loss:  202986.03125\n",
            "epoch  126\n",
            "train loss:  203682.53125\n",
            "epoch  127\n",
            "train loss:  202939.515625\n",
            "epoch  128\n",
            "train loss:  202948.78125\n",
            "epoch  129\n",
            "train loss:  202349.953125\n",
            "Validation Loss: 207241.5\n",
            "epoch  130\n",
            "train loss:  201738.875\n",
            "epoch  131\n",
            "train loss:  202463.0625\n",
            "epoch  132\n",
            "train loss:  203654.15625\n",
            "epoch  133\n",
            "train loss:  202650.71875\n",
            "epoch  134\n",
            "train loss:  201785.796875\n",
            "Validation Loss: 207288.65625\n",
            "epoch  135\n",
            "train loss:  202479.109375\n",
            "epoch  136\n",
            "train loss:  201262.203125\n",
            "epoch  137\n",
            "train loss:  202285.75\n",
            "epoch  138\n",
            "train loss:  201520.21875\n",
            "epoch  139\n",
            "train loss:  201888.84375\n",
            "Validation Loss: 205772.875\n",
            "epoch  140\n",
            "train loss:  201216.5625\n",
            "epoch  141\n",
            "train loss:  201348.625\n",
            "epoch  142\n",
            "train loss:  201799.34375\n",
            "epoch  143\n",
            "train loss:  201902.5\n",
            "epoch  144\n",
            "train loss:  201229.5625\n",
            "Validation Loss: 205822.75\n",
            "epoch  145\n",
            "train loss:  200484.875\n",
            "epoch  146\n",
            "train loss:  201248.71875\n",
            "epoch  147\n",
            "train loss:  200562.96875\n",
            "epoch  148\n",
            "train loss:  200441.59375\n",
            "epoch  149\n",
            "train loss:  201451.84375\n",
            "Validation Loss: 205342.53125\n",
            "epoch  150\n",
            "train loss:  200313.46875\n",
            "epoch  151\n",
            "train loss:  199531.53125\n",
            "epoch  152\n",
            "train loss:  201243.9375\n",
            "epoch  153\n",
            "train loss:  199836.9375\n",
            "epoch  154\n",
            "train loss:  199891.09375\n",
            "Validation Loss: 205471.765625\n",
            "epoch  155\n",
            "train loss:  198892.875\n",
            "epoch  156\n",
            "train loss:  199377.0\n",
            "epoch  157\n",
            "train loss:  199663.140625\n",
            "epoch  158\n",
            "train loss:  198831.21875\n",
            "epoch  159\n",
            "train loss:  199219.625\n",
            "Validation Loss: 204829.390625\n",
            "epoch  160\n",
            "train loss:  198782.625\n",
            "epoch  161\n",
            "train loss:  198968.09375\n",
            "epoch  162\n",
            "train loss:  198882.84375\n",
            "epoch  163\n",
            "train loss:  199204.0\n",
            "epoch  164\n",
            "train loss:  199870.9375\n",
            "Validation Loss: 204617.796875\n",
            "epoch  165\n",
            "train loss:  198480.09375\n",
            "epoch  166\n",
            "train loss:  198809.03125\n",
            "epoch  167\n",
            "train loss:  197596.65625\n",
            "epoch  168\n",
            "train loss:  197837.546875\n",
            "epoch  169\n",
            "train loss:  197564.9375\n",
            "Validation Loss: 204963.125\n",
            "epoch  170\n",
            "train loss:  197258.40625\n",
            "epoch  171\n",
            "train loss:  197508.71875\n",
            "epoch  172\n",
            "train loss:  197298.8125\n",
            "epoch  173\n",
            "train loss:  198387.140625\n",
            "epoch  174\n",
            "train loss:  196681.59375\n",
            "Validation Loss: 203964.578125\n",
            "epoch  175\n",
            "train loss:  197604.296875\n",
            "epoch  176\n",
            "train loss:  196464.6875\n",
            "epoch  177\n",
            "train loss:  197660.6875\n",
            "epoch  178\n",
            "train loss:  196828.046875\n",
            "epoch  179\n",
            "train loss:  196164.09375\n",
            "Validation Loss: 203531.234375\n",
            "epoch  180\n",
            "train loss:  196096.421875\n",
            "epoch  181\n",
            "train loss:  196423.375\n",
            "epoch  182\n",
            "train loss:  195539.359375\n",
            "epoch  183\n",
            "train loss:  196078.375\n",
            "epoch  184\n",
            "train loss:  195066.15625\n",
            "Validation Loss: 202886.671875\n",
            "epoch  185\n",
            "train loss:  195010.15625\n",
            "epoch  186\n",
            "train loss:  194698.90625\n",
            "epoch  187\n",
            "train loss:  195425.4375\n",
            "epoch  188\n",
            "train loss:  194589.40625\n",
            "epoch  189\n",
            "train loss:  195043.09375\n",
            "Validation Loss: 202005.765625\n",
            "epoch  190\n",
            "train loss:  194346.171875\n",
            "epoch  191\n",
            "train loss:  194818.0625\n",
            "epoch  192\n",
            "train loss:  194541.25\n",
            "epoch  193\n",
            "train loss:  194438.828125\n",
            "epoch  194\n",
            "train loss:  194478.40625\n",
            "Validation Loss: 202481.265625\n",
            "epoch  195\n",
            "train loss:  192856.46875\n",
            "epoch  196\n",
            "train loss:  193285.84375\n",
            "epoch  197\n",
            "train loss:  193323.875\n",
            "epoch  198\n",
            "train loss:  193407.578125\n",
            "epoch  199\n",
            "train loss:  193014.390625\n",
            "Validation Loss: 202057.328125\n",
            "epoch  200\n",
            "train loss:  192674.5625\n",
            "epoch  201\n",
            "train loss:  192839.0\n",
            "epoch  202\n",
            "train loss:  192913.03125\n",
            "epoch  203\n",
            "train loss:  192389.78125\n",
            "epoch  204\n",
            "train loss:  192596.671875\n",
            "Validation Loss: 201087.34375\n",
            "epoch  205\n",
            "train loss:  192178.984375\n",
            "epoch  206\n",
            "train loss:  192228.25\n",
            "epoch  207\n",
            "train loss:  191109.75\n",
            "epoch  208\n",
            "train loss:  190972.96875\n",
            "epoch  209\n",
            "train loss:  191045.0\n",
            "Validation Loss: 200014.96875\n",
            "epoch  210\n",
            "train loss:  190850.9375\n",
            "epoch  211\n",
            "train loss:  190692.078125\n",
            "epoch  212\n",
            "train loss:  190596.15625\n",
            "epoch  213\n",
            "train loss:  190589.359375\n",
            "epoch  214\n",
            "train loss:  189916.8125\n",
            "Validation Loss: 199565.6875\n",
            "epoch  215\n",
            "train loss:  189420.71875\n",
            "epoch  216\n",
            "train loss:  189620.359375\n",
            "epoch  217\n",
            "train loss:  189324.875\n",
            "epoch  218\n",
            "train loss:  188686.0625\n",
            "epoch  219\n",
            "train loss:  188457.859375\n",
            "Validation Loss: 198178.203125\n",
            "epoch  220\n",
            "train loss:  187617.671875\n",
            "epoch  221\n",
            "train loss:  188090.96875\n",
            "epoch  222\n",
            "train loss:  186812.59375\n",
            "epoch  223\n",
            "train loss:  186730.921875\n",
            "epoch  224\n",
            "train loss:  186871.09375\n",
            "Validation Loss: 198449.75\n",
            "epoch  225\n",
            "train loss:  187276.15625\n",
            "epoch  226\n",
            "train loss:  185947.265625\n",
            "epoch  227\n",
            "train loss:  185962.28125\n",
            "epoch  228\n",
            "train loss:  185410.5625\n",
            "epoch  229\n",
            "train loss:  185073.125\n",
            "Validation Loss: 197054.6875\n",
            "epoch  230\n",
            "train loss:  185217.875\n",
            "epoch  231\n",
            "train loss:  184526.6875\n",
            "epoch  232\n",
            "train loss:  184337.328125\n",
            "epoch  233\n",
            "train loss:  184115.09375\n",
            "epoch  234\n",
            "train loss:  184266.671875\n",
            "Validation Loss: 195139.125\n",
            "epoch  235\n",
            "train loss:  182995.296875\n",
            "epoch  236\n",
            "train loss:  182778.90625\n",
            "epoch  237\n",
            "train loss:  182715.015625\n",
            "epoch  238\n",
            "train loss:  182145.15625\n",
            "epoch  239\n",
            "train loss:  181958.40625\n",
            "Validation Loss: 194852.1875\n",
            "epoch  240\n",
            "train loss:  181347.984375\n",
            "epoch  241\n",
            "train loss:  181264.28125\n",
            "epoch  242\n",
            "train loss:  180383.75\n",
            "epoch  243\n",
            "train loss:  179842.46875\n",
            "epoch  244\n",
            "train loss:  179118.5625\n",
            "Validation Loss: 193893.625\n",
            "epoch  245\n",
            "train loss:  179145.15625\n",
            "epoch  246\n",
            "train loss:  178634.859375\n",
            "epoch  247\n",
            "train loss:  178895.8125\n",
            "epoch  248\n",
            "train loss:  177546.609375\n",
            "epoch  249\n",
            "train loss:  176039.984375\n",
            "Validation Loss: 191656.1875\n",
            "epoch  250\n",
            "train loss:  176821.21875\n",
            "epoch  251\n",
            "train loss:  175710.125\n",
            "epoch  252\n",
            "train loss:  175807.09375\n",
            "epoch  253\n",
            "train loss:  173762.84375\n",
            "epoch  254\n",
            "train loss:  174810.1875\n",
            "Validation Loss: 189080.875\n",
            "epoch  255\n",
            "train loss:  173633.671875\n",
            "epoch  256\n",
            "train loss:  172805.21875\n",
            "epoch  257\n",
            "train loss:  172630.59375\n",
            "epoch  258\n",
            "train loss:  171832.578125\n",
            "epoch  259\n",
            "train loss:  170645.8125\n",
            "Validation Loss: 187929.25\n",
            "epoch  260\n",
            "train loss:  170347.625\n",
            "epoch  261\n",
            "train loss:  170014.59375\n",
            "epoch  262\n",
            "train loss:  168505.46875\n",
            "epoch  263\n",
            "train loss:  168787.96875\n",
            "epoch  264\n",
            "train loss:  167014.0625\n",
            "Validation Loss: 184930.71875\n",
            "epoch  265\n",
            "train loss:  166352.1875\n",
            "epoch  266\n",
            "train loss:  166089.140625\n",
            "epoch  267\n",
            "train loss:  164529.71875\n",
            "epoch  268\n",
            "train loss:  164188.34375\n",
            "epoch  269\n",
            "train loss:  163327.875\n",
            "Validation Loss: 181750.71875\n",
            "epoch  270\n",
            "train loss:  162629.9375\n",
            "epoch  271\n",
            "train loss:  160381.09375\n",
            "epoch  272\n",
            "train loss:  159557.3125\n",
            "epoch  273\n",
            "train loss:  158911.0625\n",
            "epoch  274\n",
            "train loss:  157147.078125\n",
            "Validation Loss: 178382.21875\n",
            "epoch  275\n",
            "train loss:  156773.28125\n",
            "epoch  276\n",
            "train loss:  155594.359375\n",
            "epoch  277\n",
            "train loss:  153963.625\n",
            "epoch  278\n",
            "train loss:  152668.765625\n",
            "epoch  279\n",
            "train loss:  152155.03125\n",
            "Validation Loss: 173320.96875\n",
            "epoch  280\n",
            "train loss:  150074.828125\n",
            "epoch  281\n",
            "train loss:  149426.328125\n",
            "epoch  282\n",
            "train loss:  147602.578125\n",
            "epoch  283\n",
            "train loss:  145625.15625\n",
            "epoch  284\n",
            "train loss:  144355.484375\n",
            "Validation Loss: 168797.46875\n",
            "epoch  285\n",
            "train loss:  143399.828125\n",
            "epoch  286\n",
            "train loss:  142230.03125\n",
            "epoch  287\n",
            "train loss:  140271.6875\n",
            "epoch  288\n",
            "train loss:  137771.796875\n",
            "epoch  289\n",
            "train loss:  135846.4375\n",
            "Validation Loss: 162043.6875\n",
            "epoch  290\n",
            "train loss:  134747.6875\n",
            "epoch  291\n",
            "train loss:  133224.5625\n",
            "epoch  292\n",
            "train loss:  132208.140625\n",
            "epoch  293\n",
            "train loss:  130323.2734375\n",
            "epoch  294\n",
            "train loss:  128405.203125\n",
            "Validation Loss: 156666.3125\n",
            "epoch  295\n",
            "train loss:  126736.8984375\n",
            "epoch  296\n",
            "train loss:  125096.8203125\n",
            "epoch  297\n",
            "train loss:  123364.890625\n",
            "epoch  298\n",
            "train loss:  122672.0859375\n",
            "epoch  299\n",
            "train loss:  121006.84375\n",
            "Validation Loss: 151392.296875\n",
            "epoch  300\n",
            "train loss:  119621.3984375\n",
            "epoch  301\n",
            "train loss:  117796.1875\n",
            "epoch  302\n",
            "train loss:  117341.796875\n",
            "epoch  303\n",
            "train loss:  115858.265625\n",
            "epoch  304\n",
            "train loss:  114104.7265625\n",
            "Validation Loss: 146741.21875\n",
            "epoch  305\n",
            "train loss:  113795.96875\n",
            "epoch  306\n",
            "train loss:  112282.9609375\n",
            "epoch  307\n",
            "train loss:  111693.3203125\n",
            "epoch  308\n",
            "train loss:  110389.4921875\n",
            "epoch  309\n",
            "train loss:  109760.0625\n",
            "Validation Loss: 145811.9375\n",
            "epoch  310\n",
            "train loss:  109144.6171875\n",
            "epoch  311\n",
            "train loss:  107587.1015625\n",
            "epoch  312\n",
            "train loss:  107395.8828125\n",
            "epoch  313\n",
            "train loss:  106692.15625\n",
            "epoch  314\n",
            "train loss:  106567.515625\n",
            "Validation Loss: 144181.203125\n",
            "epoch  315\n",
            "train loss:  106448.78125\n",
            "epoch  316\n",
            "train loss:  105447.1484375\n",
            "epoch  317\n",
            "train loss:  104861.015625\n",
            "epoch  318\n",
            "train loss:  104541.8671875\n",
            "epoch  319\n",
            "train loss:  103065.9296875\n",
            "Validation Loss: 141758.109375\n",
            "epoch  320\n",
            "train loss:  102805.984375\n",
            "epoch  321\n",
            "train loss:  102483.3046875\n",
            "epoch  322\n",
            "train loss:  101717.5234375\n",
            "epoch  323\n",
            "train loss:  100716.21875\n",
            "epoch  324\n",
            "train loss:  101089.3125\n",
            "Validation Loss: 140799.15625\n",
            "epoch  325\n",
            "train loss:  100122.609375\n",
            "epoch  326\n",
            "train loss:  99986.109375\n",
            "epoch  327\n",
            "train loss:  99807.0390625\n",
            "epoch  328\n",
            "train loss:  98696.546875\n",
            "epoch  329\n",
            "train loss:  98362.78125\n",
            "Validation Loss: 138876.65625\n",
            "epoch  330\n",
            "train loss:  97747.3046875\n",
            "epoch  331\n",
            "train loss:  97192.40625\n",
            "epoch  332\n",
            "train loss:  95856.265625\n",
            "epoch  333\n",
            "train loss:  96117.4140625\n",
            "epoch  334\n",
            "train loss:  95350.15625\n",
            "Validation Loss: 135966.15625\n",
            "epoch  335\n",
            "train loss:  94406.7578125\n",
            "epoch  336\n",
            "train loss:  94176.53125\n",
            "epoch  337\n",
            "train loss:  93643.8125\n",
            "epoch  338\n",
            "train loss:  93311.625\n",
            "epoch  339\n",
            "train loss:  93387.203125\n",
            "Validation Loss: 135245.40625\n",
            "epoch  340\n",
            "train loss:  92450.21875\n",
            "epoch  341\n",
            "train loss:  92253.5234375\n",
            "epoch  342\n",
            "train loss:  91730.09375\n",
            "epoch  343\n",
            "train loss:  90664.296875\n",
            "epoch  344\n",
            "train loss:  90072.40625\n",
            "Validation Loss: 132500.03125\n",
            "epoch  345\n",
            "train loss:  89487.796875\n",
            "epoch  346\n",
            "train loss:  89019.8984375\n",
            "epoch  347\n",
            "train loss:  88370.0703125\n",
            "epoch  348\n",
            "train loss:  88571.78125\n",
            "epoch  349\n",
            "train loss:  87387.6875\n",
            "Validation Loss: 131442.140625\n",
            "epoch  350\n",
            "train loss:  87107.4140625\n",
            "epoch  351\n",
            "train loss:  86820.546875\n",
            "epoch  352\n",
            "train loss:  86626.15625\n",
            "epoch  353\n",
            "train loss:  85734.875\n",
            "epoch  354\n",
            "train loss:  85448.234375\n",
            "Validation Loss: 131597.3125\n",
            "epoch  355\n",
            "train loss:  85131.3515625\n",
            "epoch  356\n",
            "train loss:  84150.109375\n",
            "epoch  357\n",
            "train loss:  84009.1875\n",
            "epoch  358\n",
            "train loss:  83900.53125\n",
            "epoch  359\n",
            "train loss:  83314.25\n",
            "Validation Loss: 129340.859375\n",
            "epoch  360\n",
            "train loss:  82836.421875\n",
            "epoch  361\n",
            "train loss:  82303.5078125\n",
            "epoch  362\n",
            "train loss:  81589.390625\n",
            "epoch  363\n",
            "train loss:  81196.828125\n",
            "epoch  364\n",
            "train loss:  80136.7890625\n",
            "Validation Loss: 128549.2109375\n",
            "epoch  365\n",
            "train loss:  80520.921875\n",
            "epoch  366\n",
            "train loss:  79608.1640625\n",
            "epoch  367\n",
            "train loss:  79333.25\n",
            "epoch  368\n",
            "train loss:  78968.046875\n",
            "epoch  369\n",
            "train loss:  78669.359375\n",
            "Validation Loss: 127468.03125\n",
            "epoch  370\n",
            "train loss:  77543.8203125\n",
            "epoch  371\n",
            "train loss:  77788.90625\n",
            "epoch  372\n",
            "train loss:  77250.4765625\n",
            "epoch  373\n",
            "train loss:  77011.1953125\n",
            "epoch  374\n",
            "train loss:  76540.1875\n",
            "Validation Loss: 126812.890625\n",
            "epoch  375\n",
            "train loss:  76508.3828125\n",
            "epoch  376\n",
            "train loss:  75465.2578125\n",
            "epoch  377\n",
            "train loss:  75285.296875\n",
            "epoch  378\n",
            "train loss:  74743.75\n",
            "epoch  379\n",
            "train loss:  74576.328125\n",
            "Validation Loss: 126200.703125\n",
            "epoch  380\n",
            "train loss:  74068.71875\n",
            "epoch  381\n",
            "train loss:  73767.171875\n",
            "epoch  382\n",
            "train loss:  72559.7421875\n",
            "epoch  383\n",
            "train loss:  72263.171875\n",
            "epoch  384\n",
            "train loss:  72507.8125\n",
            "Validation Loss: 125896.75\n",
            "epoch  385\n",
            "train loss:  71723.328125\n",
            "epoch  386\n",
            "train loss:  71367.9609375\n",
            "epoch  387\n",
            "train loss:  70866.71875\n",
            "epoch  388\n",
            "train loss:  70464.578125\n",
            "epoch  389\n",
            "train loss:  69991.34375\n",
            "Validation Loss: 125509.84375\n",
            "epoch  390\n",
            "train loss:  69404.125\n",
            "epoch  391\n",
            "train loss:  69609.5703125\n",
            "epoch  392\n",
            "train loss:  69288.203125\n",
            "epoch  393\n",
            "train loss:  67916.234375\n",
            "epoch  394\n",
            "train loss:  67724.875\n",
            "Validation Loss: 125448.65625\n",
            "epoch  395\n",
            "train loss:  67909.203125\n",
            "epoch  396\n",
            "train loss:  67718.453125\n",
            "epoch  397\n",
            "train loss:  66611.109375\n",
            "epoch  398\n",
            "train loss:  66441.640625\n",
            "epoch  399\n",
            "train loss:  66188.15625\n",
            "Validation Loss: 125599.8984375\n",
            "epoch  400\n",
            "train loss:  66443.9296875\n",
            "epoch  401\n",
            "train loss:  65656.28125\n",
            "epoch  402\n",
            "train loss:  65312.8359375\n",
            "epoch  403\n",
            "train loss:  65040.8046875\n",
            "epoch  404\n",
            "train loss:  64500.0546875\n",
            "Validation Loss: 124944.4140625\n",
            "epoch  405\n",
            "train loss:  64771.84765625\n",
            "epoch  406\n",
            "train loss:  63732.328125\n",
            "epoch  407\n",
            "train loss:  63359.08203125\n",
            "epoch  408\n",
            "train loss:  62750.9765625\n",
            "epoch  409\n",
            "train loss:  62350.1640625\n",
            "Validation Loss: 124975.0390625\n",
            "epoch  410\n",
            "train loss:  62820.84375\n",
            "epoch  411\n",
            "train loss:  62520.2421875\n",
            "epoch  412\n",
            "train loss:  62323.0546875\n",
            "epoch  413\n",
            "train loss:  61502.8125\n",
            "epoch  414\n",
            "train loss:  61198.37890625\n",
            "Validation Loss: 124594.2265625\n",
            "epoch  415\n",
            "train loss:  61472.078125\n",
            "epoch  416\n",
            "train loss:  61043.5234375\n",
            "epoch  417\n",
            "train loss:  60893.328125\n",
            "epoch  418\n",
            "train loss:  60566.05859375\n",
            "epoch  419\n",
            "train loss:  59833.0859375\n",
            "Validation Loss: 124500.609375\n",
            "epoch  420\n",
            "train loss:  59753.09375\n",
            "epoch  421\n",
            "train loss:  59378.8359375\n",
            "epoch  422\n",
            "train loss:  58859.59765625\n",
            "epoch  423\n",
            "train loss:  58735.46875\n",
            "epoch  424\n",
            "train loss:  58543.40625\n",
            "Validation Loss: 124898.140625\n",
            "epoch  425\n",
            "train loss:  58310.3125\n",
            "epoch  426\n",
            "train loss:  58058.95703125\n",
            "epoch  427\n",
            "train loss:  57978.78515625\n",
            "epoch  428\n",
            "train loss:  57815.421875\n",
            "epoch  429\n",
            "train loss:  57381.8359375\n",
            "Validation Loss: 125461.875\n",
            "epoch  430\n",
            "train loss:  56606.21875\n",
            "epoch  431\n",
            "train loss:  56661.45703125\n",
            "epoch  432\n",
            "train loss:  56412.30078125\n",
            "epoch  433\n",
            "train loss:  56712.43359375\n",
            "epoch  434\n",
            "train loss:  55531.7734375\n",
            "Validation Loss: 125062.34375\n",
            "epoch  435\n",
            "train loss:  55750.94921875\n",
            "epoch  436\n",
            "train loss:  55748.9765625\n",
            "epoch  437\n",
            "train loss:  54860.703125\n",
            "epoch  438\n",
            "train loss:  54714.94140625\n",
            "epoch  439\n",
            "train loss:  54913.5859375\n",
            "Validation Loss: 125432.2421875\n",
            "epoch  440\n",
            "train loss:  54398.9609375\n",
            "epoch  441\n",
            "train loss:  54261.3671875\n",
            "epoch  442\n",
            "train loss:  54175.9296875\n",
            "epoch  443\n",
            "train loss:  54156.3515625\n",
            "epoch  444\n",
            "train loss:  53897.984375\n",
            "Validation Loss: 124731.53125\n",
            "epoch  445\n",
            "train loss:  53321.33203125\n",
            "epoch  446\n",
            "train loss:  52817.16015625\n",
            "epoch  447\n",
            "train loss:  52967.1484375\n",
            "epoch  448\n",
            "train loss:  52531.390625\n",
            "epoch  449\n",
            "train loss:  52451.359375\n",
            "Validation Loss: 126002.453125\n",
            "epoch  450\n",
            "train loss:  52269.24609375\n",
            "epoch  451\n",
            "train loss:  51838.375\n",
            "epoch  452\n",
            "train loss:  51690.03515625\n",
            "epoch  453\n",
            "train loss:  51769.20703125\n",
            "epoch  454\n",
            "train loss:  51619.51953125\n",
            "Validation Loss: 125890.453125\n",
            "epoch  455\n",
            "train loss:  50851.46875\n",
            "epoch  456\n",
            "train loss:  50989.65625\n",
            "epoch  457\n",
            "train loss:  51242.3515625\n",
            "epoch  458\n",
            "train loss:  50600.390625\n",
            "epoch  459\n",
            "train loss:  50709.89453125\n",
            "Validation Loss: 125293.15625\n",
            "epoch  460\n",
            "train loss:  50095.89453125\n",
            "epoch  461\n",
            "train loss:  50014.00390625\n",
            "epoch  462\n",
            "train loss:  49788.62109375\n",
            "epoch  463\n",
            "train loss:  50027.6484375\n",
            "epoch  464\n",
            "train loss:  49236.64453125\n",
            "Validation Loss: 125766.7890625\n",
            "epoch  465\n",
            "train loss:  49349.3203125\n",
            "epoch  466\n",
            "train loss:  48980.9140625\n",
            "epoch  467\n",
            "train loss:  48462.88671875\n",
            "epoch  468\n",
            "train loss:  48959.16015625\n",
            "epoch  469\n",
            "train loss:  48525.421875\n",
            "Validation Loss: 126633.953125\n",
            "epoch  470\n",
            "train loss:  48406.703125\n",
            "epoch  471\n",
            "train loss:  47499.203125\n",
            "epoch  472\n",
            "train loss:  47796.2109375\n",
            "epoch  473\n",
            "train loss:  47331.22265625\n",
            "epoch  474\n",
            "train loss:  47485.953125\n",
            "Validation Loss: 126664.9375\n",
            "epoch  475\n",
            "train loss:  47270.46484375\n",
            "epoch  476\n",
            "train loss:  47285.3671875\n",
            "epoch  477\n",
            "train loss:  46702.64453125\n",
            "epoch  478\n",
            "train loss:  47033.3046875\n",
            "epoch  479\n",
            "train loss:  46400.19140625\n",
            "Validation Loss: 126287.0703125\n",
            "epoch  480\n",
            "train loss:  46528.546875\n",
            "epoch  481\n",
            "train loss:  46219.03125\n",
            "epoch  482\n",
            "train loss:  46572.796875\n",
            "epoch  483\n",
            "train loss:  46152.796875\n",
            "epoch  484\n",
            "train loss:  45617.42578125\n",
            "Validation Loss: 126365.203125\n",
            "epoch  485\n",
            "train loss:  45681.3359375\n",
            "epoch  486\n",
            "train loss:  45399.21484375\n",
            "epoch  487\n",
            "train loss:  45288.8515625\n",
            "epoch  488\n",
            "train loss:  45349.1171875\n",
            "epoch  489\n",
            "train loss:  45197.19140625\n",
            "Validation Loss: 126068.3125\n",
            "epoch  490\n",
            "train loss:  44797.87109375\n",
            "epoch  491\n",
            "train loss:  44593.1328125\n",
            "epoch  492\n",
            "train loss:  44229.25\n",
            "epoch  493\n",
            "train loss:  44667.1875\n",
            "epoch  494\n",
            "train loss:  44512.59375\n",
            "Validation Loss: 127060.6015625\n",
            "epoch  495\n",
            "train loss:  44021.6015625\n",
            "epoch  496\n",
            "train loss:  44138.37890625\n",
            "epoch  497\n",
            "train loss:  43742.57421875\n",
            "epoch  498\n",
            "train loss:  43520.46875\n",
            "epoch  499\n",
            "train loss:  43561.72265625\n",
            "Validation Loss: 125441.8359375\n",
            "epoch  500\n",
            "train loss:  43478.0390625\n",
            "epoch  501\n",
            "train loss:  43189.61328125\n",
            "epoch  502\n",
            "train loss:  43021.6796875\n",
            "epoch  503\n",
            "train loss:  42691.98828125\n",
            "epoch  504\n",
            "train loss:  43009.89453125\n",
            "Validation Loss: 126073.6796875\n",
            "epoch  505\n",
            "train loss:  42765.5\n",
            "epoch  506\n",
            "train loss:  42865.78515625\n",
            "epoch  507\n",
            "train loss:  42777.8671875\n",
            "epoch  508\n",
            "train loss:  41786.984375\n",
            "epoch  509\n",
            "train loss:  41923.76953125\n",
            "Validation Loss: 125991.125\n",
            "epoch  510\n",
            "train loss:  41967.16015625\n",
            "epoch  511\n",
            "train loss:  41863.21484375\n",
            "epoch  512\n",
            "train loss:  41580.8359375\n",
            "epoch  513\n",
            "train loss:  41434.9921875\n",
            "epoch  514\n",
            "train loss:  41253.0703125\n",
            "Validation Loss: 125829.0\n",
            "epoch  515\n",
            "train loss:  41499.25\n",
            "epoch  516\n",
            "train loss:  40917.640625\n",
            "epoch  517\n",
            "train loss:  41007.8515625\n",
            "epoch  518\n",
            "train loss:  40695.31640625\n",
            "epoch  519\n",
            "train loss:  40803.6015625\n",
            "Validation Loss: 126272.171875\n",
            "epoch  520\n",
            "train loss:  40677.890625\n",
            "epoch  521\n",
            "train loss:  40176.0390625\n",
            "epoch  522\n",
            "train loss:  40243.1484375\n",
            "epoch  523\n",
            "train loss:  40096.07421875\n",
            "epoch  524\n",
            "train loss:  40011.671875\n",
            "Validation Loss: 126705.171875\n",
            "epoch  525\n",
            "train loss:  40006.4375\n",
            "epoch  526\n",
            "train loss:  39353.921875\n",
            "epoch  527\n",
            "train loss:  39590.3671875\n",
            "epoch  528\n",
            "train loss:  39748.8828125\n",
            "epoch  529\n",
            "train loss:  39610.02734375\n",
            "Validation Loss: 127525.109375\n",
            "epoch  530\n",
            "train loss:  39074.53125\n",
            "epoch  531\n",
            "train loss:  38966.9921875\n",
            "epoch  532\n",
            "train loss:  39434.953125\n",
            "epoch  533\n",
            "train loss:  39156.42578125\n",
            "epoch  534\n",
            "train loss:  38596.77734375\n",
            "Validation Loss: 126072.625\n",
            "epoch  535\n",
            "train loss:  38645.140625\n",
            "epoch  536\n",
            "train loss:  38518.53515625\n",
            "epoch  537\n",
            "train loss:  38314.2734375\n",
            "epoch  538\n",
            "train loss:  38176.1484375\n",
            "epoch  539\n",
            "train loss:  37901.90625\n",
            "Validation Loss: 126174.40625\n",
            "epoch  540\n",
            "train loss:  38163.8515625\n",
            "epoch  541\n",
            "train loss:  37981.1484375\n",
            "epoch  542\n",
            "train loss:  37756.87109375\n",
            "epoch  543\n",
            "train loss:  38142.234375\n",
            "epoch  544\n",
            "train loss:  37637.46875\n",
            "Validation Loss: 125605.59375\n",
            "epoch  545\n",
            "train loss:  37851.2421875\n",
            "epoch  546\n",
            "train loss:  37929.19921875\n",
            "epoch  547\n",
            "train loss:  37711.515625\n",
            "epoch  548\n",
            "train loss:  37361.265625\n",
            "epoch  549\n",
            "train loss:  36904.54296875\n",
            "Validation Loss: 126541.9453125\n",
            "epoch  550\n",
            "train loss:  37491.14453125\n",
            "epoch  551\n",
            "train loss:  36815.8203125\n",
            "epoch  552\n",
            "train loss:  37039.64453125\n",
            "epoch  553\n",
            "train loss:  36313.44921875\n",
            "epoch  554\n",
            "train loss:  36306.20703125\n",
            "Validation Loss: 126157.4609375\n",
            "epoch  555\n",
            "train loss:  36244.171875\n",
            "epoch  556\n",
            "train loss:  36416.703125\n",
            "epoch  557\n",
            "train loss:  36380.27734375\n",
            "epoch  558\n",
            "train loss:  36152.1171875\n",
            "epoch  559\n",
            "train loss:  36106.421875\n",
            "Validation Loss: 125573.890625\n",
            "epoch  560\n",
            "train loss:  36365.34375\n",
            "epoch  561\n",
            "train loss:  35776.3515625\n",
            "epoch  562\n",
            "train loss:  35945.4921875\n",
            "epoch  563\n",
            "train loss:  35847.0546875\n",
            "epoch  564\n",
            "train loss:  35385.37109375\n",
            "Validation Loss: 125539.109375\n",
            "epoch  565\n",
            "train loss:  35397.8203125\n",
            "epoch  566\n",
            "train loss:  35508.5\n",
            "epoch  567\n",
            "train loss:  35708.1953125\n",
            "epoch  568\n",
            "train loss:  35178.7890625\n",
            "epoch  569\n",
            "train loss:  34595.5\n",
            "Validation Loss: 125406.203125\n",
            "epoch  570\n",
            "train loss:  35153.671875\n",
            "epoch  571\n",
            "train loss:  34735.3671875\n",
            "epoch  572\n",
            "train loss:  35033.26953125\n",
            "epoch  573\n",
            "train loss:  34662.74609375\n",
            "epoch  574\n",
            "train loss:  34651.46875\n",
            "Validation Loss: 126136.109375\n",
            "epoch  575\n",
            "train loss:  34779.125\n",
            "epoch  576\n",
            "train loss:  34545.484375\n",
            "epoch  577\n",
            "train loss:  34682.15625\n",
            "epoch  578\n",
            "train loss:  34050.69140625\n",
            "epoch  579\n",
            "train loss:  34405.72265625\n",
            "Validation Loss: 126179.484375\n",
            "epoch  580\n",
            "train loss:  34453.2265625\n",
            "epoch  581\n",
            "train loss:  33820.33984375\n",
            "epoch  582\n",
            "train loss:  33899.12890625\n",
            "epoch  583\n",
            "train loss:  33452.65234375\n",
            "epoch  584\n",
            "train loss:  34018.40234375\n",
            "Validation Loss: 126186.8984375\n",
            "epoch  585\n",
            "train loss:  33558.63671875\n",
            "epoch  586\n",
            "train loss:  33840.65234375\n",
            "epoch  587\n",
            "train loss:  33584.94140625\n",
            "epoch  588\n",
            "train loss:  33743.34375\n",
            "epoch  589\n",
            "train loss:  33425.1953125\n",
            "Validation Loss: 125685.0703125\n",
            "epoch  590\n",
            "train loss:  33297.328125\n",
            "epoch  591\n",
            "train loss:  33341.40625\n",
            "epoch  592\n",
            "train loss:  33213.703125\n",
            "epoch  593\n",
            "train loss:  33347.56640625\n",
            "epoch  594\n",
            "train loss:  32921.1015625\n",
            "Validation Loss: 125105.328125\n",
            "epoch  595\n",
            "train loss:  33466.8125\n",
            "epoch  596\n",
            "train loss:  32955.45703125\n",
            "epoch  597\n",
            "train loss:  32949.09375\n",
            "epoch  598\n",
            "train loss:  32511.0546875\n",
            "epoch  599\n",
            "train loss:  32847.4765625\n",
            "Validation Loss: 125910.65625\n",
            "epoch  600\n",
            "train loss:  32819.5390625\n",
            "epoch  601\n",
            "train loss:  32890.5234375\n",
            "epoch  602\n",
            "train loss:  32983.37890625\n",
            "epoch  603\n",
            "train loss:  32523.48046875\n",
            "epoch  604\n",
            "train loss:  32643.05078125\n",
            "Validation Loss: 125659.734375\n",
            "epoch  605\n",
            "train loss:  32549.921875\n",
            "epoch  606\n",
            "train loss:  32061.388671875\n",
            "epoch  607\n",
            "train loss:  32503.365234375\n",
            "epoch  608\n",
            "train loss:  32174.248046875\n",
            "epoch  609\n",
            "train loss:  32142.443359375\n",
            "Validation Loss: 125467.6015625\n",
            "epoch  610\n",
            "train loss:  32120.794921875\n",
            "epoch  611\n",
            "train loss:  32154.447265625\n",
            "epoch  612\n",
            "train loss:  31891.669921875\n",
            "epoch  613\n",
            "train loss:  31953.017578125\n",
            "epoch  614\n",
            "train loss:  31968.19140625\n",
            "Validation Loss: 126111.640625\n",
            "epoch  615\n",
            "train loss:  31739.453125\n",
            "epoch  616\n",
            "train loss:  31302.62109375\n",
            "epoch  617\n",
            "train loss:  31485.2421875\n",
            "epoch  618\n",
            "train loss:  31462.330078125\n",
            "epoch  619\n",
            "train loss:  31192.724609375\n",
            "Validation Loss: 124726.625\n",
            "epoch  620\n",
            "train loss:  31492.982421875\n",
            "epoch  621\n",
            "train loss:  31524.908203125\n",
            "epoch  622\n",
            "train loss:  31400.2890625\n",
            "epoch  623\n",
            "train loss:  31240.91015625\n",
            "epoch  624\n",
            "train loss:  31468.00390625\n",
            "Validation Loss: 125731.671875\n",
            "epoch  625\n",
            "train loss:  30885.837890625\n",
            "epoch  626\n",
            "train loss:  31188.37890625\n",
            "epoch  627\n",
            "train loss:  31050.53515625\n",
            "epoch  628\n",
            "train loss:  31023.5\n",
            "epoch  629\n",
            "train loss:  31085.09765625\n",
            "Validation Loss: 127335.09375\n",
            "epoch  630\n",
            "train loss:  30910.515625\n",
            "epoch  631\n",
            "train loss:  30841.3828125\n",
            "epoch  632\n",
            "train loss:  30835.7265625\n",
            "epoch  633\n",
            "train loss:  30733.091796875\n",
            "epoch  634\n",
            "train loss:  30072.7578125\n",
            "Validation Loss: 125036.15625\n",
            "epoch  635\n",
            "train loss:  30516.140625\n",
            "epoch  636\n",
            "train loss:  30687.326171875\n",
            "epoch  637\n",
            "train loss:  30586.880859375\n",
            "epoch  638\n",
            "train loss:  30119.33203125\n",
            "epoch  639\n",
            "train loss:  30605.685546875\n",
            "Validation Loss: 125893.171875\n",
            "epoch  640\n",
            "train loss:  30040.521484375\n",
            "epoch  641\n",
            "train loss:  30105.5\n",
            "epoch  642\n",
            "train loss:  30154.546875\n",
            "epoch  643\n",
            "train loss:  30270.052734375\n",
            "epoch  644\n",
            "train loss:  30163.654296875\n",
            "Validation Loss: 126853.1328125\n",
            "epoch  645\n",
            "train loss:  30352.2890625\n",
            "epoch  646\n",
            "train loss:  29853.28515625\n",
            "epoch  647\n",
            "train loss:  29878.65234375\n",
            "epoch  648\n",
            "train loss:  29548.46484375\n",
            "epoch  649\n",
            "train loss:  29465.91796875\n",
            "Validation Loss: 125417.046875\n",
            "epoch  650\n",
            "train loss:  29511.693359375\n",
            "epoch  651\n",
            "train loss:  29894.58984375\n",
            "epoch  652\n",
            "train loss:  29287.36328125\n",
            "epoch  653\n",
            "train loss:  29645.8828125\n",
            "epoch  654\n",
            "train loss:  29418.14453125\n",
            "Validation Loss: 127046.9453125\n",
            "epoch  655\n",
            "train loss:  29445.798828125\n",
            "epoch  656\n",
            "train loss:  29721.1796875\n",
            "epoch  657\n",
            "train loss:  29334.94921875\n",
            "epoch  658\n",
            "train loss:  29273.033203125\n",
            "epoch  659\n",
            "train loss:  29599.484375\n",
            "Validation Loss: 126144.2578125\n",
            "epoch  660\n",
            "train loss:  29293.388671875\n",
            "epoch  661\n",
            "train loss:  28921.88671875\n",
            "epoch  662\n",
            "train loss:  29039.58203125\n",
            "epoch  663\n",
            "train loss:  29215.85546875\n",
            "epoch  664\n",
            "train loss:  29374.625\n",
            "Validation Loss: 126145.6796875\n",
            "epoch  665\n",
            "train loss:  28961.251953125\n",
            "epoch  666\n",
            "train loss:  29089.02734375\n",
            "epoch  667\n",
            "train loss:  28749.921875\n",
            "epoch  668\n",
            "train loss:  29147.595703125\n",
            "epoch  669\n",
            "train loss:  28699.236328125\n",
            "Validation Loss: 124659.65625\n",
            "epoch  670\n",
            "train loss:  28599.111328125\n",
            "epoch  671\n",
            "train loss:  28823.5625\n",
            "epoch  672\n",
            "train loss:  28837.015625\n",
            "epoch  673\n",
            "train loss:  28496.681640625\n",
            "epoch  674\n",
            "train loss:  28427.921875\n",
            "Validation Loss: 126436.1015625\n",
            "epoch  675\n",
            "train loss:  28534.919921875\n",
            "epoch  676\n",
            "train loss:  28474.677734375\n",
            "epoch  677\n",
            "train loss:  28614.294921875\n",
            "epoch  678\n",
            "train loss:  28596.9296875\n",
            "epoch  679\n",
            "train loss:  28500.556640625\n",
            "Validation Loss: 126093.8515625\n",
            "epoch  680\n",
            "train loss:  28409.91015625\n",
            "epoch  681\n",
            "train loss:  28362.357421875\n",
            "epoch  682\n",
            "train loss:  28718.580078125\n",
            "epoch  683\n",
            "train loss:  28257.48046875\n",
            "epoch  684\n",
            "train loss:  28369.40625\n",
            "Validation Loss: 126276.09375\n",
            "epoch  685\n",
            "train loss:  28196.00390625\n",
            "epoch  686\n",
            "train loss:  27739.833984375\n",
            "epoch  687\n",
            "train loss:  28062.953125\n",
            "epoch  688\n",
            "train loss:  28226.541015625\n",
            "epoch  689\n",
            "train loss:  27700.578125\n",
            "Validation Loss: 126919.9609375\n",
            "epoch  690\n",
            "train loss:  28100.291015625\n",
            "epoch  691\n",
            "train loss:  28106.337890625\n",
            "epoch  692\n",
            "train loss:  28250.541015625\n",
            "epoch  693\n",
            "train loss:  28329.109375\n",
            "epoch  694\n",
            "train loss:  27679.97265625\n",
            "Validation Loss: 127627.109375\n",
            "epoch  695\n",
            "train loss:  27650.794921875\n",
            "epoch  696\n",
            "train loss:  27579.1640625\n",
            "epoch  697\n",
            "train loss:  28205.234375\n",
            "epoch  698\n",
            "train loss:  27469.3046875\n",
            "epoch  699\n",
            "train loss:  28155.04296875\n",
            "Validation Loss: 126785.015625\n",
            "epoch  700\n",
            "train loss:  27741.7578125\n",
            "epoch  701\n",
            "train loss:  27759.048828125\n",
            "epoch  702\n",
            "train loss:  27371.02734375\n",
            "epoch  703\n",
            "train loss:  27365.607421875\n",
            "epoch  704\n",
            "train loss:  27236.32421875\n",
            "Validation Loss: 128044.5390625\n",
            "epoch  705\n",
            "train loss:  27431.90234375\n",
            "epoch  706\n",
            "train loss:  27602.333984375\n",
            "epoch  707\n",
            "train loss:  27286.4609375\n",
            "epoch  708\n",
            "train loss:  27362.30859375\n",
            "epoch  709\n",
            "train loss:  27430.80078125\n",
            "Validation Loss: 127206.3359375\n",
            "epoch  710\n",
            "train loss:  27254.7265625\n",
            "epoch  711\n",
            "train loss:  27399.287109375\n",
            "epoch  712\n",
            "train loss:  27090.671875\n",
            "epoch  713\n",
            "train loss:  27433.90625\n",
            "epoch  714\n",
            "train loss:  27252.2890625\n",
            "Validation Loss: 126915.6171875\n",
            "epoch  715\n",
            "train loss:  27074.03515625\n",
            "epoch  716\n",
            "train loss:  26999.5703125\n",
            "epoch  717\n",
            "train loss:  26660.77734375\n",
            "epoch  718\n",
            "train loss:  27062.921875\n",
            "epoch  719\n",
            "train loss:  27127.578125\n",
            "Validation Loss: 127607.78125\n",
            "epoch  720\n",
            "train loss:  27412.40625\n",
            "epoch  721\n",
            "train loss:  26461.978515625\n",
            "epoch  722\n",
            "train loss:  26959.43359375\n",
            "epoch  723\n",
            "train loss:  26426.42578125\n",
            "epoch  724\n",
            "train loss:  27108.359375\n",
            "Validation Loss: 128085.578125\n",
            "epoch  725\n",
            "train loss:  26864.47265625\n",
            "epoch  726\n",
            "train loss:  26617.3125\n",
            "epoch  727\n",
            "train loss:  26683.861328125\n",
            "epoch  728\n",
            "train loss:  26910.1015625\n",
            "epoch  729\n",
            "train loss:  26818.77734375\n",
            "Validation Loss: 127899.1640625\n",
            "epoch  730\n",
            "train loss:  26937.662109375\n",
            "epoch  731\n",
            "train loss:  26751.66796875\n",
            "epoch  732\n",
            "train loss:  26867.037109375\n",
            "epoch  733\n",
            "train loss:  26339.1328125\n",
            "epoch  734\n",
            "train loss:  26565.390625\n",
            "Validation Loss: 128103.7421875\n",
            "epoch  735\n",
            "train loss:  26728.134765625\n",
            "epoch  736\n",
            "train loss:  26469.841796875\n",
            "epoch  737\n",
            "train loss:  26457.87890625\n",
            "epoch  738\n",
            "train loss:  26318.15625\n",
            "epoch  739\n",
            "train loss:  26023.53515625\n",
            "Validation Loss: 129195.90625\n",
            "epoch  740\n",
            "train loss:  26147.03125\n",
            "epoch  741\n",
            "train loss:  26535.26171875\n",
            "epoch  742\n",
            "train loss:  26609.853515625\n",
            "epoch  743\n",
            "train loss:  26270.84765625\n",
            "epoch  744\n",
            "train loss:  26284.14453125\n",
            "Validation Loss: 128716.703125\n",
            "epoch  745\n",
            "train loss:  26215.244140625\n",
            "epoch  746\n",
            "train loss:  26335.080078125\n",
            "epoch  747\n",
            "train loss:  26061.876953125\n",
            "epoch  748\n",
            "train loss:  25546.01171875\n",
            "epoch  749\n",
            "train loss:  26265.47265625\n",
            "Validation Loss: 128419.546875\n",
            "epoch  750\n",
            "train loss:  26097.796875\n",
            "epoch  751\n",
            "train loss:  26079.861328125\n",
            "epoch  752\n",
            "train loss:  25683.28515625\n",
            "epoch  753\n",
            "train loss:  25992.2265625\n",
            "epoch  754\n",
            "train loss:  26293.140625\n",
            "Validation Loss: 128913.5703125\n",
            "epoch  755\n",
            "train loss:  25964.8046875\n",
            "epoch  756\n",
            "train loss:  25817.03125\n",
            "epoch  757\n",
            "train loss:  25923.140625\n",
            "epoch  758\n",
            "train loss:  26128.61328125\n",
            "epoch  759\n",
            "train loss:  26123.314453125\n",
            "Validation Loss: 129802.671875\n",
            "epoch  760\n",
            "train loss:  25724.212890625\n",
            "epoch  761\n",
            "train loss:  26216.98828125\n",
            "epoch  762\n",
            "train loss:  25689.640625\n",
            "epoch  763\n",
            "train loss:  25584.41015625\n",
            "epoch  764\n",
            "train loss:  25393.140625\n",
            "Validation Loss: 128782.796875\n",
            "epoch  765\n",
            "train loss:  25595.21875\n",
            "epoch  766\n",
            "train loss:  25558.8203125\n",
            "epoch  767\n",
            "train loss:  25960.681640625\n",
            "epoch  768\n",
            "train loss:  25978.51953125\n",
            "epoch  769\n",
            "train loss:  25261.728515625\n",
            "Validation Loss: 129445.890625\n",
            "epoch  770\n",
            "train loss:  25888.61328125\n",
            "epoch  771\n",
            "train loss:  25495.779296875\n",
            "epoch  772\n",
            "train loss:  25552.51171875\n",
            "epoch  773\n",
            "train loss:  25360.896484375\n",
            "epoch  774\n",
            "train loss:  25562.634765625\n",
            "Validation Loss: 129334.4140625\n",
            "epoch  775\n",
            "train loss:  25484.81640625\n",
            "epoch  776\n",
            "train loss:  25468.298828125\n",
            "epoch  777\n",
            "train loss:  25182.955078125\n",
            "epoch  778\n",
            "train loss:  25207.86328125\n",
            "epoch  779\n",
            "train loss:  25358.48828125\n",
            "Validation Loss: 129231.453125\n",
            "epoch  780\n",
            "train loss:  25130.5390625\n",
            "epoch  781\n",
            "train loss:  25292.716796875\n",
            "epoch  782\n",
            "train loss:  25089.23828125\n",
            "epoch  783\n",
            "train loss:  25059.140625\n",
            "epoch  784\n",
            "train loss:  24950.744140625\n",
            "Validation Loss: 129511.25\n",
            "epoch  785\n",
            "train loss:  25278.4921875\n",
            "epoch  786\n",
            "train loss:  25491.658203125\n",
            "epoch  787\n",
            "train loss:  25251.5625\n",
            "epoch  788\n",
            "train loss:  25031.0703125\n",
            "epoch  789\n",
            "train loss:  24885.044921875\n",
            "Validation Loss: 129451.578125\n",
            "epoch  790\n",
            "train loss:  25242.61328125\n",
            "epoch  791\n",
            "train loss:  25031.57421875\n",
            "epoch  792\n",
            "train loss:  24918.3671875\n",
            "epoch  793\n",
            "train loss:  25050.478515625\n",
            "epoch  794\n",
            "train loss:  25207.779296875\n",
            "Validation Loss: 129942.4765625\n",
            "epoch  795\n",
            "train loss:  24781.658203125\n",
            "epoch  796\n",
            "train loss:  24669.1640625\n",
            "epoch  797\n",
            "train loss:  24735.451171875\n",
            "epoch  798\n",
            "train loss:  24756.4765625\n",
            "epoch  799\n",
            "train loss:  24502.408203125\n",
            "Validation Loss: 130618.828125\n",
            "epoch  800\n",
            "train loss:  24654.853515625\n",
            "epoch  801\n",
            "train loss:  24914.306640625\n",
            "epoch  802\n",
            "train loss:  24572.77734375\n",
            "epoch  803\n",
            "train loss:  24644.298828125\n",
            "epoch  804\n",
            "train loss:  24474.47265625\n",
            "Validation Loss: 130710.09375\n",
            "epoch  805\n",
            "train loss:  24974.36328125\n",
            "epoch  806\n",
            "train loss:  24777.705078125\n",
            "epoch  807\n",
            "train loss:  24475.2734375\n",
            "epoch  808\n",
            "train loss:  24334.416015625\n",
            "epoch  809\n",
            "train loss:  24636.728515625\n",
            "Validation Loss: 130998.0546875\n",
            "epoch  810\n",
            "train loss:  24265.955078125\n",
            "epoch  811\n",
            "train loss:  24708.29296875\n",
            "epoch  812\n",
            "train loss:  24472.0390625\n",
            "epoch  813\n",
            "train loss:  24870.39453125\n",
            "epoch  814\n",
            "train loss:  24205.515625\n",
            "Validation Loss: 131173.203125\n",
            "epoch  815\n",
            "train loss:  24280.11328125\n",
            "epoch  816\n",
            "train loss:  24685.0\n",
            "epoch  817\n",
            "train loss:  24348.234375\n",
            "epoch  818\n",
            "train loss:  24359.998046875\n",
            "epoch  819\n",
            "train loss:  24328.671875\n",
            "Validation Loss: 130724.9609375\n",
            "epoch  820\n",
            "train loss:  23939.5625\n",
            "epoch  821\n",
            "train loss:  24431.74609375\n",
            "epoch  822\n",
            "train loss:  23903.724609375\n",
            "epoch  823\n",
            "train loss:  24121.408203125\n",
            "epoch  824\n",
            "train loss:  23842.87109375\n",
            "Validation Loss: 131875.9375\n",
            "epoch  825\n",
            "train loss:  24130.724609375\n",
            "epoch  826\n",
            "train loss:  24567.26953125\n",
            "epoch  827\n",
            "train loss:  24223.31640625\n",
            "epoch  828\n",
            "train loss:  23856.91015625\n",
            "epoch  829\n",
            "train loss:  24252.26171875\n",
            "Validation Loss: 131620.515625\n",
            "epoch  830\n",
            "train loss:  23912.552734375\n",
            "epoch  831\n",
            "train loss:  24074.05859375\n",
            "epoch  832\n",
            "train loss:  23974.2890625\n",
            "epoch  833\n",
            "train loss:  23969.7265625\n",
            "epoch  834\n",
            "train loss:  24355.677734375\n",
            "Validation Loss: 131383.84375\n",
            "epoch  835\n",
            "train loss:  23889.41796875\n",
            "epoch  836\n",
            "train loss:  23890.462890625\n",
            "epoch  837\n",
            "train loss:  24086.7578125\n",
            "epoch  838\n",
            "train loss:  24061.4453125\n",
            "epoch  839\n",
            "train loss:  23436.064453125\n",
            "Validation Loss: 129834.0390625\n",
            "epoch  840\n",
            "train loss:  24027.970703125\n",
            "epoch  841\n",
            "train loss:  24008.3671875\n",
            "epoch  842\n",
            "train loss:  23664.287109375\n",
            "epoch  843\n",
            "train loss:  23824.8359375\n",
            "epoch  844\n",
            "train loss:  23586.265625\n",
            "Validation Loss: 131087.5\n",
            "epoch  845\n",
            "train loss:  23642.90234375\n",
            "epoch  846\n",
            "train loss:  23732.75\n",
            "epoch  847\n",
            "train loss:  23863.826171875\n",
            "epoch  848\n",
            "train loss:  23874.96875\n",
            "epoch  849\n",
            "train loss:  23045.57421875\n",
            "Validation Loss: 132743.71875\n",
            "epoch  850\n",
            "train loss:  23276.95703125\n",
            "epoch  851\n",
            "train loss:  23562.52734375\n",
            "epoch  852\n",
            "train loss:  23489.49609375\n",
            "epoch  853\n",
            "train loss:  23453.13671875\n",
            "epoch  854\n",
            "train loss:  23156.7421875\n",
            "Validation Loss: 131840.5\n",
            "epoch  855\n",
            "train loss:  23744.55078125\n",
            "epoch  856\n",
            "train loss:  23684.51171875\n",
            "epoch  857\n",
            "train loss:  23454.06640625\n",
            "epoch  858\n",
            "train loss:  23532.1015625\n",
            "epoch  859\n",
            "train loss:  23510.72265625\n",
            "Validation Loss: 132388.1875\n",
            "epoch  860\n",
            "train loss:  23232.787109375\n",
            "epoch  861\n",
            "train loss:  23739.6953125\n",
            "epoch  862\n",
            "train loss:  23470.0546875\n",
            "epoch  863\n",
            "train loss:  23457.486328125\n",
            "epoch  864\n",
            "train loss:  23297.6640625\n",
            "Validation Loss: 132569.734375\n",
            "epoch  865\n",
            "train loss:  23156.19921875\n",
            "epoch  866\n",
            "train loss:  23365.12109375\n",
            "epoch  867\n",
            "train loss:  23278.87109375\n",
            "epoch  868\n",
            "train loss:  23141.70703125\n",
            "epoch  869\n",
            "train loss:  23617.8203125\n",
            "Validation Loss: 132263.40625\n",
            "epoch  870\n",
            "train loss:  23437.328125\n",
            "epoch  871\n",
            "train loss:  22912.017578125\n",
            "epoch  872\n",
            "train loss:  23248.80078125\n",
            "epoch  873\n",
            "train loss:  23246.4375\n",
            "epoch  874\n",
            "train loss:  22880.439453125\n",
            "Validation Loss: 133378.125\n",
            "epoch  875\n",
            "train loss:  23281.99609375\n",
            "epoch  876\n",
            "train loss:  22903.10546875\n",
            "epoch  877\n",
            "train loss:  23195.91796875\n",
            "epoch  878\n",
            "train loss:  22933.23828125\n",
            "epoch  879\n",
            "train loss:  23356.68359375\n",
            "Validation Loss: 132292.625\n",
            "epoch  880\n",
            "train loss:  22842.0234375\n",
            "epoch  881\n",
            "train loss:  22974.046875\n",
            "epoch  882\n",
            "train loss:  23087.5625\n",
            "epoch  883\n",
            "train loss:  23368.0625\n",
            "epoch  884\n",
            "train loss:  23509.974609375\n",
            "Validation Loss: 133347.015625\n",
            "epoch  885\n",
            "train loss:  22941.24609375\n",
            "epoch  886\n",
            "train loss:  22825.044921875\n",
            "epoch  887\n",
            "train loss:  22875.5234375\n",
            "epoch  888\n",
            "train loss:  22957.796875\n",
            "epoch  889\n",
            "train loss:  22951.71484375\n",
            "Validation Loss: 133630.84375\n",
            "epoch  890\n",
            "train loss:  23059.669921875\n",
            "epoch  891\n",
            "train loss:  22845.236328125\n",
            "epoch  892\n",
            "train loss:  22991.5859375\n",
            "epoch  893\n",
            "train loss:  22658.41015625\n",
            "epoch  894\n",
            "train loss:  22897.828125\n",
            "Validation Loss: 133054.46875\n",
            "epoch  895\n",
            "train loss:  22803.84375\n",
            "epoch  896\n",
            "train loss:  22779.3515625\n",
            "epoch  897\n",
            "train loss:  22567.095703125\n",
            "epoch  898\n",
            "train loss:  22580.37890625\n",
            "epoch  899\n",
            "train loss:  22492.41796875\n",
            "Validation Loss: 133250.0\n",
            "epoch  900\n",
            "train loss:  22681.998046875\n",
            "epoch  901\n",
            "train loss:  22745.56640625\n",
            "epoch  902\n",
            "train loss:  22582.37890625\n",
            "epoch  903\n",
            "train loss:  22605.33203125\n",
            "epoch  904\n",
            "train loss:  22758.66796875\n",
            "Validation Loss: 133951.9375\n",
            "epoch  905\n",
            "train loss:  22690.1171875\n",
            "epoch  906\n",
            "train loss:  22563.46875\n",
            "epoch  907\n",
            "train loss:  22672.83984375\n",
            "epoch  908\n",
            "train loss:  22235.5390625\n",
            "epoch  909\n",
            "train loss:  22543.775390625\n",
            "Validation Loss: 133432.8125\n",
            "epoch  910\n",
            "train loss:  22419.59375\n",
            "epoch  911\n",
            "train loss:  22711.23046875\n",
            "epoch  912\n",
            "train loss:  22314.2109375\n",
            "epoch  913\n",
            "train loss:  22291.28515625\n",
            "epoch  914\n",
            "train loss:  22385.3984375\n",
            "Validation Loss: 134560.796875\n",
            "epoch  915\n",
            "train loss:  22227.5703125\n",
            "epoch  916\n",
            "train loss:  22270.154296875\n",
            "epoch  917\n",
            "train loss:  22199.923828125\n",
            "epoch  918\n",
            "train loss:  22013.44921875\n",
            "epoch  919\n",
            "train loss:  22188.96875\n",
            "Validation Loss: 134065.609375\n",
            "epoch  920\n",
            "train loss:  22324.21484375\n",
            "epoch  921\n",
            "train loss:  22305.09375\n",
            "epoch  922\n",
            "train loss:  22404.234375\n",
            "epoch  923\n",
            "train loss:  22478.5625\n",
            "epoch  924\n",
            "train loss:  22274.83984375\n",
            "Validation Loss: 135197.078125\n",
            "epoch  925\n",
            "train loss:  22445.2265625\n",
            "epoch  926\n",
            "train loss:  22126.60546875\n",
            "epoch  927\n",
            "train loss:  22365.658203125\n",
            "epoch  928\n",
            "train loss:  22142.162109375\n",
            "epoch  929\n",
            "train loss:  22373.70703125\n",
            "Validation Loss: 135643.125\n",
            "epoch  930\n",
            "train loss:  22370.927734375\n",
            "epoch  931\n",
            "train loss:  22030.310546875\n",
            "epoch  932\n",
            "train loss:  21987.11328125\n",
            "epoch  933\n",
            "train loss:  22414.314453125\n",
            "epoch  934\n",
            "train loss:  22151.4453125\n",
            "Validation Loss: 135342.28125\n",
            "epoch  935\n",
            "train loss:  22121.22265625\n",
            "epoch  936\n",
            "train loss:  22228.1796875\n",
            "epoch  937\n",
            "train loss:  21989.90625\n",
            "epoch  938\n",
            "train loss:  22185.12109375\n",
            "epoch  939\n",
            "train loss:  22049.09765625\n",
            "Validation Loss: 134775.6875\n",
            "epoch  940\n",
            "train loss:  21843.59375\n",
            "epoch  941\n",
            "train loss:  21845.75\n",
            "epoch  942\n",
            "train loss:  22313.546875\n",
            "epoch  943\n",
            "train loss:  21930.59765625\n",
            "epoch  944\n",
            "train loss:  22072.166015625\n",
            "Validation Loss: 135707.609375\n",
            "epoch  945\n",
            "train loss:  21738.869140625\n",
            "epoch  946\n",
            "train loss:  21700.12890625\n",
            "epoch  947\n",
            "train loss:  21907.16796875\n",
            "epoch  948\n",
            "train loss:  22009.7578125\n",
            "epoch  949\n",
            "train loss:  21793.53515625\n",
            "Validation Loss: 133629.671875\n",
            "epoch  950\n",
            "train loss:  21939.5\n",
            "epoch  951\n",
            "train loss:  21797.2109375\n",
            "epoch  952\n",
            "train loss:  22296.3046875\n",
            "epoch  953\n",
            "train loss:  21769.7421875\n",
            "epoch  954\n",
            "train loss:  21571.73046875\n",
            "Validation Loss: 135307.59375\n",
            "epoch  955\n",
            "train loss:  21960.91796875\n",
            "epoch  956\n",
            "train loss:  21987.556640625\n",
            "epoch  957\n",
            "train loss:  21950.640625\n",
            "epoch  958\n",
            "train loss:  21537.64453125\n",
            "epoch  959\n",
            "train loss:  21645.501953125\n",
            "Validation Loss: 134305.140625\n",
            "epoch  960\n",
            "train loss:  21637.470703125\n",
            "epoch  961\n",
            "train loss:  21494.6328125\n",
            "epoch  962\n",
            "train loss:  21620.25390625\n",
            "epoch  963\n",
            "train loss:  21739.09375\n",
            "epoch  964\n",
            "train loss:  21666.451171875\n",
            "Validation Loss: 135884.078125\n",
            "epoch  965\n",
            "train loss:  21746.1171875\n",
            "epoch  966\n",
            "train loss:  22034.568359375\n",
            "epoch  967\n",
            "train loss:  21610.265625\n",
            "epoch  968\n",
            "train loss:  21624.703125\n",
            "epoch  969\n",
            "train loss:  21688.181640625\n",
            "Validation Loss: 135629.90625\n",
            "epoch  970\n",
            "train loss:  21072.20703125\n",
            "epoch  971\n",
            "train loss:  21751.853515625\n",
            "epoch  972\n",
            "train loss:  21718.265625\n",
            "epoch  973\n",
            "train loss:  21505.44921875\n",
            "epoch  974\n",
            "train loss:  21803.4921875\n",
            "Validation Loss: 135276.3125\n",
            "epoch  975\n",
            "train loss:  21499.203125\n",
            "epoch  976\n",
            "train loss:  21476.109375\n",
            "epoch  977\n",
            "train loss:  21403.984375\n",
            "epoch  978\n",
            "train loss:  21429.2265625\n",
            "epoch  979\n",
            "train loss:  21489.37890625\n",
            "Validation Loss: 135493.203125\n",
            "epoch  980\n",
            "train loss:  21255.28515625\n",
            "epoch  981\n",
            "train loss:  21430.08984375\n",
            "epoch  982\n",
            "train loss:  21405.1484375\n",
            "epoch  983\n",
            "train loss:  21380.31640625\n",
            "epoch  984\n",
            "train loss:  21487.078125\n",
            "Validation Loss: 134984.6875\n",
            "epoch  985\n",
            "train loss:  21553.69921875\n",
            "epoch  986\n",
            "train loss:  21465.4765625\n",
            "epoch  987\n",
            "train loss:  21032.673828125\n",
            "epoch  988\n",
            "train loss:  21400.71484375\n",
            "epoch  989\n",
            "train loss:  21191.41015625\n",
            "Validation Loss: 137028.59375\n",
            "epoch  990\n",
            "train loss:  21076.8984375\n",
            "epoch  991\n",
            "train loss:  21460.67578125\n",
            "epoch  992\n",
            "train loss:  21418.9453125\n",
            "epoch  993\n",
            "train loss:  21426.951171875\n",
            "epoch  994\n",
            "train loss:  21696.724609375\n",
            "Validation Loss: 137203.375\n",
            "epoch  995\n",
            "train loss:  21115.21484375\n",
            "epoch  996\n",
            "train loss:  21536.185546875\n",
            "epoch  997\n",
            "train loss:  21344.28125\n",
            "epoch  998\n",
            "train loss:  21272.4609375\n",
            "epoch  999\n",
            "train loss:  21380.248046875\n",
            "Validation Loss: 138212.828125\n"
          ]
        }
      ],
      "source": [
        "model = GCN(128)\n",
        "\n",
        "model = model.to(device)\n",
        "data = data.to(device)\n",
        "E_train = E_train.to(device)\n",
        "E_val = E_val.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.001)  # L2 regularization\n",
        "\n",
        "train(model, V, data, train_edges=E_train, val_edges=valid_edges_in_V, optimizer=optimizer, test_active = False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OSw9jHJ3tKgj"
      },
      "source": [
        "### Loading the saved model and losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33jZOju53KKl"
      },
      "outputs": [],
      "source": [
        "#### loading losses\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "with open('/content/gdrive/My Drive/TUNEUP/train_losses_1001.pkl', 'rb') as f:\n",
        "    train_losses = pickle.load(f)\n",
        "\n",
        "with open('/content/gdrive/My Drive/TUNEUP/val_losses_1001.pkl', 'rb') as f:\n",
        "    val_losses = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "rH2aqtDjrntI",
        "outputId": "830ed5db-d185-412c-bdf3-3bca779d2e24"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAIjCAYAAABRULnOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADTKElEQVR4nOzdd3hUZdrH8e/U9ITQkgCh994RC6IgoagoqIioIKgrAgrYV0XA9oqKiuiyrgq6KyL2AgqRJkiUjvQmnRR6SJ/MzPvHyUwSWiahTAK/z3UdM3POc865Z3iczJ2nmdxutxsREREREREp88z+DkBERERERETODyV4IiIiIiIilwgleCIiIiIiIpcIJXgiIiIiIiKXCCV4IiIiIiIilwgleCIiIiIiIpcIJXgiIiIiIiKXCCV4IiIiIiIilwgleCIiIiIiIpcIJXgiIiLFNGjQIGrWrFmic8eOHYvJZDq/AYmIiORRgiciIpcMk8nk07Zw4UJ/h+oXgwYNIjQ01N9hiIjIBWRyu91ufwchIiJyPvzvf/8r9PzTTz8lPj6e//73v4X233DDDURFRZX4Pg6HA5fLRUBAQLHPzc3NJTc3l8DAwBLfv6QGDRrEV199RVpa2kW/t4iIXBxWfwcgIiJyvtx9992Fnv/xxx/Ex8efsv9kGRkZBAcH+3wfm81WovgArFYrVqt+/YqIyIWhLpoiInJZ6dy5M02bNmXlypV06tSJ4OBg/vnPfwLw/fff06tXL6pUqUJAQAB16tThxRdfxOl0FrrGyWPwdu3ahclk4o033uCDDz6gTp06BAQE0K5dO5YvX17o3NONwTOZTAwfPpzvvvuOpk2bEhAQQJMmTfjll19OiX/hwoW0bduWwMBA6tSpw7///e/zPq7vyy+/pE2bNgQFBVGxYkXuvvtu9u/fX6hMUlIS9913H9WqVSMgIICYmBh69+7Nrl27vGVWrFhBXFwcFStWJCgoiFq1ajF48ODzFqeIiJxKf0IUEZHLzuHDh+nRowd33nknd999t7e75rRp0wgNDWX06NGEhoYyf/58xowZQ2pqKq+//nqR150+fTonTpzgH//4ByaTiQkTJtCnTx/+/vvvIlv9lixZwjfffMPDDz9MWFgYkyZNom/fvuzZs4cKFSoAsHr1arp3705MTAzjxo3D6XQyfvx4KlWqdO5vSp5p06Zx33330a5dO1599VWSk5N55513+P3331m9ejXlypUDoG/fvmzYsIERI0ZQs2ZNUlJSiI+PZ8+ePd7n3bp1o1KlSjz99NOUK1eOXbt28c0335y3WEVE5DTcIiIil6hhw4a5T/5Vd+2117oB95QpU04pn5GRccq+f/zjH+7g4GB3VlaWd9/AgQPdNWrU8D7fuXOnG3BXqFDBfeTIEe/+77//3g24f/zxR+++F1544ZSYALfdbndv377du2/t2rVuwP3uu+969910003u4OBg9/79+737tm3b5rZaradc83QGDhzoDgkJOePxnJwcd+XKld1NmzZ1Z2Zmevf/9NNPbsA9ZswYt9vtdh89etQNuF9//fUzXuvbb791A+7ly5cXGZeIiJw/6qIpIiKXnYCAAO67775T9gcFBXkfnzhxgkOHDnHNNdeQkZHB5s2bi7xuv379iIyM9D6/5pprAPj777+LPLdr167UqVPH+7x58+aEh4d7z3U6nfz666/ccsstVKlSxVuubt269OjRo8jr+2LFihWkpKTw8MMPF5oEplevXjRs2JBZs2YBxvtkt9tZuHAhR48ePe21PC19P/30Ew6H47zEJyIiRVOCJyIil52qVatit9tP2b9hwwZuvfVWIiIiCA8Pp1KlSt4JWo4fP17kdatXr17ouSfZO1MSdLZzPed7zk1JSSEzM5O6deueUu50+0pi9+7dADRo0OCUYw0bNvQeDwgI4LXXXuPnn38mKiqKTp06MWHCBJKSkrzlr732Wvr27cu4ceOoWLEivXv3ZurUqWRnZ5+XWEVE5PSU4ImIyGWnYEudx7Fjx7j22mtZu3Yt48eP58cffyQ+Pp7XXnsNAJfLVeR1LRbLafe7fViR6FzO9YeRI0eydetWXn31VQIDA3n++edp1KgRq1evBoyJY7766isSEhIYPnw4+/fvZ/DgwbRp00bLNIiIXEBK8ERERDBmpzx8+DDTpk3j0Ucf5cYbb6Rr166Fulz6U+XKlQkMDGT79u2nHDvdvpKoUaMGAFu2bDnl2JYtW7zHPerUqcNjjz3G3LlzWb9+PTk5Obz55puFylxxxRW8/PLLrFixgs8++4wNGzYwY8aM8xKviIicSgmeiIgI+S1oBVvMcnJyeP/99/0VUiEWi4WuXbvy3XffceDAAe/+7du38/PPP5+Xe7Rt25bKlSszZcqUQl0pf/75ZzZt2kSvXr0AY93ArKysQufWqVOHsLAw73lHjx49pfWxZcuWAOqmKSJyAWmZBBEREeDKK68kMjKSgQMH8sgjj2Aymfjvf/9bqrpIjh07lrlz53LVVVcxdOhQnE4nkydPpmnTpqxZs8anazgcDl566aVT9pcvX56HH36Y1157jfvuu49rr72W/v37e5dJqFmzJqNGjQJg69atdOnShTvuuIPGjRtjtVr59ttvSU5O5s477wTgk08+4f333+fWW2+lTp06nDhxgv/85z+Eh4fTs2fP8/aeiIhIYUrwREREgAoVKvDTTz/x2GOP8dxzzxEZGcndd99Nly5diIuL83d4ALRp04aff/6Zxx9/nOeff57Y2FjGjx/Ppk2bfJrlE4xWyeeff/6U/XXq1OHhhx9m0KBBBAcH83//93889dRThISEcOutt/Laa695Z8aMjY2lf//+zJs3j//+979YrVYaNmzIzJkz6du3L2BMsrJs2TJmzJhBcnIyERERtG/fns8++4xatWqdt/dEREQKM7lL058mRUREpNhuueUWNmzYwLZt2/wdioiI+JnG4ImIiJQhmZmZhZ5v27aN2bNn07lzZ/8EJCIipYpa8ERERMqQmJgYBg0aRO3atdm9ezf/+te/yM7OZvXq1dSrV8/f4YmIiJ9pDJ6IiEgZ0r17dz7//HOSkpIICAigY8eOvPLKK0ruREQEUAueiIiIiIjIJUNj8ERERERERC4RSvBEREREREQuERqDV4q5XC4OHDhAWFgYJpPJ3+GIiIiIiIifuN1uTpw4QZUqVTCbz9xOpwSvFDtw4ACxsbH+DkNEREREREqJvXv3Uq1atTMeV4JXioWFhQHGP2J4eLhfY3E4HMydO5du3bphs9n8GouUDaozUlw+1RmHA6ZONR7fdx+obl3W9DkjxaU6I8VVmupMamoqsbGx3hzhTJTglWKebpnh4eGlIsELDg4mPDzc75VbygbVGSkun+pMejo88YTxeOhQCAm5eAFKqaPPGSku1RkprtJYZ4oauqVJVkRERERERC4RSvBEREREREQuEUrwRERERERELhEagyciIiIiZZLb7SY3Nxen0+lTeYfDgdVqJSsry+dz5PJ2MeuMxWLBarWe8/JoSvBEREREpMzJyckhMTGRjIwMn89xu91ER0ezd+9erTEsPrnYdSY4OJiYmBjsdnuJr6EET0RERETKFJfLxc6dO7FYLFSpUgW73e7Tl2+Xy0VaWhqhoaFnXShaxONi1Rm3201OTg4HDx5k586d1KtXr8T3U4InIiJlR0AA/PRT/mMRuSzl5OTgcrmIjY0lODjY5/NcLhc5OTkEBgYqwROfXMw6ExQUhM1mY/fu3d57loQSPBERKTusVujVy99RiEgpoSRNLjXno07r/woREREREZFLhFrwRESk7HA44LPPjMcDBoDN5t94REREShm14ImISNmRkwP33WdsOTn+jkZEpFSoWbMmb7/9tr/DkFJCCZ6IiIiIyEVgMpnOuo0dO7ZE112+fDkPPvjgOcXWuXNnRo4ceU7XkNJBXTRFRERERC6CxMRE7+MvvviCMWPGsGXLFu++0NBQ72O3243T6cRqLfrreqVKlc5voFKmqQVPRERERMo8t9tNRk5ukVtmjtOncr5ubrfb5xijo6O9W0REBCaTyft88+bNhIWF8fPPP9OmTRsCAgJYsmQJO3bsoHfv3kRFRREaGkq7du349ddfC1335C6aJpOJDz/8kFtvvZXg4GDq1avHDz/8cE7v79dff02TJk0ICAigZs2avPnmm4WOv//++9SrV4/AwECioqK47bbbvMe++uormjVrRlBQEBUqVKBr166kp6efUzxyZmrBExEREZEyL9PhpPGYORf9vhvHxxFsP39fqZ9++mneeOMNateuTWRkJHv37qVnz568/PLLBAQE8Omnn3LTTTexZcsWqlevfsbrjBs3jgkTJvD666/z7rvvMmDAAHbv3k358uWLHdPKlSu54447GDt2LP369WPp0qU8/PDDVKhQgUGDBrFixQoeeeQR/vvf/3LllVdy5MgRFi9eDBitlv3792fChAnceuutnDhxgsWLFxcrMZbiUYInIiIiIlJKjB8/nhtuuMH7vHz58rRo0cL7/MUXX+Tbb7/lhx9+YPjw4We8zqBBg+jfvz8Ar7zyCpMmTWLZsmV079692DFNnDiRLl268PzzzwNQv359Nm7cyOuvv86gQYPYs2cPISEh3HjjjYSFhVGjRg1atWoFGAlebm4uffr0oUaNGgA0a9as2DGI75TgSZFSTmSx/O9DbDluoqe/gxERERE5jSCbhY3j485axuVycSL1BGHhYedtkfQgm+W8XMejbdu2hZ6npaUxduxYZs2a5U2WMjMz2bNnz1mv07x5c+/jkJAQwsPDSUlJKVFMmzZtonfv3oX2XXXVVbz99ts4nU5uuOEGatSoQe3atenevTvdu3f3dg9t0aIFXbp0oVmzZsTFxdGtWzduu+02IiMjSxSLFE1j8KRI6/YdZ9jna/lpt6qLiPhZQADMnGlsAQH+jkZEShGTyUSw3VrkFmS3+FTO181kMp3X1xESElLo+eOPP863337LK6+8wuLFi1mzZg3NmjUjp4ilYmwnrRNqMplwuVznNVaPsLAwVq1axeeff05MTAxjxoyhRYsWHDt2DIvFQnx8PD///DONGzfm3XffpUGDBuzcufOCxCJK8MQHdqtRTZzqKi0i/ma1wu23G5sPM8uJiJR1v//+O4MGDeLWW2+lWbNmREdHs2vXrosaQ6NGjfj9999Piat+/fpYLEYLptVqpWvXrkyYMIG//vqLXbt2MX/+fMBILq+66irGjRvH6tWrsdvtfPvttxf1NVxO9NtRimSzGAlerhI8ERERkYuqXr16fPPNN9x0002YTCaef/75C9YSd/DgQdasWVNoX0xMDI899hjt2rXjxRdfpF+/fiQkJDB58mTef/99AH766Sf+/vtvOnXqRGRkJLNnz8blctGgQQP+/PNP5s2bR7du3ahcuTJ//vknBw8epFGjRhfkNYgSPPGBN8G7MJ8lIiK+y80Fz199b71VrXgicsmbOHEigwcP5sorr6RixYo89dRTpKamXpB7TZ8+nenTpxfa9+KLL/Lcc88xc+ZMxowZw4svvkhMTAzjx49n0KBBAJQrV45vvvmGsWPHkpWVRb169fj8889p0qQJmzZt4rfffuPtt98mNTWVGjVq8Oabb9KjR48L8hoETG7NUVpqpaamEhERwfHjxwkPD/dbHOv3H+fGd5cQYXez4vm4U/p0i5yOw+Fg9uzZ9OzZU3VGfOJTnUlPB89CwGlpcNJYFbm86HPm8pWVlcXOnTupVasWgYGBPp/ncrlITU0lPDz8vE2yIpe2i11nzla3fc0NVLOlSJ4WPKda8ERERERESjUleFIkTbIiIiIiIlI2KMGTItksxvS/GoMnIiIiIlK6KcGTItk1i6aIiIiISJmgBE+K5Omi6caE06UsT0RERESktFKCJ0XyTLICkKN+miIiIiIipZYWEJIiFUzwHJpKU0T8yW6HqVPzH4uIiEghSvCkSJ5JVkAJnoj4mc0GeQvrioiIyKnURVOKZDKZvElejtZKEBEREREptZTgiU88E63kqAVPRPwpNxdmzTK23Fx/RyMi4hedO3dm5MiR3uc1a9bk7bffPus5JpOJ77777pzvfb6uIxeOEjzxiWepBE2yIiJ+lZ0NN95obNnZ/o5GRKRYbrrpJrp3737aY4sXL8ZkMvHXX38V+7rLly/nwQcfPNfwChk7diwtW7Y8ZX9iYiI9evQ4r/c62bRp0yhXrtwFvcelTAme+MQz0YrG4ImIiIiUzJAhQ4iPj2ffvn2nHJs6dSpt27alefPmxb5upUqVCA4OPh8hFik6OpqAgICLci8pGSV44hN73hg8h8bgiYiISGnkdkNOetGbI8O3cr5ubt+/G914441UqlSJadOmFdqflpbGl19+yZAhQzh8+DD9+/enatWqBAcH06xZMz7//POzXvfkLprbtm2jU6dOBAYG0rhxY+Lj408556mnnqJ+/foEBwdTu3Ztnn/+eRwOB2C0oI0bN461a9diMpkwmUzemE/uorlu3Tquv/56goKCqFChAg8++CBpaWne44MGDeKWW27hjTfeICYmhgoVKjBs2DDvvUpiz5499O7dm9DQUMLDw7njjjtITk72Hl+7di3XXXcdYWFhhIeH06ZNG1asWAHA7t27uemmm4iMjCQkJIQmTZowe/bsEsdSGpWZWTTHjh3LuHHjCu1r0KABmzdvBiArK4vHHnuMGTNmkJ2dTVxcHO+//z5RUVHe8nv27GHo0KEsWLCA0NBQBg4cyKuvvorVmv82LFy4kNGjR7NhwwZiY2N57rnnGHTSjG3vvfcer7/+OklJSbRo0YJ3332X9u3be4/7EktZY1MXTRERESnNHBnwSpWzFjED5c73ff95AOwhPhW1Wq3ce++9TJs2jWeffRaTyfgD+pdffonT6aR///6kpaXRpk0bnnrqKcLDw5k1axb33HMPderUKfR980xcLhd9+vQhKiqKP//8k+PHjxcar+cRFhbGtGnTqFKlCuvWreOBBx4gLCyMJ598kn79+rF+/Xp++eUXfv31VwAiIiJOuUZ6ejpxcXF07NiR5cuXk5KSwv3338/w4cMLJbELFiwgJiaGBQsWsH37dvr160fLli154IEHfHrfTn59nuRu0aJF5ObmMmzYMPr168fChQsBGDBgAK1ateJf//oXFouFNWvWYLPZABg2bBg5OTn89ttvhISEsHHjRkJDQ4sdR2lWZhI8gCZNmngrGVAoMRs1ahSzZs3iyy+/JCIiguHDh9OnTx9+//13AJxOJ7169SI6OpqlS5eSmJjIvffei81m45VXXgFg586d9OrVi4ceeojPPvuMefPmcf/99xMTE0NcXBwAX3zxBaNHj2bKlCl06NCBt99+m7i4OLZs2ULlypV9iqUsUhdNERERkXM3ePBgXn/9dRYtWkTnzp0Bo3tm3759iYiIICIigscff9xbfsSIEcyZM4eZM2f6lOD9+uuvbN68mTlz5lClipHwvvLKK6eMm3vuuee8j2vWrMnjjz/OjBkzePLJJwkKCiI0NBSr1Up0dPQZ7zV9+nSysrL49NNPCQkxktzJkydz00038dprr3kbNyIjI5k8eTIWi4WGDRvSq1cv5s2bV6IEb968eaxbt46dO3cSGxsLwKeffkqTJk1Yvnw57dq1Y8+ePTzxxBM0bNgQgHr16nnP37NnD3379qVZs2YA1K5du9gxlHZlKsE7UyU7fvw4H330EdOnT+f6668HjP9RGjVqxB9//MEVV1zB3Llz2bhxI7/++itRUVG0bNmSF198kaeeeoqxY8dit9uZMmUKtWrV4s033wSgUaNGLFmyhLfeesub4E2cOJEHHniA++67D4ApU6Ywa9YsPv74Y55++mmfYimLPLNoKsETERGRUskWbLSmnYXL5SL1xAnCw8Iwm8/TSCVb8ca+NWzYkCuvvJKPP/6Yzp07s337dhYvXsz48eMBo1HilVdeYebMmezfv5+cnByys7N9HmO3adMmYmNjvckdQMeOHU8p98UXXzBp0iR27NhBWloaubm5hIeHF+u1bNq0iRYtWniTO4CrrroKl8vFli1bvAlekyZNsFgs3jIxMTGsW7euWPcqeM/Y2FhvcgfQuHFjypUrx6ZNm2jXrh2jR4/m/vvv57///S9du3bl9ttvp06dOgA88sgjDB06lLlz59K1a1f69u1bonGPpVmZSvC2bdtGlSpVCAwMpGPHjrz66qtUr16dlStX4nA46Nq1q7dsw4YNqV69OgkJCVxxxRUkJCTQrFmzQt0k4+LiGDp0KBs2bKBVq1YkJCQUuoanjKdZOycnh5UrV/LMM894j5vNZrp27UpCQgKAT7GcSXZ2NtkFZoVLTU0FwOFwnFM/5fMhL78jI9v/sUjZ4Kknqi/iK5/qjMOBrWB51a/Lmj5nLl8OhwO3243L5cLlKvDHZ2vQWc9zu91gc+K2BePK6x55ztzuYo3DA7jvvvt49NFHeffdd/n444+pU6cO11xzDS6XiwkTJvDOO+8wceJEmjVrRkhICKNGjSI7O7vQa/W8/pOfu/NiKXjM89jzfiUkJDBgwADGjh1Lt27diIiI4IsvvmDixInesqe7TsHr+Xovt9uN1Wo95Tqn/NuddOxM9/YlrjFjxnDnnXcye/Zsfv75Z1544QWmT5/OrbfeyuDBg7nhhhuYNWsW8fHxvPrqq7zxxhsMHz78tLF47nfy+32heN4zh8NRKCkG3z/rykyC16FDB6ZNm0aDBg1ITExk3LhxXHPNNaxfv56kpCTsdvsp06lGRUWRlJQEQFJS0ilj4DzPiyqTmppKZmYmR48exel0nraMZyygL7GcyauvvnrKOEOAuXPnXrSZkc4kLdUCmFi1ei3uvWv8GouULacb2C1yNmerM6bcXGrmTQW+a9483NYy82tMLiB9zlx+PL260tLSyMnJKfb5J06cuABR+a579+6YzWY+/vhjPvnkEwYPHuyNadGiRfTo0YObb74ZwNsa1qBBA+8f/3Nzc8nJyfE+d7lcZGVlkZqaSvXq1dm7dy9bt2719nybP38+AJmZmaSmprJgwQJiY2MLJTXbt2/H7XYXumbBexTkuU7NmjWZNm0aiYmJ3la8+Ph4zGYzVapUITU1FYfDQW5ubqHr5OTknLKvoKysrEKxFOR5fRs3bqRatWoAbN68mWPHjlGjRg3vOdHR0QwePJjBgwczZMgQPvzwQ7p06QIY4wnvuusu7rrrLsaNG8e///1v7r333rP+m12sOpOTk0NmZia//fYbuSet95qRkeHTNcrMb8aC/YabN29Ohw4dqFGjBjNnziQo6Ox/rSkrnnnmGUaPHu19npqaSmxsLN26dSt2k/n5NjN5OdtTj9KwSVN6tokt+gS57DkcDuLj47nhhhu8A5tFzsbnOpP3pafRRYpLSi99zly+srKy2Lt3L6GhoQQGBvp8ntvt5sSJE4SFhXknOPEHz8yPL774IqmpqfzjH//wftdr1KgRX3/9NevXrycyMpK33nqLgwcP0qRJE28Zq9WK3W73PjebzQQGBhIeHs7NN99M/fr1GTFiBBMmTCA1NZVXX30VgKCgIMLDw2natCn79u1j9uzZtGvXjtmzZzNr1ixMJpP3mg0aNGDPnj38/fffVKtWjbCwMO/yCJ7rDBkyhNdee41HHnmEF154gYMHD/LMM89w9913U7duXQBsNhtWq7XQd1m73X7KvoICAwNxuVz8/fffhfYHBARw880306xZMx5++GEmTpxIbm4uw4cP59prr+Xaa68lMzOTJ598kr59+1KrVi327dvH2rVr6dOnD+Hh4YwaNYru3btTv359jh49SkJCQqH39mQXu85kZWURFBTknQW1oDMlxCcrMwneycqVK0f9+vXZvn07N9xwAzk5ORw7dqxQy1lycrL3LxfR0dEsW7as0DU806kWLFNwilVPmfDwcIKCgrBYLFgsltOWKXiNomI5k4CAgNOuK2Kz2fz+i8tuM5qIXZj8HouULaWh/krZojojxaU6c/lxOp2YTCbMZnOxxtJ5uth5zvWn+++/n48//piePXt6W6IAnn/+eXbu3EmPHj0IDg7mwQcf5JZbbuH48eOFYj75NRR8P7799luGDBnCFVdcQc2aNZk0aZK31dBsNnPLLbcwatQoHnnkEbKzs+nVqxfPP/88Y8eO9V7z9ttv57vvvqNLly4cO3aMqVOnemeW91wnNDSUOXPm8Oijj9KhQweCg4Pp27cvEydO9F7Hs8zCybF6rnM6ZrPZO5toQXXq1GH79u18//33jBgxgs6dO2M2m+nevTvvvvsuZrMZm83GkSNHGDRoEMnJyVSsWJE+ffowfvx4zGYzLpeLESNGsG/fPsLDw+nevTtvvfXWGWO52HXGbDZjMplO+7nm8+ecu4w6ceKEOzIy0v3OO++4jx075rbZbO6vvvrKe3zz5s1uwJ2QkOB2u93u2bNnu81mszs5Odlb5t///rc7PDzcnZWV5Xa73e4nn3zS3bRp00L36d+/vzsuLs77vH379u7hw4d7nzudTnfVqlXdr776qtvtdvsUi6+OHz/uBtzHjx8v1nkXwoOfLHPXeOon99QlO/wdipQROTk57u+++86dk5Pj71CkjPCpzuTmut0LFhhbbu7FCk1KKX3OXL4yMzPdGzdudGdmZhbrPKfT6T569Kjb6XReoMjkUnOx68zZ6ravuUGZacF7/PHHuemmm6hRowYHDhzghRdewGKx0L9/fyIiIhgyZAijR4+mfPnyhIeHM2LECDp27Oid1KRbt240btyYe+65hwkTJpCUlMRzzz3HsGHDvK1mDz30EJMnT+bJJ59k8ODBzJ8/n5kzZzJr1ixvHKNHj2bgwIG0bduW9u3b8/bbb5Oenu6dVdOXWMoirYMnIqVCVhZcd53xOC0NQnxbe0pERORyUWYSvH379tG/f38OHz5MpUqVuPrqq/njjz+oVKkSgLdptW/fvoUWF/ewWCz89NNPDB06lI4dOxISEsLAgQO9U9IC1KpVi1mzZjFq1CjeeecdqlWrxocffuhdIgGgX79+HDx4kDFjxpCUlETLli355ZdfCk28UlQsZZFNyySIiIiIiJR6ZSbBmzFjxlmPBwYG8t577/Hee++dsUyNGjWYPXv2Wa/TuXNnVq9efdYyw4cPP+NUqr7GUtbYvQudF28aYBERERERuXj8O7pUygzPQufZuU4/RyIiIiIiImeiBE98YrcYsx1pDJ6IiIiISOmlBE98EmA1lklQgiciIiIiUnopwROfeLpo5miSFRERERGRUqvMTLIi/hXgGYPnUIInIn5ks8GECfmPRUREpBAleOKTALXgiUhpYLfDE0/4OwoREZFSS100xSf5s2gqwRMRERG50EwmE9999533+ebNm7niiisIDAykZcuWZ9wnohY88UmAEjwRKQ2cTli1ynjcujVYLP6NR0SkmAYNGsQnn3wCgNVqpXz58jRv3pz+/fszaNAgzGbjO1diYiKRkZHe81544QVCQkLYsmULoaGhZ9wnohY88YlnoXPNoikifpWVBe3bG1tWlr+jEREpke7du5OYmMiuXbv4+eefue6663j00Ue58cYbyc3NBSA6OpqAgADvOTt27ODqq6+mRo0aVKhQ4Yz7iisnJ+fcX5CUKkrwxCdqwRMREZHSzO12k+HIKHLLzM30qZyvm9vtLnasAQEBREdHU7VqVVq3bs0///lPvv/+e37++WemTZsGFO6iaTKZWLlyJePHj8dkMjF27NjT7gPYu3cvd9xxB+XKlaN8+fL07t2bXbt2ee89aNAgbrnlFl5++WWqVKlCgwYNinXeG2+8QUxMDBUqVGDYsGE4HA5vmezsbJ566iliY2MJCAigbt26fPTRR97j69evp0ePHoSGhhIVFcU999zDoUOHiv3+ydmpi6b4xG5TgiciIiKlV2ZuJh2md7jo9/3zrj8JtgWf83Wuv/56WrRowTfffMP9999f6FhiYiJdu3ale/fuPP7444SGhvLQQw+dss/hcBAXF0fHjh1ZvHgxVquVl156ie7du/PXX39ht9sBmDdvHuHh4cTHxwP4fN6CBQuIiYlhwYIFbN++nX79+tGyZUseeOABAO69914SEhKYNGkSLVq0YOfOnd4E7tixY1x//fXcf//9vPXWW2RmZvLUU09xxx13MH/+/HN+/ySfEjzxibpoioiIiFxYDRs25K+//jplf3R0NFarldDQUKKjowEIDQ09Zd///vc/XC4XH374ISaTCYCpU6dSrlw5Fi5cSLdu3QAICQnhww8/9CZuvp4XGRnJ5MmTsVgsNGzYkF69ejFv3jweeOABtm7dysyZM4mPj6dr164A1K5d2/saJk+eTKtWrXjllVe8+z7++GNiY2PZunUr9evXP6/v5eVMCZ74xLtMQq7Tz5GIiIiInCrIGsSfd/151jIul4sTJ04QFhbmnczkfNz3fHG73d4EqyTWrl3L9u3bCQsLK7Q/KyuLHTt2eJ83a9bMm9wV57wmTZpgKTC5VUxMDOvWrQNgzZo1WCwWrr322jPGtmDBgtNOBrNjxw4leOeREjzxid27Dl7x+5mLiIiIXGgmk6nIrpIul4tcay7BtuDzluCdT5s2baJWrVolPj8tLY02bdrw2WefnXKsUqVK3schISElOs9msxU6ZjKZcLmM3l1BQWdPdNPS0rjpppt47bXXTjkWExNz1nOleJTgiU8CrMZfa7LVgiciIiJy3s2fP59169YxatSoEl+jdevWfPHFF1SuXJnw8PALfl5BzZo1w+VysWjRIm8XzZPv8fXXX1OzZk2sVqUgF1Lp+9OFlEqaRVNESgWbDV54wdhO+kuyiEhZkZ2dTVJSEvv372fVqlW88sor9O7dmxtvvJF77723xNcdMGAAFStWpHfv3ixevJidO3eycOFCHnnkEfbt23fezyuoZs2aDBw4kMGDB/Pdd995rzFz5kwAhg0bxpEjR+jfvz/Lly9nx44dzJkzh/vuuw+nUw0I55MSPPGJt4tmrqtE0wGLiJwXdjuMHWtsBcaPiIiUJb/88gsxMTHUrFmT7t27s2DBAiZNmsT3339faIxbcQUHB/Pbb79RvXp1+vTpQ6NGjRgyZAhZWVlnbZkr6Xkn+9e//sVtt93Gww8/TMOGDXnggQdIT08HoEqVKvz+++84nU66detGs2bNGDlyJOXKlSuV3WXLMpNb39ZLrdTUVCIiIjh+/HiJm8vPl0OpGbR9ZQEA217ugc2i/xHl7BwOB7Nnz6Znz56n9NkXOR3VGSku1ZnLV1ZWFjt37qRWrVoEBgb6fJ7L5SI1NZXw8HAlFeKTi11nzla3fc0NVLPFJ54umqClEkTEj1wu2LDB2Fz6LBIRETmZRjiKT+wFWuyyc12EBPgxGBG5fGVmQtOmxuO0NDhpJjgREZHLnVrwxCdmswmLyejNq5k0RURERERKJyV44jNr3rqb6qIpIiIiIlI6KcETn3mG4WmpBBERERGR0kkJnvjM5knwHErwRERERERKIyV44jNPC16WxuCJiIiIiJRKSvDEZ3ZPgudQgiciIiIiUhppmQTxmc2b4KmLpoj4ic0Gjz+e/1hEREQKUQue+MxmNpZJyFQLnoj4i90Or79ubHa7v6MREbngOnfuzMiRI/0dxilx1KxZk7fffvus55hMJr777rtzvvf5us7lQgme+ExdNEVERETOzaBBgzCZTDz00EOnHBs2bBgmk4lBgwZ5933zzTe8+OKLJb7fTTfdRPfu3U97bPHixZhMJv76669iX3f58uU8+OCDJY7rdMaOHUvLli1P2Z+YmEiPHj3O671ONm3aNMqVK3dB73GxKMETn9mU4ImIv7lcsGuXsbnUXVxEyqbY2FhmzJhBZmamd19WVhbTp0+nevXqhcqWL1+esLCwEt9ryJAhxMfHs2/fvlOOTZ06lbZt29K8efNiX7dSpUoEBweXOK7iiI6OJiAg4KLc61KgBE98phY8EfG7zEyoVcvYCnwxEhHxSk8/85aV5XvZkz9jTlemhFq3bk1sbCzffPONd98333xD9erVadWqVaGyp+sa+corrzB48GDCwsKoXr06H3zwwRnvdeONN1KpUiWmTZtWaH9aWhpffvklQ4YM4fDhw/Tv35+qVasSHBxMs2bN+Pzzz8/6Gk7uorlt2zY6depEYGAgjRs3Jj4+/pRznnrqKerXr09wcDC1a9fm+eefx+FwAEYL2rhx41i7di0mkwmTyeSN+eQumuvWreP6668nKCiIChUq8OCDD5KWluY9PmjQIG655RbeeOMNYmJiqFChAsOGDfPeqyT27NlD7969CQ0NJTw8nDvuuIPk5GTv8bVr13LdddcRFhZGeHg4bdq0YcWKFQDs3r2bm266icjISEJCQmjSpAmzZ88ucSxFUYInPtMkKyIiIlLqhYaecTPddlvhspUrn7n8yV0Ca9Y8tcw5GDx4MFOnTvU+//jjj7nvvvt8OvfNN9+kbdu2rF69mocffpihQ4eyZcuW05a1Wq3ce++9TJs2Dbfb7d3/5Zdf4nQ66d+/P1lZWbRp04ZZs2axfv16HnzwQe655x6WLVvmUzwul4s+ffpgt9v5888/mTJlCk899dQp5cLCwpg2bRobN27knXfe4T//+Q9vvfUWAP369eOxxx6jSZMmJCYmkpiYSL9+/U65Rnp6OnFxcURGRrJ8+XK+/PJLfv31V4YPH16o3IIFC9ixYwcLFizgk08+Ydq0aackub5yuVzceuutHDlyhEWLFhEfH8/ff/9dKL4BAwZQrVo1li9fzsqVK3n66aex5U0GNmzYMLKzs/ntt99Yt24dr732GqHnWH/ORrNois9sFuOnJlkREREROTd33303zzzzDLt37wbg999/Z8aMGSxcuLDIc3v27MnDDz8MGK1ib731FgsWLKBBgwanLT948GBef/11Fi1aROfOnQGje2bfvn2JiIggIiKCxz0zFAMjRoxgzpw5zJw5k/bt2xcZz6+//srmzZuZM2cOVapUAeCVV145Zdzcc889531cs2ZNHn/8cWbMmMGTTz5JUFAQoaGhWK1WoqOjz3iv6dOnk5WVxaeffkpISAgAkydP5qabbuK1114jKioKgMjISCZPnozFYqFhw4b06tWLefPm8cADDxT5ek62aNEi1q1bx86dO4mNjQXg008/pUmTJixfvpx27dqxZ88ennjiCRo2bAhAvXr1vOfv2bOHvn370qxZMwBq165d7BiKQwme+Exj8ERERKTUK9BV72RukwlycvJ3pKSc+Trmkzq67dp1bnGdpFKlSvTq1cvbstarVy8qVqzo07kFx8yZTCaio6NJOctradiwIVdeeSUff/wxnTt3Zvv27SxevJjx48cD4HQ6eeWVV5g5cyb79+8nJyeH7Oxsn8fYbdq0idjYWG9yB9CxY8dTyn3xxRdMmjSJHTt2kJaWRm5uLuHh4T7do+C9WrRo4U3uAK666ipcLhdbtmzxJnhNmjTBYrF4y8TExLBu3bpi3ctj69atxMbGepM7gMaNG1OuXDk2bdpEu3btGD16NPfffz///e9/6dq1K7fffjt16tQB4JFHHmHo0KHMnTuXrl270rdv3xKNe/SVumiKz+x5yyQowRMREZFSKyTkzFtgoO9lg4KKLnuOBg8ezLRp0/jkk08YPHiwz+fZTloH1GQy4Spi4qkhQ4bw9ddfc+LECaZOnUqdOnW49tprAXj99dd55513eOqpp1iwYAFr1qwhLi6OnILJ8DlKSEhgwIAB9OzZk59++onVq1fz7LPPntd7FFSS9+hcjB07lg0bNtCrVy/mz59P48aN+fbbbwG4//77+fvvv7nnnntYt24dbdu25d13371gsSjBE59pDJ6IiIjI+dO9e3dycnJwOBzExcVd0HvdcccdmM1mpk+fzqeffsrgwYMxmUyA0T20d+/e3H333bRo0YLatWuzdetWn6/dqFEj9u7dS2JionffH3/8UajM0qVLqVGjBs8++yxt27alXr163u6pHna7Hafz7A0JjRo1Yu3ataQXmOTm999/x2w2n7GL6rmqX78+e/fuZe/evd59Gzdu5NixYzRu3LhQuVGjRjF37lz69OlTaIxlbGwsDz30EN988w2PPfYY//nPfy5IrKAET4rBk+Bl5qgFT0RERORcWSwWNm3axMaNGwt1J7wQQkND6devH8888wyJiYmF1tqrV68e8fHxLF26lE2bNvGPf/yj0AyRRenatSv169dn4MCBrF27lsWLF/Pss88WKlOvXj327NnDjBkz2LFjB5MmTfK2cHnUrFmTnTt3smbNGg4dOkR2dvYp9xowYACBgYEMHDiQ9evXs2DBAkaMGME999zj7Z5ZUk6nkzVr1hTaNm3aROfOnWnWrBkDBgxg1apVLFu2jHvvvZdrr72Wtm3bkpmZyfDhw1m4cCG7d+/m999/Z/ny5TRq1AiAkSNHMmfOHHbu3MmqVatYsGCB99iFoARPfOZdJiFXCZ6I+InVCg8/bGxWDSMXkbIvPDy82OPQSmrIkCEcPXqUuLi4QuPlnnvuOVq3bk1cXBydO3cmOjqaW265xefrms1mvv32WzIzM2nfvj33338/L7/8cqEyN998M6NGjWL48OG0bNmSpUuX8vzzzxcq07dvX7p37851111HpUqVTrtUQ3BwMHPmzOHIkSO0a9eO2267jS5dujB58uTivRmnkZaWRqtWrQptvXv3xmQy8e233xIZGUmnTp3o2rUrtWvX5osvvgCMRP3w4cPce++91K9fnzvuuIMePXowbtw4wEgchw0bRqNGjejevTv169fn/fffP+d4z8TkLjhfqpQqqampREREcPz48Yv2P/6ZOBwOXvr0Zz7ZZuGK2uWZ8eCpA2dFCnI4HMyePZuePXue0g9e5HRUZ6S4VGcuX1lZWezcuZNatWoRePK4urNwuVykpqYSHh6O+eRJVERO42LXmbPVbV9zA9Vs8Zm3i6bG4ImIiIiIlErq3yI+83TRzNYsmiLiL243HDpkPK5YEfImCBARERGDEjzxmS1vmQQtdC4ifpORAZUrG4/T0s7LNOUiIiKXEnXRFJ/Z8yZ30iyaIiIiIiKlkxI88ZndOwZPCZ6IiIj4n+YKlEvN+ajTSvDEZwF5LXjp2bn6QBURERG/8cyampGR4edIRM4vT50+l5mBNQZPfOZJ8FxuyHK4CLJf2AU5RURERE7HYrFQrlw5UlJSAGNtNJMPky65XC5ycnLIysrSMgnik4tVZ9xuNxkZGaSkpFCuXLlzWvheCZ74zF6gTqfn5CrBExEREb+Jjo4G8CZ5vnC73WRmZhIUFORTQihysetMuXLlvHW7pJTgic/MJgi2W8jIcZKenUvF0AB/hyQiIiKXKZPJRExMDJUrV8bhcPh0jsPh4LfffqNTp07n1AVOLh8Xs87YbLZzarnzUIInxRLiTfA00YqI+IHVCgMH5j8WkcuexWLx+UuxxWIhNzeXwMBAJXjik7JYZ/TbUYol2G4FckjPyfV3KCJyOQoIgGnT/B2FiIhIqaXRpVIsIXkzraRlK8ETERERESlt1IInxRKcN7FKhrpoiog/uN3gmRY9OBg0SYKIiEghasGTYgkJMP4mkK4WPBHxh4wMCA01Nq1/JSIicgoleFIsoXYjwVMXTRERERGR0qfMJnj/93//h8lkYuTIkd59WVlZDBs2jAoVKhAaGkrfvn1JTk4udN6ePXvo1asXwcHBVK5cmSeeeILc3MLJysKFC2ndujUBAQHUrVuXaacZ0P/ee+9Rs2ZNAgMD6dChA8uWLSt03JdYyqLgvDF4GZpkRURERESk1CmTCd7y5cv597//TfPmzQvtHzVqFD/++CNffvklixYt4sCBA/Tp08d73Ol00qtXL3Jycli6dCmffPIJ06ZNY8yYMd4yO3fupFevXlx33XWsWbOGkSNHcv/99zNnzhxvmS+++ILRo0fzwgsvsGrVKlq0aEFcXFyhhTaLiqWsCrF7JlnRGDwRERERkdKmzE2ykpaWxoABA/jPf/7DSy+95N1//PhxPvroI6ZPn871118PwNSpU2nUqBF//PEHV1xxBXPnzmXjxo38+uuvREVF0bJlS1588UWeeuopxo4di91uZ8qUKdSqVYs333wTgEaNGrFkyRLeeust4uLiAJg4cSIPPPAA9913HwBTpkxh1qxZfPzxxzz99NM+xXI62dnZZGdne5+npqYCxgKLvi7geaF47h9oNSY0SMvK8XtMUrp56ofqifjKpzrjcGArWF7167KmzxkpLtUZKa7SVGd8jaHMJXjDhg2jV69edO3atVCCt3LlShwOB127dvXua9iwIdWrVychIYErrriChIQEmjVrRlRUlLdMXFwcQ4cOZcOGDbRq1YqEhIRC1/CU8XQFzcnJYeXKlTzzzDPe42azma5du5KQkOBzLKfz6quvMm7cuFP2z507l+Dg4GK8SxfOgd1/Axa27NjN7Nk7/R2OlAHx8fH+DkHKmLPVGUtWFjfmPZ4zZw7OwMCLE5SUavqckeJSnZHiKg11JsPHycXKVII3Y8YMVq1axfLly085lpSUhN1up1y5coX2R0VFkZSU5C1TMLnzHPccO1uZ1NRUMjMzOXr0KE6n87RlNm/e7HMsp/PMM88wevRo7/PU1FRiY2Pp1q0b4eHhZzzvYnA4HMTHx9O6WWN+2LOF8IpR9OzZyq8xSenmqTM33HADNput6BPksudTnUlP9z6Mi4uDkJCLFJ2URvqckeJSnZHiKk11xtO7ryhlJsHbu3cvjz76KPHx8QReon+xDQgIICAg4JT9NpvN7xXKIzLEiO9EtrPUxCSlW2mqv1I2nLXOBAbCbbcZ5QIDQXVL0OeMFJ/qjBRXaagzvt6/zEyysnLlSlJSUmjdujVWqxWr1cqiRYuYNGkSVquVqKgocnJyOHbsWKHzkpOTiY6OBiA6OvqUmSw9z4sqEx4eTlBQEBUrVsRisZy2TMFrFBVLWRUWZPxNIDXT//2QReQyFBgIX35pbJfoH/tERETORZlJ8Lp06cK6detYs2aNd2vbti0DBgzwPrbZbMybN897zpYtW9izZw8dO3YEoGPHjqxbt67QbJfx8fGEh4fTuHFjb5mC1/CU8VzDbrfTpk2bQmVcLhfz5s3zlmnTpk2RsZRV4YHGXw5OZGmZBBERERGR0qbMdNEMCwujadOmhfaFhIRQoUIF7/4hQ4YwevRoypcvT3h4OCNGjKBjx47eSU26detG48aNueeee5gwYQJJSUk899xzDBs2zNs18qGHHmLy5Mk8+eSTDB48mPnz5zNz5kxmzZrlve/o0aMZOHAgbdu2pX379rz99tukp6d7Z9WMiIgoMpayKjwwrwUvSy14IiIiIiKlTZlJ8Hzx1ltvYTab6du3L9nZ2cTFxfH+++97j1ssFn766SeGDh1Kx44dCQkJYeDAgYwfP95bplatWsyaNYtRo0bxzjvvUK1aNT788EPvEgkA/fr14+DBg4wZM4akpCRatmzJL7/8UmjilaJiKavC8hK8tOxcXC43ZrPJzxGJyGUlPR1CQ43HaWmaZEVEROQkZTrBW7hwYaHngYGBvPfee7z33ntnPKdGjRrMnj37rNft3Lkzq1evPmuZ4cOHM3z48DMe9yWWsigswKgybjecyM4lIkgDlEVERERESosyMwZPSocAm4UAq1FtNNGKiIiIiEjpogRPii08SBOtiIiIiIiURkrwpNg00YqIiIiISOmkBE+KLSxvqYTj6qIpIiIiIlKqKMGTYosMNhK8Yxk5fo5EREREREQKKtOzaIp/lA8x1gw8nK4ET0QuMosFevbMfywiIiKFKMGTYqsQagfgSJoSPBG5yAIDYdYsf0chIiJSaqmLphRb+ZC8BE8teCIiIiIipYoSPCk2T4KnLpoiIiIiIqWLEjwptgpqwRMRf0lPh5AQY0tP93c0IiIipY7G4EmxRSrBExF/ysjwdwQiIiKlllrwpNjUgiciIiIiUjopwZNi84zBy3Q4ycxx+jkaERERERHxUIInxRYaYMVuMarO4fRsP0cjIiIiIiIeSvCk2Ewmk5ZKEBEREREphZTgSYloqQQRERERkdJHs2hKiVQIzWvBS1OCJyIXkdkM116b/1hEREQKUYInJaIumiLiF0FBsHChv6MQEREptfTnTymRyOC8BC9DCZ6IiIiISGmhBE9KxLsWnrpoioiIiIiUGuqiKUVLS8G0K4HoYysxbQECQ6gYVAPQJCsicpGlp0PNmsbjXbsgJMSf0YiIiJQ6SvCkaIlrsX51Lx0Adhq72jcaClzDwTStgyciF9mhQ/6OQEREpNRSF00pWmAErmrtORxSD3dELADlHckAJB3P9GdkIiIiIiJSgBI8KVpse5wDZ7Ok/vO42j8EQJDFCcDBE9nkOl3+jE5ERERERPIowZPisdgACDC5sJpNuNyom6aIiIiISCmhBE+KxW02EjyTy0FUeCAAicez/BmSiIiIiIjkUYInxWMxlkfA6SA6wkjwkpTgiYiIiIiUCppFU4rHkldlnDlEhyvBE5GLzGyGtm3zH4uIiEghSvCkeDwteK7c/Ba8VCV4InKRBAXB8uX+jkJERKTU0p8/pXjM+S14MREagyciIiIiUpoowZPiKTAGzzPJSrISPBERERGRUkEJnhRP3iyaOB35LXipWuxcRC6SjAyoWdPYMjL8HY2IiEipozF4Ujx56+Dhyp9FM/l4Nm63G5PJ5MfAROSy4HbD7t35j0VERKQQteBJ8XgSPGcOlcOMBC/H6eJweo4fgxIREREREVCCJ8Xk9nbRzMVuNVM5LACAA8fUTVNERERExN+U4EnxFGjBA6hePhiA3Yc1FkZERERExN+U4EnxFBiDB/kJ3p4jSvBERERERPxNCZ4UT4FZNAFi8xK8vUrwRERERET8TrNoSvEUWAcPoEYFteCJyEVkMkHjxvmPRUREpBAleFI85rwq43KA260xeCJycQUHw4YN/o5CRESk1FIXTSkeTwsegCvXm+AlHs8kJ9flp6BERERERASU4ElxWQo0+jpzqBQWQKDNjMutpRJERERERPxNCZ4UT8EWPKcDk8mU301T4/BE5ELLyIAmTYwtQ585IiIiJ9MYPCkezyya4J1opXr5YLYmp2miFRG58Nxu2Lgx/7GIiIgUohY8KR6TqfBEK+QvlbDncLq/ohIREREREZTgSUl418LLAaB2pVAAdhxUgiciIiIi4k9K8KT4vGvh5QJQNy/B256S5q+IREREREQEJXhSEpbCXTTrVA4BYO/RDLIcTn9FJSIiIiJy2VOCJ8XnbcEzumhWCg0gPNCK2w07D6mbpoiIiIiIvyjBk+LzjsEzumiaTCbqVvaMw1M3TRG5gEwmqFHD2Ewmf0cjIiJS6ijBk+KzFJ5kBfAmeBqHJyIXVHAw7NplbMHB/o5GRESk1FGCJ8XnSfDyxuAB1NFEKyIiIiIifqcET4rvLC14WipBRERERMR/ykyC969//YvmzZsTHh5OeHg4HTt25Oeff/Yez8rKYtiwYVSoUIHQ0FD69u1LcnJyoWvs2bOHXr16ERwcTOXKlXniiSfIzc0tVGbhwoW0bt2agIAA6taty7Rp006J5b333qNmzZoEBgbSoUMHli1bVui4L7GUaZ4xeBu+haXvwvZ5hcbg5TpdfgxORC5pmZnQrp2xZWb6OxoREZFSp8wkeNWqVeP//u//WLlyJStWrOD666+nd+/ebNiwAYBRo0bx448/8uWXX7Jo0SIOHDhAnz59vOc7nU569epFTk4OS5cu5ZNPPmHatGmMGTPGW2bnzp306tWL6667jjVr1jBy5Ejuv/9+5syZ4y3zxRdfMHr0aF544QVWrVpFixYtiIuLIyUlxVumqFjKvAAjmWP1/2Duc/DZbcTaThAaYCUn18XfmklTRC4UlwtWrDA2l/6YJCIicrIyk+DddNNN9OzZk3r16lG/fn1efvllQkND+eOPPzh+/DgfffQREydO5Prrr6dNmzZMnTqVpUuX8scffwAwd+5cNm7cyP/+9z9atmxJjx49ePHFF3nvvffIyTG6Gk6ZMoVatWrx5ptv0qhRI4YPH85tt93GW2+95Y1j4sSJPPDAA9x33300btyYKVOmEBwczMcffwzgUyxl3vVjoOXd0PxOsAaC24U54xCNYsIA2HDguJ8DFBERERG5PFn9HUBJOJ1OvvzyS9LT0+nYsSMrV67E4XDQtWtXb5mGDRtSvXp1EhISuOKKK0hISKBZs2ZERUV5y8TFxTF06FA2bNhAq1atSEhIKHQNT5mRI0cCkJOTw8qVK3nmmWe8x81mM127diUhIQHAp1jOJDs7m+zsbO/z1NRUABwOBw6H40ynXRSe+zscDohuCb3eBsC6eymm43vIzUqjYXQYy3cdZd3eY9zYNOrMF5PLQqE6I+IDn+qMw4GtYHnVr8uaPmekuFRnpLhKU53xNYYyleCtW7eOjh07kpWVRWhoKN9++y2NGzdmzZo12O12ypUrV6h8VFQUSUlJACQlJRVK7jzHPcfOViY1NZXMzEyOHj2K0+k8bZnNmzd7r1FULGfy6quvMm7cuFP2z507l+BSMh14fHx8oefXZ+cSBvy5ZAG5mU0AC4vX76SFe4df4pPS5+Q6I1KUs9UZS1YWN+Y9njNnDs7AwIsTlJRq+pyR4lKdkeIqDXUmIyPDp3JlKsFr0KABa9as4fjx43z11VcMHDiQRYsW+Tus8+aZZ55h9OjR3uepqanExsbSrVs3wsPD/RiZ8ReD+Ph4brjhBmw2m3e/JfFNSDpAh9bNCQm5gs//9QfJOXZ69LgOkxYhvqydqc6InIlPdSY9f4xvXFwchIRcpOikNNLnjBSX6owUV2mqM57efUUpUwme3W6nbt26ALRp04bly5fzzjvv0K9fP3Jycjh27FihlrPk5GSio6MBiI6OPmW2S8/MlgXLnDzbZXJyMuHh4QQFBWGxWLBYLKctU/AaRcVyJgEBAQQEBJyy32az+b1CeZwSi91oWbS6HTSuGonNYiI1K5fktFxiy5eOVkfxr9JUf6VsOGudKbDfZrMVei6XL33OSHGpzkhxlYY64+v9y8wkK6fjcrnIzs6mTZs22Gw25s2b5z22ZcsW9uzZQ8eOHQHo2LEj69atKzTbZXx8POHh4TRu3NhbpuA1PGU817Db7bRp06ZQGZfLxbx587xlfInlkmILMn46MrFbzdSr7Jloxbe/MIiIFFvFisYmIiIipygzLXjPPPMMPXr0oHr16pw4cYLp06ezcOFC5syZQ0REBEOGDGH06NGUL1+e8PBwRowYQceOHb2TmnTr1o3GjRtzzz33MGHCBJKSknjuuecYNmyYt9XsoYceYvLkyTz55JMMHjyY+fPnM3PmTGbNmuWNY/To0QwcOJC2bdvSvn173n77bdLT07nvvvsAfIrlkmLNS/ByjfWomlQJZ2NiKhsPHKd707O3WIqIFFtICBw86O8oRERESq0yk+ClpKRw7733kpiYSEREBM2bN2fOnDnccMMNALz11luYzWb69u1LdnY2cXFxvP/++97zLRYLP/30E0OHDqVjx46EhIQwcOBAxo8f7y1Tq1YtZs2axahRo3jnnXeoVq0aH374oTHOI0+/fv04ePAgY8aMISkpiZYtW/LLL78UmnilqFguKQVa8MBI8L5cqRY8ERERERF/KDMJ3kcffXTW44GBgbz33nu89957ZyxTo0YNZs+efdbrdO7cmdWrV5+1zPDhwxk+fPg5xXLJODnBqxoBKMETEREREfGHMj0GT0qBkxK8RjHhmEyQlJrFwRPZZzlRRKQEMjOhc2djy8z0dzQiIiKljhI8OTcnJXihAVbqVgoFYPWeo/6KSkQuVS4XLFpkbC6Xv6MREREpdZTgybk5aZIVgDY1IgFYteeYHwISEREREbl8KcGTc3NSCx5A6+qeBE8teCIiIiIiF5MSPDk3p0vwapQD4K99x3A41YVKRERERORiUYIn5+Y0CV7tiqGEB1rJcrjYnHjCT4GJiIiIiFx+lODJubEFGz8LjMEzm020rqFumiIiIiIiF5sSPDk31kDjp6PwdOWecXgrdyvBE5HzLDjY2EREROQUZWahcymlPF00D++An0aBxQ7t7tdEKyJyYYSEQHq6v6MQEREptZTgybkJrWz8zDwCKz42HmccoUWv9zGZYN/RTFJSs6gcHui/GEVERERELhPqoinnJqop3PoBdH4GGt1s7Es/SFigjcYx4QAs3XHYjwGKiIiIiFw+lODJuTGZoEU/6Pw0tLjT2JdtzJzZqX4lAH7betBf0YnIpSYrC3r1MrasLH9HIyIiUuoowZPzJyDM+JmTBkCnenkJ3raDuFxuf0UlIpcSpxNmzzY2p9Pf0YiIiJQ6SvDk/PEkeHkteG1qRBJit3AoLYeNial+DExERERE5PKgBE/OnwBjzJ0nwbNbzXSsUxGAReqmKSIiIiJywSnBk/OnYAueywVAp/pGgrd0xyF/RSUiIiIictlQgifnjz0074EbHMY6VR1rVwBgxa6jZOdqvIyIiIiIyIWkBE/OH1sQmCzG47xumnUrh1IxNIDsXBerdh/zX2wiIiIiIpcBJXhy/phMBbpppuXtMtGpntFNM35jsr8iExERERG5LCjBk/PrpIlWALo3jQbgl/WJuN1aLkFEzkFICLjdxhYS4u9oRERESh0leHJ+eVvw8pdF6FS/EsF2CweOZ7F233E/BSYiIiIiculTgifnlyfBW/ER/DoW1kwn0GbhuoaVAfh5faL/YhMRERERucQpwZPzK7SS8XPTj7DkLfhuKBzcQs+mMQD8vC5J3TRFpOSysuD2240tK8vf0YiIiJQ6Vn8HIJeYLi9A+drgzIW/voCMQ5C6n+sa1iHQZmbPkQw2HEiladUIf0cqImWR0wlffWU8njbNr6GIiIiURmrBk/OrYj24YTx0fwUqNTT2ZRwh2G7lugZGN81Z69RNU0RERETkQlCCJxdOUDnjZ+ZRAHo2M7ppzl6n2TRFRERERC4EJXhy4QSXN35mHgPg+oaVCbSZ2X04gzV7j/ktLBERERGRS5USPLlwgiKNn5lHAAgJsNIjb7KVmSv2+isqEREREZFLlhI8uXCCPC14R727+rWLBeCHNQdIz871R1QiIiIiIpcsJXhy4Xhb8PITvA61ylOzQjDpOU5NtiIiIiIicp4pwZMLxzMGL+OId5fJZKJfu+oAfLFc3TRFpJiCgyEtzdiCg/0djYiISKmjBE8uHE8LXvJ6mHYjfHoL7JhP3zZVsZhNrNx9lM1JqX4NUUTKGJMJQkKMzWTydzQiIiKljhI8uXAia4HJDI4M2LUY/l4AiydSOSyQ7k2iAXh33nY/BykiIiIiculQgicXTkRVeHAh3PYxXPessS/1AAAjutQF4Of1iSQdz/JTgCJS5mRnw6BBxpad7e9oRERESh0leHJhxbSApn2NDeBEIrjdNIwOp13NSFxu+HrVPv/GKCJlR24ufPKJseVqJl4REZGTKcGTiyPMWP8ORwZkG+PuPJOtTP19Jxk5+qImIiIiInKulODJxWEPhsAI43GqsTxC75ZVqFEhmENpOfxr4Q4/BiciIiIicmlQgicXT1gV4+cJI8GzWcw83b0hAP9e9De7DqX7KzIRERERkUuCEjy5eMKMmTP5/E54pRq8fyXd6wRyTb2K5DhdvDRrk3/jExEREREp45TgycVT82rjZ24W5JyAlA2Y9izlhZuaYDbBr5uSWbn7yNmvISIiIiIiZ6QETy6eTo/DqI3wyGqo393Yd3QXdSuH0rtlVQAGT1vBnsMZfgxSRERERKTsKlGCt3fvXvbty5/aftmyZYwcOZIPPvjgvAUml6iIqlC+NlRuZDw/uguAsTc3oUW1CI5nOhj5xWpynS7/xSgipVdwMKSkGFtwsL+jERERKXVKlODdddddLFiwAICkpCRuuOEGli1bxrPPPsv48ePPa4ByiYqsafzMS/Aigmy8N6A1YQFWVu05xuQF2/0WmoiUYiYTVKpkbCaTv6MREREpdUqU4K1fv5727dsDMHPmTJo2bcrSpUv57LPPmDZt2vmMTy5VngRv7zL45h/w3cNUS13LS7c2BWDSvG38sPaA/+ITERERESmDrCU5yeFwEBAQAMCvv/7KzTffDEDDhg1JTEw8f9HJpatiAzCZIesY/DXD2Jf4F72HLuH37YeYuWIfI2esJshm4YbGUX4NVURKkexsGD3aeDxxIuT9LhIRERFDiVrwmjRpwpQpU1i8eDHx8fF0725MmHHgwAEqVKhwXgOUS1R4DAz4Cm54Ea57ztiXsgGy03i1T3PuaFsNlxtGfL6KTxN2kZOrMXkiAuTmwvvvG1turr+jERERKXVKlOC99tpr/Pvf/6Zz587079+fFi1aAPDDDz94u26KFKluF7jqEbj2CQivCm4XLPsAy6bveaXNCa5vWJksh4sx32+g68RFrN9/3N8Ri4iIiIiUaiXqotm5c2cOHTpEamoqkZGR3v0PPvggwZrVTEqiahtI3Q/zxgFGxfyg/0w+b9iUSfO2sedIBg9/torJd7WiUUw4NotW+BAREREROVmJErzMzEzcbrc3udu9ezfffvstjRo1Ii4u7rwGKJeJq0dCThrkZkNaMhzejvWXp7inSkv61XHz7vZK/H60Ki+8t5Z0Szhxna5i2HV1CbRZCl8n/TAkr89/Xr4WhMWAyQJmJYUiIiIicmkrUYLXu3dv+vTpw0MPPcSxY8fo0KEDNpuNQ4cOMXHiRIYOHXq+45RLXdU2cM+3xuOju2BSazi6E47uxA48BjxWYC6F1UvqsnhxBIF2K+WC7aRmOwm2uGmeswqLM/vM9zGZjWTPZIaK9aBCXWOqdXsItLwbKtQxygVXALPlzNcRERERESmFSpTgrVq1irfeeguAr776iqioKFavXs3XX3/NmDFjlODJuYmsCYNmQdI643nqftj6C+Rm4c7NwXTiAK3MeevkOYEThU8/7g4myV0Bq8lJLVMiZtz5B90uYwOjpa9ga9/q/+U/rtwEbnkPrEFgC4LIGsb+nHSYNx7SUozn9mDoODx/4XYRERERET8qUYKXkZFBWFgYAHPnzqVPnz6YzWauuOIKdu/efV4DlMtUjY7G5nGDMTbPBHBgDc4DaziYmsW+oxkkH88gOTWTjKxc9mcH8nVWK3KwARBINnYcWHBhxo0572egKYd25i0Ek4UFF13Mq+ho3ojJhJEQpmyADzp7b58T3QZ7lSa4D23DtCehcKyr/wdV2xotgRUbwBVDISAMdi2BTT+AK2+mv/Cq0KAHWAMgJwNSNoLLmXesCrS8Cyy2C/N+ioiIiMhloUQJXt26dfnuu++49dZbmTNnDqNGjQIgJSWF8PDw8xqgyCmqtMRSpSXRQPRJh9xuN68Auw9n4HC6iN+UzG9bD+Jywd6jGSQez8orCLud+WdPdfbwPq5n2sdE2/tUNR3CBESa0rAnrYSklUaCCexqOoKtx9y02T+dCu4jsH+FcWDfclhToCXwZKs+OfOxHx8Bs80Izu3Oa2l0Q0gluPtrqNQwrwXSnVfGBZYAsNp9eddELg1BQbBzZ/5jERERKaRECd6YMWO46667GDVqFNdffz0dOxotLXPnzqVVq1bnNUCR4jCZjBSsZsUQAOpFhfFw57oAZOTkMv3PPew7msmxjByua1iZq+tW5O9D6Xy3ej/bU9KoXSmUb1aZuSnnFe81G5r2cL15Naa8rp6b3bHMW9EGgADa0tG8ASsuos1Hudc8h2qmQwCYbXZ2VOzCgfCWNKxkJ3LffEKzkjyBQqVGRkufIxM2z4Ls4+BynPqi0g/Cvzud/gVb7FCllTGm0OUEt9NoMXS5jHGFDbpDQN4fXUIrG/sA0g4aYx09alwJta4p7tstcvGZzVCzpr+jEBERKbVKlODddtttXH311SQmJnrXwAPo0qULt95663kLrqBXX32Vb775hs2bNxMUFMSVV17Ja6+9RoMGDbxlsrKyeOyxx5gxYwbZ2dnExcXx/vvvExUV5S2zZ88ehg4dyoIFCwgNDWXgwIG8+uqrWK35b8XChQsZPXo0GzZsIDY2lueee45BgwYViue9997j9ddfJykpiRYtWvDuu+8WWgPQl1jk4gq2W7n/mtqn7K8QGkC7muW9zx/rVt/YH2LHZDKx81A6Hy25mq3JadSPCiUtOY2ow+mEBdrYnpLGQlfeHzVc8D+65l84G0greKfB1I8KpUaFEI5nODi6O4eaFUOoVzmUylc+SlLiPlrViKRDrYoEBVj4NGEvtcJddF0xFI6doeuzMwf2/nnmF733D9/eHIDwamALNFoFq7UBW96SJxXrQ42rjElnbEEQUc33a4qIiIjIRVWiBA8gOjqa6Oho9u3bB0C1atUu6CLnixYtYtiwYbRr147c3Fz++c9/0q1bNzZu3EhIiNEqMWrUKGbNmsWXX35JREQEw4cPp0+fPvz+++8AOJ1OevXqRXR0NEuXLiUxMZF7770Xm83GK68YLTY7d+6kV69ePPTQQ3z22WfMmzeP+++/n5iYGO8SEF988QWjR49mypQpdOjQgbfffpu4uDi2bNlC5cqVfYpFSq+KoQGFnteqGMJLtzQ7bdmMnFx2pKRTLyqU9fuPM2P5XoLtFr5YvpfsXBfta5UnNdPB5iRjJpityWlsTc7P+ralpBG/MTn/gmuSsFtSMJkgO9eYDMbMy1SwZdO6RgUaRIXRrlYFjmflsv9YFj2jjhPlSsRmtXE820VwYCAWizFLqOXAyvxJZNxuSD0AzrwWQmuAMTGMxQaHtsGuxZC6Lz+OlA1nfoOqd4SoJkZL4d7lkHnU2G+2QtVWYDfG55or1MXkrl7U2y1SPDk58OyzxuOXXwa7uiiLiIgUZHK73e6iixXmcrl46aWXePPNN0lLM76shoWF8dhjj/Hss89ivgjrjR08eJDKlSuzaNEiOnXqxPHjx6lUqRLTp0/ntttuA2Dz5s00atSIhIQErrjiCn7++WduvPFGDhw44G1JmzJlCk899RQHDx7Ebrfz1FNPMWvWLNavz59d8c477+TYsWP88ssvAHTo0IF27doxefJk7/sRGxvLiBEjePrpp32KxRepqalERERw/Phxv49tdDgczJ49m549e2KzaSKQohw4lkmQzUJkiB23203KiWz2Hc1kybZDJKVm0bp6ObIcTtbsPc6uw+nk5LrYfTgds9nEsYzTdNMsQsXQAA6lZRMWYOVEdi6x5YP414A2NK0agcvlxmw2ecs6XW5STmQRE1Fg/NLBrZBx2Hicuh9SNhmPc9Jh689GEufG6EZaTG6TGZMlAJrfDg16Aiaju2hMS6OrKuT/lMuaT58z6ekQGmo8TkuDvD/wyeVJv5ukuFRnpLhKU53xNTcoUQves88+y0cffcT//d//cdVVVwGwZMkSxo4dS1ZWFi+//HLJoi6G48eNL5rlyxtd61auXInD4aBr1/wucg0bNqR69erepCohIYFmzZoV6iYZFxfH0KFD2bBhA61atSIhIaHQNTxlRo4cCUBOTg4rV67kmWee8R43m8107dqVhIQEn2M5nezsbLKz89dwS01NBYyK5XAU/0v/+eS5v7/jKCsqhRj/a3ner/JBFsoHhdK8Smihcne2rVroudvtZv7mgyzYepD+7WJJOZHNpPk72Jx0glyXm+rlgzh4Ipuo8EDCAq2s22/UkUNpRr05kW3M2Ln3SCY3vrsEAJvFRFRYAC1iyxFst7B273G2pqRRr3IIL/VuQuvq5aBcLShXi6TULMpXbo29Ye/8oLq+mP84cS3m7XO9S024w6vhjmoCmDBlHMaUvB5wQ3oK5jXTMeWcwOR2QW4mrPrU2E7iNttwtRmM64phAJhOJEHmEeOg2Yq7ekejxVEueT59zjgc2AqW12fSZU2/m6S4VGekuEpTnfE1hhIleJ988gkffvghN998s3df8+bNqVq1Kg8//PAFT/BcLhcjR47kqquuomnTpgAkJSVht9spV65cobJRUVEkJSV5y5w8Bs7zvKgyqampZGZmcvToUZxO52nLbN682edYTufVV19l3Lhxp+yfO3cuwcHBZzzvYoqPj/d3CJeFK22we40x7u6BGkANz5ETuN1gMuXgdsOGMBPHsiHXDS43rD1sZlda4dYwh9PNvmNZ7DtWuO5tS0mn33+WUTHATa0wN0mZJvam501SE+rGbnHTvpKbthXdJzWwNcl/mAYcOFDgWN28n/UwN2qHzZkBQPTx1cQeWYLZ7cTkdhGadQCrOwcAk8uBZfm/sSz/92nfiwxbebZF3YTLbCXbGkFyeAu1+F3izvY5Y8nK4sa8x3PmzMEZGHhxgpJSTb+bpLhUZ6S4SkOdycjI8KlciRK8I0eO0LBhw1P2N2zYkCNHjpTkksUybNgw1q9fz5IlSy74vS6mZ555htGjR3ufp6amEhsbS7du3UpFF834+HhuuOEGvzdPS75ep9mXk+vCbjXz27ZDJKdmExpgYVPSCRxON0E2MxVCA9h1KJ1pCXsAOJRt4lB24YTJSBJNbD0OCw4FcizDQaWwAG5vU5V7OlTnr/3HaRQdRpDdgs1y+i7ZhevMXYWOuXOzceQY3bvNqz/FnDAJHHlLWASEGWsGAqbkdQQ7jtBiX/7yEs6413DV7mw8Ca8KVn3Bv1T49DmTnu59GBcXpy6alzn9bpLiUp2R4ipNdcbTu68oJUrwWrRoweTJk5k0aVKh/ZMnT6Z58+YluaTPhg8fzk8//cRvv/1GtWr5s/lFR0eTk5PDsWPHCrWcJScnEx0d7S2zbNmyQtdLTk72HvP89OwrWCY8PJygoCAsFgsWi+W0ZQpeo6hYTicgIICAgFO7otlsNr9XKI/SFIucnuefp0vjGO++m09T7p+9mrB420Gyc11sOHAcu8XChgPHmbuxcN3ef8xIvNIPZ/D63G28PndboeMVQuzUqBBMhdAAhnauQ6vYchQc2XvaOmOzQVBed9XOTxrb6ST+BUveMsYCZhyC/SuxzHkKi+e42WosFQEQUhHaDoZyeRO7xF4BEVVPd1Up5c76OVNgv81mK/RcLl/63STFpTojxVUa6oyv9y9RgjdhwgR69erFr7/+6l0DLyEhgb179zJ79uySXLJIbrebESNG8O2337Jw4UJq1apV6HibNm2w2WzMmzePvn37ArBlyxb27NnjjbFjx468/PLLpKSkeGe7jI+PJzw8nMaNG3vLnPwa4uPjvdew2+20adOGefPmccsttwBGl9F58+YxfPhwn2MR8Te71UyXRkZX457NYgody3W6sJhN7DuayeakE6zYdYSf1yeRdDyLHKerUNnD6TkcTje6W8ZvTMZkAqvZRMfa5ck4ambhN+upWzmM+lFhtKpe7pRZSs8qpjncPtV47MiCz26DxLXGc1cuODKMnwDH9sCvY/PPjawJw1cYM4WKiIiIXCZKlOBde+21bN26lffee8877qxPnz48+OCDvPTSS1xzzflfMHnYsGFMnz6d77//nrCwMO9YtoiICIKCgoiIiGDIkCGMHj2a8uXLEx4ezogRI+jYsaN3UpNu3brRuHFj7rnnHiZMmEBSUhLPPfccw4YN87acPfTQQ0yePJknn3ySwYMHM3/+fGbOnMmsWbO8sYwePZqBAwfStm1b2rdvz9tvv016ejr33XefN6aiYhEpzax53S5jywcTWz6YGxpH8UzPRrjdbg4cz8JmMbEjJZ19RzOIDLZzNCOHMd9vINPhxO02xv39tu0wYGbFofwxegFWMwOvrEmFEDux5YOJiQikVsUQygX7MNW9LRAG/ZT/3LP0gyvXWP5h1TQ4sMY4lrjWWMh9YiMw2yAwHO74FCo1OM2FRURERC4dJV4Hr0qVKqdMprJ27Vo++ugjPvjgg3MO7GT/+te/AOjcuXOh/VOnTvUuQv7WW29hNpvp27dvocXFPSwWCz/99BNDhw6lY8eOhISEMHDgQMaPH+8tU6tWLWbNmsWoUaN45513qFatGh9++KF3DTyAfv36cfDgQcaMGUNSUhItW7bkl19+KTTxSlGxiJRFJpOJquWM5RUqhwUCFbzHrqlXiVV7jtKsagSZDie/bkxk46bNhEbVICk1m4Qdh8nOdfHBb38XumagzUyPpjHUqhjCjc1jqF2p8EyjZwmmcBfMbi/lP172H5j9OKQfNJ6fOAC/joOrHjWeRzcDe+mYuEiKKSgIPMvYBAWdvayIiMhlqETr4J3J2rVrad26NU6n83xd8rKmdfCkLDu5zmTnOvlk6S62p6SRneti9+EM9h7J8HbvBDCboEF0OM2qhvPANbWpFxV2yjp+PnG74fAOcKTD0d0w857Cx4Mioc19YAs2JnVpfa8SvlJAnzNSXKozUlyqM1JcpanOXNB18EREiivAauHBTnUK7XO73czblMJv2w6y81A6i7cdYlNiKpsSU/l61X7qVQ5le0oaD3euwwOdahMW6OMHq8kEFfOWbIhpAe3/Advzpjc+8rexcPuSifnls45B56fP/UWKiIiI+JkSPBHxG5PJRNfGUXRtbHRv3p6SxsT4Lcxel4TT5WZz0gkAJs3fztTfd9G6RiSNYsK5rU01yofYiQiyYfGlda/nhPzHaSnwx/uQcQTSkmHrL7BiKmQb96LWtVC/2/l+qXK+5OTAK68Yj//5T7D7MH5TRETkMlKsBK9Pnz5nPX7s2LFziUVELnN1K4fy/oA2ZOY4WbAlBYD5m1P4dVMyxzIcLNp6kEVbDzJl0Q4AWlUvx/ibm9IgOgy79fTr8Z0itDJ0HWs8zkmHNxpAWhIkTDb2LfsAHt9qdOOU0sfhgHHjjMdPPKEET0RE5CTFSvAiIiKKPH7vvfeeU0AiIkF2i3fphp7NYnC53Pzx92FW7TnKwi0HWbf/ONm5LlbvOcZNk5dQKSyA7k2iuaVVFVrGRvrWqgdgD4H+02FbXvfNDd/B8T0w+wmoWN8Yo9f6Hgg8+2efiIiISGlRrARv6tSpFyoOEZEzMptNXFm3IlfWrcjw6+vhdLn5c+dh3pizha3JaRw8kc1//9jNf//YTZMq4bzdryX1osJ8u3itTsYGEFQO5o2HdV/mH09PgRvGn/ZUERERkdJGY/DEJ06Xk1x3rr/DEAHAYjZxZZ2KfPNwRXJyXczblMzXq/azcEsKGw6kEvf2bzSuEk6dSqF0qFWBuzpU9+3C7f9hjMXLPGaM1dsyC9Z/C9XaG8ejmkD5WhfsdYmIiIicKyV4UqSFexcyYv4IqlmqcTM3+zsckULsVjM9msXQo1kMB45lMvaHDczdmMz6/ams35/K92sOkJ6dyw2No6hZMeTsFwsILTw+b0Ido8vmFwOMfUGRMHqzsei6iIiISCnk46wEcjmzmY2p6Z1ofUMp3aqUC+KDe9sy65GrefnWpkSHG4nYy7M30fmNhTzw6Qr2Hc3w7WL2EOj+CsReAbEdwBpkLK+Q9NcFfAUiIiIi50YJnhTJm+C5leBJ2dCkSgQDOtRgyVPXcVXdCt798RuTufq1BQyetpyMHB+6HLcdDEPmwJC5ULuzsW/3UsjJgNycs54qIiIi4g9K8KRIdosxDbla8KSssVrMTLuvPT8Ov5rHbqjv3T9/cwo3T/6dT5buwuly+3axam2Mn7++AK/EGNu6ry5A1HJWgYGwbJmxBaqrrIiIyMmU4EmRPC14mmRFyiKbxUyzahGM6FKPt/q1oFFMOGAsqv7CDxv4x39XcCzDh9a4RjdDQHj+c1curJ1xgaKWM7JYoF07Y7NY/B2NiIhIqaNJVqRIVrNRTdSCJ2Xdra2qcWuraqSkZjFzxV4mzd/Or5tSaPPSr9xzRQ2e6t6QIPsZkoZKDeDJneDMhuQN8NENsOcPOLobTGZjAXVrwMV9QSIiIiInUQueFEldNOVSUzk8kOHX1+ODe9pQt3IoTpebaUt30WjML6zbd/zMJ1qsxuQrVduAPQxyTsA7zeHtpjC5LeRmX7wXcbnKyYHXXze2HI2DFBEROZkSPCmSumjKpapzg8r8OvpanunR0Ltv2PRVzPorEbf7LGPzzBbo8A+wBYM1bxzYsT1wcPMFjlhwOODJJ43N4fB3NCIiIqWOEjwpkpZJkEvdP66tw+xHrqF8iJ09RzIYNn0V437cSK7TdeaTujwPzybCc8lQ/Upj38EtFydgERERkTNQgidF8nTRdOHC5T7LF16RMqxxlXDmjOxE39bVAJi2dBc3vruELUknij65Ut4MnUrwRERExM+U4EmRPC14AA6XukTJpatSWABv3tGCJ+IaEB5oZXPSCW5573d2HUov4sS8Lp6rPoWpveC/fWDfygsfsIiIiMhJlOBJkWwWJXhyeRl2XV3mPdaZlrHlyHQ4eX3OlrN316zW3viZngK7l8COebBk4sUJVkRERKQAJXhSpEIteE4leHJ5qBQWwAs3NQZg1rpEbpuSwNH0M8zaWK0NDJ4Lt0+D65839iWuvTiBioiIiBSgBE+KZDaZsZqMtfDUgieXk1bVI3m7X0vCAq2s2XuM4Z+v4siZkrzqHaDJrdD+QcAEx/fCph9h+zw4svOixi0iIiKXLyV44hNPN00leHK5uaVVVT4d3B6TCX7ffpi+/1rK4bSzrHcXGA4V6xmPv7gb/tcH3u8IaQcvTsCXusBAWLDA2AID/R2NiIhIqaMET3zi6aaZ49TCwnL5aVU9kg/vbUtUeAA7D6XzzDfrzr5O3rVPQUxLiG4G9lDIzYS9f160eC9pFgt07mxsFou/oxERESl1lOCJTzwJnlrw5HLVpVEU0+5rj81iYu7GZMb9uJHs3DOsDdnsNvjHInhoidFtE+DAqosXrIiIiFy2lOCJTzwJXq4r18+RiPhPo5hwnutlTLwybekuxv+4seiTqrY2fv4xBd5uDu+2hY0/XMAoL3EOB7z3nrE59AcnERGRkynBE594u2i61EVTLm8Dr6zJi7c0BeCzP/cwc8Xes59Q61owW8GRDsd2w+FtkDD5IkR6icrJgeHDjS1Hn0ciIiInU4InPtEkKyL57rmiBje1qALA01//xeak1DMXrlAHHl0LQ36FOz839u1fBY7MixCpiIiIXG6s/g5Ayga72Q5okhURj7f7tSQjO5d5m1N48aeN/G9IB0wm0+kLR1QzNrcbQqMgLRkmtzNa9iJrQptBEBQJZgtUaQ324Iv5UkREROQSogRPfGI1G1VFY/BEDBazibE3N2Hx9kP8vv0wX67cxx1tY89+kskE9bvDqk+MdfIAju6Evxfkl6l1LXR9wXgcGmUkhiIiIiI+UoInPrFbjBY8ddEUyRdbPpgR19Xlzfit/PObdYTYrfRqHnP2k3q9CW0GgssJmcdg5TQjyQM4vAN2LoL/XG88N1vhwYXGcgsiIiIiPlCCJz7ROngipzfsurrsPJzON6v2M+LzVYQEtKNzg8pnPsFig6pt8p/X75b/eO0MWPiqkfxlp0LWcfjmHxDVxOi+2bQv1O5slDVZwKxh1CIiIlKYEjzxidbBEzk9s9nE67e1ADd8s3o/Y3/YwNxRFbFbS5B8tbjT2AAS18K/O0HKBmMDWPt5ftmgSLjvF6jc8NxfhIiIiFwylOCJT5TgiZyZxWxi/C1N+W3bQXYdzmDWugPc2uocx87FtIABX8PBzcbzvX/A5lngdhnPM4/Cf2+FiKqAyej22eruc7tnWRAQAD/9lP9YRETkfHJkwY754MgAwOTMJSgn3c9BFY8SPPGJEjyRswsNsDLoypq8MXcrHy7eSe8WVTGbzzCrpq/qdTU2AIZDTjo4HZB6AP5zHZw4YGwAKZugSZ9LfwZOqxV69fJ3FCIiUpYd3gHLPwTP0KPsE5CVt+TRgdWQluQtagXK13z44sd4DpTgiU+U4IkU7a4ONfjXwh1sOJDKFyv20r999fN7A3uI8TOoHDy0BA5tNZ7/8jQc2wNvNwWL3ei+2bg3BJYzjte5Dio1OL+xiIiI5ObAltlGrxKAo7vg0Lb84xFVIbii8dgWCLWvg8AIOJEIyz+C9IPGMWsgXP+sMamYywVrPss/ZgsyxqCHVob0Q/DVYOMPnQAms7HcUN56zQRXgAp1jVmrnQ5I3Z/f8yWkEsS2NyYwmzce9q888+syW6F6RzCZcbndZFvDz8e7ddEowROfaBZNkaKVD7Ez/Pp6vPbLZp77bj01ygdzZd2KF+ZmFesZG8CRnTD3Wcg4bDw/kQgpG/PLhlWBkevAcgl85Dsc8NlnxuMBA8Bm8288IiIXm8tpjNP2LF1VrgaERRmP3W7j8z8323h+IjH/d4PJDDWuNMqDMZNz1jHj8fF9sOVnyM0yngdGQM2rjT8a7loCyz4wJv8CsIca17EGwP7VcHzP+Xldqfug/YNGC9qKjwsfm/scVGwAmUeM11TQoS0lu58tGK4cAZiM5DOovJEYmsxQ53oIrwKA0+Hg0OzZJbuHn1wCv+3lYvCsg6dZNEXO7sFOtdmclMr3aw7wyIw1fP5AB+pFhV3Ym3YcBvXjwJFp/MLfMT8/wdv+q9GNc/odxi/skIpw9WgIizb+qunKzd/MttLfxTMnB+67z3h8++1K8ETk4sg8Bknr8p+HV4GAvFYdi83oWVGUY3vhu6HGtcBomWp+B0Q3B2c27FxsJDBgdB1MS8k/N7iisS6q2wUbvoHD2/OPma3QvJ+xdurWOfkTc52r398+/f7sVNj6S+F9dboYr8caCNXaGcmf22V0hczNNBLPg1sgcU3+OTEtjYnFLDaY9Zjx/v4wIv94wxuN31vb5hqteZ7XZQmAPh8YLXK5WXBst3F93HD47wIJrQnCqxpJqtsF+1cUbvnr8A9ofe+5v0+lkBI88UmAxZjMQAmeyNlZzCZe7dOMLUkn2Jx0gof+t5KfH+1Uslk1fWUy5bfmAVRtnf/417Gw5C3YMS9/37IPznAdC9w5HRp0vyBhiohcdKmJsPknIxFwOTE7c6mftAnz4o3gzoXD24wWMcgbh3U8/9zKjY2kKicNVn1q/DyTgHDjsxigVie4bZrRa2LlJ7D+KyMBObbb6E5f0L5lJX9tkTUh7SA40o0ujQWF503AFRgOEbFGbGkpcGBV4XL2UKOcp3WvSitjf9JfcOTvvEIm4/dCuweMpwc3F04wa3cu/DuoJGzBxlJBuI3n0c3hun8acTsyYd8KcOf9O5WrDuVrn9v9LnFK8MQn3nXwXErwRIoSbLcy/YEruGHiInYcTGfa0p082KmOf4Lp9KTxizAnw5gRbOXUU79geLidMPtx2Pyj8TymJTToafzitwX59hdqEbk87F5q9BDwqODpNm4yWmQq1jdallwO2P27MYGF22Wcs2N+/rioqKbQ/gEICIOUzbB7ibHfZM5b79OS/9MWbFzbZILj+43uhSYz3gTFZAbcRvfFk7vx5bEAjQBOf7iwgq1NYPRyqFDHiP3orvwJOiC/+yLAph9hQi2jm6Qzu/A1bMFw67+N3hJb5xR+LyJrQtW2+a8lLMp47biN+3mST2ug0fJUqYGRnK6cCofyEi6LFVr0N9ZPPZ3sE8bYNM91StJrIzzGGNt9PjW5xdhOxxYEta45v/e7xCnBE5+oBU+keMqH2HmqR0Oe/Oov3vl1G71bViUqPPDiB2IPLtwF5apHIS3Z+OJlthpfmsxWIwF8tzUc3wur/2eUXf0/I+ED40tGs9ug+hXG88pNoHqHi/taLmVut/Hee754BVc4/wn1rt+NL75gfEFu0MP4Qnm5c+bC3wuNbmRgtMTU6pTfGnMytzv/ccEyngkdPMKqgNV+fmN1OY3WDDBaV7bOMRIoMFpsWt5lJEA7f4Pf3sgvG1rZOBZU3ngeWdNIqHDndenOW44lJw32/JGflFjsRrc/MF73iQPG+5WbWbgF51z8vcDYLqSopsZmMuPCxJ59+4itXgOLxQbla+W1YmF0KwyumNdqlAF7l+UncSGVjPFhp/v/MvsEnEg2Hu9aDD+NLJDwmaDZ7fk9I6Ka5k96VbfryVcqPrMF2t3ve/mACzxkQEoFJXjiE88kK0rwRHx3W+tqfL5sD6v3HOPFnzYy+a7WRZ90oZkt3oHjhdhD4N7v4O9FxvO0FFj3pfEXcleu0br31xfG5mUyrmcJgLpdjC+RACGVjb/wgpE8RjcDaxDgNv5S7c77efLzwArn5zWmH87/gmoLLvyFLPNYfhJlC4KAvC92jixY/7UxE5zJnNdqYM5vPYhpAVVaGmWP78sfi3MiEVZ/Bul5Y2Xcef/xJAFh0RBZI/81ejYwZjuNqGYc2zbHmFjAwx4K93xndEU6vtf4Auxy5f1l31Q4xoCw/C+oBzcb8YGxrMb+lcYXVGdO4a5nAAtfNb6wupzGv6/bZdzD7TL++h/VxHi87iujBcYjsgZE5M0Qaws0JiMIrmC8TyYzmE/T8uLIhI3f5Y8p8oyX8fwsuM9kMWa6C6mU9x7GQMW6ef+2hwolNSZLEOXTdmPaW95ouQiLMuqj22nU5SM7yCtozMIX1dh4npoIyXnjeTZ8c2r3tpsmGWtL5mYbY42yUo17/jUT9iTkl6vXDW5+17j+jLsKd7cLrghNbjWShpNFNzPGHgFs+A5WTis8019kDcBk3DMtxXhvnDlGPfDMVng6Pz5itMp4JsooaPNPZz6vpKq1h6ptjPvt+cOocwDZxwvXt+AKUKmRUXdtQcZ4scqNjYT4j/fzx0VZbFD3BuMzyu3Kr5sup/E55MjM/387KNJIak/5PHEZ96vWzvj8MZkhuLw3FKfDwdrZs6nasyeWosbwNu7t2/sQEJafOFWsC/W753fnDAgzPgdELiIleOITuzkvwVMXTRGfmc0mXuzdlJsnL+GnvxK5tVUyXRpF+TusM6vaxtg8evxf/uO/voRN3xtfpnLSjMkA3M78CVo2/XDOt7eazFwbWB1LyqS8PQUSpaByxhfCbFf+CYteh+BAoyXD8wUx8ygkry9wVZPxZdlsNabzLjjbm8liJKZB5Y1Z4lL3nfNrOEXqPmNgv6/soUYCmpMGH52Hv+6frHZnI4E4sMYYe/Tb68W/RtJfhZ8vfvN8RFbYn/8q/Dwsxugel7o/fxwOxpeYawC2UbTFbxhf2N0uY7ZAzwyEHtXaG+97ykaY88+8xCPRSFbOZNtceLPAEiQms/HHDEc6ZByC5f8587nb5xl/YFg7w7ugcrHVvAYqNTTO3/Sj0WrkSe6qXwlXPGTUpw3fGmtlgpE0FuymbQuBhj3zE5SoJlCupvE4Jy1/0g8w6o53uZZIoxv36Vo6Xa7C71tAuJHonyyqMdS7oSSvvHTz/IFLxE+U4IlP1IInUjJNq0Zw/zW1+eC3v3nmm3V8/mAIdSqF+jus4mt+u7F5ZKXm/4U6ZRPsW57fAnPkb8jOO5Z5JL/7l4mTxsuY8h+7HJgyDlMucxfs33X6GHbMh5wC3eOWTAT7GbrRmW1GLK5cY+zK6bidxhf0ghr0NFr9PK0GbpfRErH79/wWFjCSTVve2JXoZkYXLGtg/uvElD9defaJ/DE1ntY3k9mYcMGzsK41AFoOgOimRlIxtUd+3GaL8UW+fK0CrRru/FlQs1PzW06CykGV1nktFyYjTk/rQVD5/C+eJ5Jg6bvGl/+CrYEms9FKsmN+ftIRGAGt7jHGVLlyjdZLR3rerHibYf+q/FZet7twq4unZRAgspbRLdRi87xJBepAgZ9pyXkTKriM+I78XXg8VXg1o0UVcJ1IIuPwPkJCQjC5Xcbr8twvuCLU72YkXOu/NlpZN36ff52g8kYLKkDTPnD1qPyuyicSjdcGxr9zjSuN9zQwwphoonxto3X0h+FGvJA/s1+TW4z6v3Jq/jpeBR3eYbSmrZuZv69aO+jwkPH+Hd6WP8uiyWy0jOfNZE1EVagXl//vVbB1sNeb+fczWwu31De7rXAMudn5E4tY7Od/CRWz2UgARcQvlOCJTzQGT6TkRnWtz9wNSew6nMHtUxL4ZeQ1VA7zw3i88ykw3NjA+CJZt8s5X9KxZwWrFvxAmzZtsFpt+V/6wRjvk5YEuU54ZpPxRfiK2mDGaHnIG1+DyWS0xJSLNc47vs+YmtyjYj1jqQgwxqQVnFGubleo3Oj0wWWn5Y9nstqNL/q+qNam6DInC4+BR9cU/7ziCIuGuJdLdm5xZ1l157XEmkynb+0pyvH9xr89GIlL5SbehMTpcDBv9mx69uyJ7Wzd7a5/zuhynH3CeB4aZSR1lpPOsQfDPxbDwU35+6KbnT5Zqd8NHtuS38pc8PUFhOatr3UazlxY9Ul+MmaxQYu7zr3VxxZkdOn1xem6jYrIJUMJnvjE00Uz25VdREkROVmQ3cL0B65g4MfL2JaSxnPfruff97TBVJIvu5eymBYklduPu0HPs69v17MY14yolt9Kc7KaVxmbLwJC88frSfGUNLHziKhqbOciIBTa3udb2dBKxuaLkrw2ixXaDSneOSIixXABF2aSS4m6aIqcmyrlgnjnzlbYLCbmbkzm+zUH/B2SiIiIXIKU4IlPlOCJnLvGVcJ55HpjMdiRX6zhw8V/F3GGnCI3F7780thyc4suLyIicplRgic+8SZ4mkVT5Jw81LkOnRsY3b9emb2JlbvPMuW5nCo7G+64w9iy1WVcRETkZErwxCfeZRLUgidyTmwWM1MHtaN3yyq43HD/J8tZvO00M+2JiIiIlIASPPGJumiKnD8mk4nxNzclJiKQoxkOhkxbwZJth/wdloiIiFwClOCJT7zLJKiLpsh5ERFs4/thV9G+ZnlynC7u+fhPvlu9399hiYiISBmnBE98YjMbU5arBU/k/KkcHshHg9rSq3kMbrcx8cojn68mNcvh79BERESkjFKCJz7RQuciF0ZYoI1Jd7bi3o41MJngh7UHuPvDP9mclOrv0ERERKQMUoInPvGMwct15+J0Of0cjcilxWI2Mb53U754sCNWs4m/9h2n+9uLufq1+Yz7cQMOp8vfIYqIiEgZoQRPfOKZRRM0Dk/kQmlfqzyfDmnvXUZh39FMpv6+ix7vLGbGsj1+jq6UsNth6lRjs9uLLi8iInKZKVMJ3m+//cZNN91ElSpVMJlMfPfdd4WOu91uxowZQ0xMDEFBQXTt2pVt27YVKnPkyBEGDBhAeHg45cqVY8iQIaSlpRUq89dff3HNNdcQGBhIbGwsEyZMOCWWL7/8koYNGxIYGEizZs2YPXt2sWMpSzwteKBumiIX0pV1KjLtvvb8+c8uTOjbnIggG9tT0nj6m3X838+b2ZZ8wt8h+pfNBoMGGZvN5u9oRERESp0yleClp6fTokUL3nvvvdMenzBhApMmTWLKlCn8+eefhISEEBcXR1ZWlrfMgAED2LBhA/Hx8fz000/89ttvPPjgg97jqampdOvWjRo1arBy5Upef/11xo4dywcffOAts3TpUvr378+QIUNYvXo1t9xyC7fccgvr168vVixlidVsxYQJUIIncjFEhQdyR7tYfnvyOu5oWw2AKYt20O3t33h0xmqWbj+E2+32c5QiIiJS2lj9HUBx9OjRgx49epz2mNvt5u233+a5556jd+/eAHz66adERUXx3Xffceedd7Jp0yZ++eUXli9fTtu2bQF499136dmzJ2+88QZVqlThs88+Iycnh48//hi73U6TJk1Ys2YNEydO9CaC77zzDt27d+eJJ54A4MUXXyQ+Pp7JkyczZcoUn2I5nezsbLKzs73PU1ONSRYcDgcOh39n1XM4HFix4sBBenY65Wzl/BqPlH6eOuvvulvWBVvhxZsa0bJaOLPXJ7Nk+2G+X3OA79ccoF3NSK6pW4F7rqhOaECZ+jg/LZ/qTG4uprlzAXB36wbWsv+6peT0OSPFpTojxVWa6oyvMVwyvxl37txJUlISXbt29e6LiIigQ4cOJCQkcOedd5KQkEC5cuW8yR1A165dMZvN/Pnnn9x6660kJCTQqVMn7AXGdsTFxfHaa69x9OhRIiMjSUhIYPTo0YXuHxcX5+0y6kssp/Pqq68ybty4U/bPnTuX4ODgEr0v55PVZMXhdhC/IJ7Klsr+DkfKiPj4eH+HcEkIAW6vBLFuEzP/NuN0m1i+6yjLdx1l+u/biKvmomUFN2aTvyM9d2erM5asLG7M+wz9acYMnIGBFyssKcX0OSPFpTojxVUa6kxGRoZP5S6ZBC8pKQmAqKioQvujoqK8x5KSkqhcuXBiYrVaKV++fKEytWrVOuUanmORkZEkJSUVeZ+iYjmdZ555plDimJqaSmxsLN26dSM8PPwsr/7CczgcvPbVawB0vLojDSIb+DUeKf0cDgfx8fHccMMN2DRW6rzpCYwHNhxIZdHWQ/xnyS6SMnP5ZJuF1RnhTLyjOTXK+/8PQiXhU51JT/c+jIuLg5CQixSdlEb6nJHiUp2R4ipNdcbTu68ol0yCdykICAggICDglP02m83vFQqMFjzckEtuqYhHyobSUn8vNS1rVKBljQrc0b46M5bt5aMlO/lrfypd31pCl4aVefOOFpQLLpuzTJ61zhTYb7PZNNGKAPqckeJTnZHiKg11xtf7l6lJVs4mOjoagOTk5EL7k5OTvceio6NJSUkpdDw3N5cjR44UKnO6axS8x5nKFDxeVCxlkQ2jUmU7s4soKSIXS0xEEKNuqM93w64iMtj4f3Te5hSueHUej3+5lm9X72P/sUw/RykiIiIXyyWT4NWqVYvo6GjmzZvn3Zeamsqff/5Jx44dAejYsSPHjh1j5cqV3jLz58/H5XLRoUMHb5nffvut0CDG+Ph4GjRoQGRkpLdMwft4ynju40ssZZHNpARPpLSqWzmUhGe68N2wq6hVMYQsh4uvVu5j1Bdr6fLmQv757Tr+PphW9IVERESkTCtTCV5aWhpr1qxhzZo1gDGZyZo1a9izZw8mk4mRI0fy0ksv8cMPP7Bu3TruvfdeqlSpwi233AJAo0aN6N69Ow888ADLli3j999/Z/jw4dx5551UqVIFgLvuugu73c6QIUPYsGEDX3zxBe+8806hsXGPPvoov/zyC2+++SabN29m7NixrFixguHDhwP4FEtZ5GnBy8xVa4BIaRRos9Aythy/jr6Wrx7qyB1tq1ExNIAsh4vpf+7hxneXMHtdopZXEBERuYSVqTF4K1as4LrrrvM+9yRdAwcOZNq0aTz55JOkp6fz4IMPcuzYMa6++mp++eUXAgvMsvbZZ58xfPhwunTpgtlspm/fvkyaNMl7PCIigrlz5zJs2DDatGlDxYoVGTNmTKG18q688kqmT5/Oc889xz//+U/q1avHd999R9OmTb1lfImlrFELnkjZYDGbaFuzPG1rlsfhdLFgcwr/Wfw3y3cd5eHPVtEythyDr65F0yrh1K4U6u9wRURE5DwqUwle586dz/qXZ5PJxPjx4xk/fvwZy5QvX57p06ef9T7Nmzdn8eLFZy1z++23c/vtt59TLGWN1WRUl6zcsrlYu8jlyGYx061JNJ3qV2LSvG1M/X0Xa/Ye45HPV2Mywcgu9bmxRQy1K4ZgMpWBNRbsdpg8Of+xiIiIFFKmEjzxL08XTSV4ImVPoM3Ck90bMuiqmrw3fzufJOzG7Ya3ft3KW79upUFUGM/2asQVtStgt5bi3vs2Gwwb5u8oRERESq1S/FtcShtPF80spxI8kbKqclgg43o35e9XevJsz0a0r1keq9nEluQT3PvxMq5+bT7T/9zDlqQT/g5VRERESkAteOIzteCJXDrMZhMPdKrNA51qk3Iii9d/2cLcjcmknMjmn9+uA6Bzg0o8EdeAJlUi/BxtAU4neLrQX3MNWCz+jUdERKSUUYInPtMkKyKXpsphgbx+ewteyM7ljTlbWL//OGv2HmPhloMs3HKQ7k2iGX59XRrFhGMx+3mcXlYWeCbbSkuDkBD/xiMiIlLKKMETn3m7aKoFT+SSFBpgZezNTQDYdSidifFb+WHtAX7ZkMQvG5IIC7TyfK/GxDWNJiLI5udoRURE5HQ0Bk985umi+dW2rxgyZwjHso75NyARuWBqVgxhUv9W/DLyGjrWrgDAiaxcnvz6L1q/GM+AD/9g6fZD5Dpdfo5UREREClILnvjMs0yCy+1iWdIyJq2exJiOY/wclYhcSA2jw/nvkPas2nOMeZuT+XVjMjsOpvP79sP8vv0wlcMCuL5hZTrWqcBNzatg9ncXThERkcucEjzxmacFzyMxPdFPkYjIxWS1mGlfqzzta5XnmR6NWLr9EE998xf7j2aSciKbGcv3MmP5Xj5cvJMBHarTuUFloiMC/R22iIjIZUkJnvjMMwbPI8OR4adIRMSfrqxbkcVPXk+Ww8kffx/m29X7+XHtAdbtP87T36zDYjbRqV5FnruxMXUqhfo7XBERkcuKEjzx2ckteOmOdD9FIiKlQaDNQucGlencoDKPdKnH7L8Smb0+iU2JqSzYcpA//l5Cncoh3NyiCvd2rEmgTUsaiIiIXGhK8MRnp7Tg5aoFT0QMdSqFMqJLPUZ0qcemxFRGfL6a7SlprN+fyvr9qUyev51bW1Xl7itqUC8qrOQ3stlgwoT8xyIiIlKIEjzxmWeSFQ+14InI6TSKCeenEVeT8Pdhlu08wg9rDrD/WCafJOzmk4Td2CwmrqpbkYl3tKR8iL14F7fb4YknLkzgIiIilwAleOIzO4W/iGXmZvopEhEp7QJtFq5rUJnrGlTmiW4NWLL9EP/7YzdzNybjcLpZuOUgV/7fPCqGBnBNvUq8cFNj1IFTRETk3CnBE5+d3EVTCZ6I+MJsNtGpfiU61a9E4vFMNiee4NEZq0nNymXf0Uw+X7aHb1btIzLYRiWLmZqtUmkeWx6T6TRLLjidsGqV8bh1a7AoLRQRESlICZ74zG46tSuV0+XEYtYXLBHxTUxEEDERQfz25HWs35/KgeOZvDp7E0czHCSlZpOEmd7v/0HVckFEBNl4tlcjrqpbMf8CWVnQvr3xOC0NQkL880JE/r+9+46Tqrr/P/6aXnZme1926Sy9KAhrNxZU1BhLNLEQvyZRozFqYjTNaIyJMb+0r9GYqin2lq8KGgk2RDrSYel9e5vZ6eX+/hgYGEEEhd1leT8fj3147z1n7nzOcNzdz55zzxER6aGU4MlBc+DY51p7pJ0CV0E3RCMiR7Nct52TB6cSt4vHVrCu0c+qHe388+1lrO6wsKM9xI72EFf9ZR6nDC5kSImXLLuFE0udTOrm2EVERHoyJXhy0PY3gtcWblOCJyKfid1qZkR5DkOK3Nh3LuHkM87k/Y1tPDN/G/M2tTBrXTOz1jUD8OdomNW7Xvf4+5sYM6yCcZW5+5/OKSIicgxSgicHzWLadypmW6StGyIRkd4s22Xj82Mr+PzYCra0BPjr+5to9EWwWEy8t3hzut5D/6kl9PYWRlXkcHp1EWcNK2FURQ5ms5I9ERE5dinBk8+kNdza3SGISC/WtyCLn3x+ZPp8Q005/Cp1/LlhxczY0snyHR0s39HBw2+tJ9dtY0iJlyElHqpLvHxuWAkVua5uil5ERKTrKcGTz6Q93N7dIYjIMWRg8Z5N0h/58nFsi5h4a00j8ze18nZtI+3BGPM3tTJ/U+qPT/e+uorThxRRmuMkx2XjptMH4rJZsFrM3dUEERGRI0oJnnwmrRGN4IlI96nMdzP1xH5MPbEfkXiCdQ2drG3ws7ahk0VbWlmwuY2ZaxrT9R99ZwM5LhtTT+xHjsvGaUOKqMp3Y7cq4RMRkd5BCZ58Jm1hPYMnIl3IZoMf/3jP8V4cVgsjK3IYWZGTvvZ2bSMrtncwf3NreqGWjlCM/525DoD7AZMJCj0OJg0o4JLjKhhS4tW0ThEROWopwZPPpDnUzK8W/orjio/jjKozujscEent7Ha4996Drn5GdTFnVBcD0NwZIWkYvLx4B4u3tlHfEWZ1vZ9oPEmTP8KrS3fy6tKdAJTnOBlals3E/vlYLWZqBhRQVeDGZjHhsGrvTxER6bmU4MlnMmPLDACeWPkEy6cu7+ZoREQ+XqEntZfnDacNTF8zDIPWQJRNzQGe+GAzcze20NwZZWdHmJ0dYd7aa3ongMNqZmxlLlNGlzGoyIPdaub4vnnapkFERHoMJXhySMwmM0kjud+ycDyM0+rs4ohE5JiSTMLqXTvhDRsG5s/27JzJZKLA46DA42B8v3wAWjojbG4J8P66FjY1d9Loj/DBhhYAIvEk8za1Mm/TnueP3XYLJw4spCTbQZ88NycOLGBMZe5niktEROTTUoInh8RisnxsgrfNv43BeYO7OCIROaaEQjBy17YJnZ2QlXXY32J3wnd83/z0tZ3tIZw2Cyt2dLBwcytzN7WyrTVIXUeYYDTBf1c3ZNzD47AyriqXIo+DIq+DqgI3Y/rkMrDIA6RGArVfn4iIHAlK8OSQWEwWYsT2W7bFt0UJnoj0SuW7Fl05dUgRpw4pSl9v7oywus7HzNWN1HWEaNu1TUNnJJ5e1GV/BhRmccbQYvrkuSjPdZHttDGuKhenTc/3iYjIZ6METw7JccXH8UHdB3jtXswmMx2RjnTZFt+WboxMRKTrFXocnDK4iFMG70n6Fm9tY0tLgNZAjFA0zoodPpZub6euI5yus7E5wMb3N2Xcy+OwUl3qpT0YpW9BFkNLvYzuk8vwsmzcDkv6GUIREZEDUYInh+S+Sffxz9p/cumQS7nz3TuV4ImIfMRxVXkcV5W3z/VwLEFHKEY0nuSdtU1saOxkR3uIRn+E+o4QDb4Ii7aktp7Z0BTYZ4GXilwXA4qyiMaTeBxWSnOcXHdSf5w2M4Ueh0b/REQEUIInh6jAVcCdE+4EoNhdzNq2tekyJXgiIh/PabOkk7BrJvXNKEsmDVbu9PHhtjYKshysrvNR7wunt3MIxRLsaA+xoz2U8bon520FwGI2MajIQ7bLSqHHwYjybEpzXOS5bZw4sBCnzayVPkVEjhFK8ORTK3GXZJxv9W8lkoiwsX0jQ/OH6pcJEZGDZDabGNUnh1F9Upu0TxldllEeiMRZvLWN9Y2duGwWQrEET87byvrGTmwWE7GEQW2DP13/9RX1Ga93WFOjfFX5biryXIRiCSb1z8dhs2AYBpNHlJLrth/5hoqIyBGnBE8+tZKszASvOdTMD9//IW9sfoNHz3yUU/qc0k2RiYj0LlkO6z7P+n3lxH5EE0nsFjON/ggrdnSwsz3ExuYAjb4IbcEoG5sC1PvCROLJfUYApy2rSx/f9eJyvE4r/Qqy6F+YhdkERV4HkXiSYq8Dw4DibAcnDSokEEnQt8CtKaEiIj2UEjz51D46ggfw9ra3Afhg5wdK8ETk8LPZ4Dvf2XN8DDOZTDisqSSrJNtJSfa++5AmkgbtwSiBSILt7UHerW3CbjVjNZuZsbqeWNwglkyysSmAPxxn+Y4Olu/o2Oc++zO2MpdTBhdiMZtIGoBhgMnE8LJsSnOcVJd4cdkthGMJJYMiIl1ICZ58avtL8CKJCADLm5d3dTgiciyw2+GXv+zuKI4aFvPujdyhqsDNiQML02XfOiu1rY1hGDT6I3SEYmxqDrC6zodhpLaA8IXjBCJx8rPsbGoOsHhrG4aRev2Sbe0s2db+se9tt5ixW810RuJUl3jpW+DG47SS47LRN9+djm9wiZdk0mBYWTZ5WZomKiLyWSnBk09t7wRvUO4g1revT5+vbllNLBHDZjm2/8IuItLTmUym9AjgkBIvk0eUfmzd5s4IScOgtt7PnA0ttIdimE1gwoTZBI3+1EqgiaRBSyBKNJEEoLbBn/GM4MfJ35Xgue0WvE4bDquZ6hIveVl2LGYIRZPYrCZGlOcwoDCL9kCY1e0mste3MLwiF6/TituuX21E5Nim74LyqRVnFaePxxaPzUjwoskoa9vWMqJwRHeEJiK9VTIJW1MrR1JVBWZz98ZzjNm9F1+x15nxPOBHJZMG65s6sZpNWMwmnpq3lR3tIfKz7IRjCQKRBJhgZ3uIlTt8eJxWWgNRWgNRAFoDAKnnBQ80Sphi4bHVi9JnVnMqYS3OduCwmnFYLTisZvoVZjG8LBuL2YTLZiEQjeN1WjGZTFTkurBZzKlzIM9tx2zWQmEicnRSgiefmtfmJduejS/q44TSE3hh7QsZ5UublvLaxtcYnDeYSwZf0k1RikivEgpB//6p485OyMrq3nhkv8xmE0NKvOnz750/7GPrGoaBYcC6xk42NnXSGUklXoYBoViCba0hfOEYwWiCJn+Y9mCMzkic2gY/VXlu4uEAQey0BWMAxJPGfreUOBQ2i4lsp428LDs5Lhud4Tg5LhvZLhvDy7wYgD8cJxJPMKoil+pSD33y3OxoD5HrsuGwWfA4rDT5w/Qv9NAWjFKQZdfq0iLSJZTgyadmMpn4xam/YGfnTk6p2HdBledqn2NDxwbsZjvn9T8Pl9XVDVGKiEhPZjKZMJmgutRLdan3k1+wi2EYxONxpk+fznnnnY7ZYmVzS5AGXzidHEbiCSKxJMFonIVb2tjcEsRqNtHSGaE0x4kvFKepM0KTP4LTZiYcS00pjSVSU0xbdo0o7u2/qxsyzp9m2wHjtJhNJJIG5TlOCjwOtrQEcNktlOW4MJmgLMdJkcdBRyjGkFIvXocVfyROPGHgdVrJclip7whT5HVQ7HUwpjKX1kAUj8NKRyhGWzBKPGFwQv98ALa3pUZKXTYLLrsWtxE5FinBk8/k5IqTP7ZsQ8cGIDVdc0H9Ak7tc2pXhSUiIr3c3qNhJpMJq8XMoGIPg4o9+61/TU2/j71XOJbAYTWTNCBpGDT5I7QGory3rgmr2cSgYg9LtnVQ3xEinjDwOK14HFZCsQTLt3ewsTlAezCaWk30IxK7Lu7sCLOzIwyALxynwZdalOzDT9n+j8qyW0juSmwhlViW5zrpX+ghkUzSGohRmu0gnjRw2y2YMBFLJCnOdqRXPN3YFGBjc4BBxR6KPKltMgYVe3BYzbQFo7tGV20UeRx4nVbiSYOqfDc5LhuGYbChKUC2y0qJ10k8aWCzmDRqKdINlOBJl5i1fZYSPBER6ZF2b+NgMYEFE+W5LspzXYysyEnX+dzQfVeO3p/OSByH1UwskcRqNlPfESbHZePDbW1E4kn65Llo9Edo6YzSFojiC8eIxJPkuGysrvOlE0ibxYQvHMcXimEymegMx/CH46xr7MRkSu1K4XVYKclx0tARxh+JZ8SRSBpsaw2xrXXPVNXVdR+Ndv9mrGr45Ep7cVhTK6b6w5kx5LhsJJMGDpuFISUeovEkq+p8DC7x4rCYaeqMEI0nsVpMTOiXT998N23BGKvrfPgjMTwO665k00nCMHDZLORn2XDZrRiGgcVsIsdlI89tZ3Wdj2A0kR4FNgwo8Nhp8kcYXOKh2OvcNR3YIBhPPSdq7Erm87PsWC17nuc1DEOJqRzVlODJYdPH04ftndsBqPJWsdW/NV32/o739Q1TRER6PY8j9auVbVfCUFWQ2hLi9Oo9C5N9luXHWjoj5Lrt+MMxshxWbBYz4ViC9Y2dxBJJ3HYrZlMqaa2t99MeimGzmHBYzTT5I7jsVnyhGMFoHKvFTGc4zpp6P03+MCMrclix08fGxk7iSYNBxR5iu1ZCzXXbyLJbae6MsKbej8tuwWwy0RqIEoknicSTZNkthGKJ9EhmRyj1XKQ/Eqe5M5Juw9L9LJyzpSW43/bO3dj6GT6tPWwWE/GkQZbdSmfEyv1L3wIgGE3gtJmpyHURiCQIxxMEI6lrVQVuWjujVOa7sVvNmEwm8tw28rPsbG8Lsb0txPCybEwmyHXZMJtNuz5jC4UeB75d7XfaLJTlOPE6reS6bXSEYnSG45zQvwCzKfVHgVy3na2tQULROB6HjWyXlXAsSSJpUFXgpiDLTmckjsdhZXWdj0KPg7IcJwZ7+hqw6w8LJgwD6nxhLCYTpTn77pEpvZsSPDlsHjr1IW6YcQO3jLuFZc3LMhK87Z3beXPLmyxqWMTNY28mx5FzgDuJiIjI/hTsWsk0171nz0CnzZIx2rhb5a79Bg+3ZNLAZEpNjY0lkmxuDhCJJ6ku9RKJJ4nGk1hMJuZvbqW23sfYyjx27lr0ZlCJhx1tqeOCLDtNnanRzKbOCA0dYfKy7FTkuqjrCLG1NUiR10E4lkpaYgmD1kCEQCRBLJnEbDLhC8VoCUTpV+Amz21nTb2fUCyBx2GlLRgl22ljR3uIWCKVdXbuGukMRhPp9oRjSTY0BTLaGE0kWbHDB5CeWrs/q+t8h++D/ZRMpl1JnpGKO89tIxxLpqfrDijKwm4xE4jGicVTI8Rep5Vk0iB71whortuGLxQjmkiSZbeSSBrEkgY2s4lct514MvXvOqTEi81qxmo2pb4sJqLxJL5QnPZQFLc9Nfpss5gxm0yEYgmG7Po3d9ut5GfZce56PtRls9DgC+MPxyn02BlS4sUfjtMRiuG0pf4gEUkkOa4qj60tQUwmGFTsSY+4R+IJwtEkLYEIdqs59VwrEIknsZhTfdNlsxzyiri9YUBCCZ4cNqOKRvH+l97HbDJjWWNh2sZpGeXfefc7AGzq2MSfz/lzd4QoIiIin9HevzDbLGYG77Viqs1ihlQOytnDSzh7+L5TW4+ryjviMe6tI5RaedUwDJp9IVYvfJ8xE08ljonKPDdtwSgbmgIYhoHdaibXbWdHW4hgNE6e204olmBHe4j6jjCGkUp8CrPsDCz2sGhLG+ZdyYDdaiaRNAhG4xi7nuecu7GV4/vm0egPE40nCcdS03HTI6E2C/m7El27xczgEg+haILmzggdoRi5bjsdwVh6T0kgPQV490ipYUA0vqd894qyu238SPJK9+ekn5plV99z2SzpZP1AvE4rWXYrll1btuz+CscSdEbiFGTZcVgt5GXZaPBFiMQTNPujmE2knjf1pkZiLyg1cf6RbtxhpARPDiuzKTVNYFzJuPS1sUVjWdK0JH0+t24uiWQCi1mre4nIIbJa4Rvf2HMsIvIJclw2clw2AEo8NrZYYXCJB5stdS0vy86AoszFecZW5h7UvT8/tuJTx9XSGSHbZcNmMaeeRTSb0smzYaSyN5PJhGEY+EJxXHYLgUg8vW9kZySO1WyiIxQjkTSwWczYLGaaOyOU5TipzHdT1x5mW1uQeNJITx/2hWM0+SPpLUDaglE6QqlnHu1Wc3rE1GI20eAL0xqIku2yEY0naQ1GSSQM4kmDRDJJPGlgt5jxOK1kO23pZHp3G9wOK7X1frxOK3aLmWA0QSiWILTrv4ZhkOWwEoknafKnRuKy7Bbiu94jmkhNU81z20gkDXy7nvPcO7nb/Uzq/vjD8X2eDd1b+0eS4b0FognqfanR27au/ZvEZ6afjnJEDModlD6+aNBFGQkewPz6+Uwqm4SBkU4KRUQ+kcMBjzzS3VGIiHxmu6fbQmr0b28fXSU2x23bVS81Nbck28nHLftTzZ4R1aoCd/o50J4uHEtgs5jTo3SQmg7cumsfyaQBO9pC2KwmApEE+Vl2vE4rFpOJQDROKJZg7sZWKnJdVOa5wARtgdiu0c5UwphMpv6bSiStLN/RgXXXiF6u20ZJdmoF2EZfhEKPHX84jssGW5bO7cZP5tApwZMjwmwy88iZj7C2bS2XDb6Mn8z5SUb582uf5/6591OaVcpfz/nrUT/XWUREREQ+vd3P1u3NbDZRuCsRtpj42GTV67Thddq4aEx5xvVi74EXmDmYvTdjsRjNqz6xWo+ioRM5Yk7tcypfHfVVTCYTIwtGZpTN2DKDbf5tLKhfwIeNh2sXIBHp9QwDmppSXx83J0dEROQYpgRPusQDpzxAWVYZd46/k37Z/TLKnlv7XPcEJSJHn2AQiotTX8H9L6suIiJyLNMUTekSA3IG8OZlbwKQNJL8atGv0mWvb3qdLw39Es2hZk6uOBmHxfFxtxERERERkQPQCJ50uYsGXYTVvOdvC0kjydXTr+a2t2/jhhk3EElEDvBqERERERH5OErwpMvlO/O5ZewtTCybyAsXvpBRtqhhEb9d9NvuCUxERERE5CinBE+6xfWjrucv5/yF6vxqrh95fUbZv1b/iwtevoBfLfwV8eQnb2IpIiIiIiIpegZPut3NY2+m0FXI+NLxvLTuJZ5e8zRbfFt4YuUT+KN+flzzY22jICIiIiJyEDSCd4Q98sgj9OvXD6fTycSJE5k/f353h9Tj2Cw2rh5+NUPzh3LH8XdkbJL+4roXufb1a/n9h7+nJdTSjVGKiIiIiPR8GsE7gp599lnuuOMOHnvsMSZOnMhvf/tbJk+eTG1tLcXFxd0dXo/ktDp54twn2Obfxtq2tTww9wGWNC1hSdMSFjYs5Pef+z0eu6e7wxSR7mK1wtSpe45FREQkg346HkG//vWv+drXvsZ1110HwGOPPca0adP429/+xt13393N0fVcOY4cchw5jCwcyQmlJ/Dokkd5deOrLGpYxDkvnIPL5qKPpw9fHvZlBuYMZFDeIOoD9VjNVgpdhd0dvogcSQ4HPPFEd0chIiLSYynBO0Ki0SiLFi3ie9/7Xvqa2WzmrLPOYs6cOft9TSQSIRLZs0WAz+cDIBaLEYvFjmzAn2D3+3d1HCXOEu6bdB9T+k3hwYUPstm3GX/MT2OwkcWNiwFwWBxEEhEcFgeXDrqUr438GjmOnIz7GIZxSM/xJZIJEkaCtkgb8+rnUVNWQywR44O6Dzir6ixyHbmHs5m9Unf1GTl6qc/IoVKfkUOlPiOHqif1mYONwWQYhnGEYzkm7dy5k4qKCj744ANqamrS17/73e/y7rvvMm/evH1ec++993Lfffftc/2pp57C7XYf0XiPBgkjwbbENuJGnNWx1ayLr6Mt2YbBvl24zFKGAwdWk5ViSzHLo8sZaB3IFNcUdiR2UG4pZ1ZkFk2JJobbh5M0kqyIrcCKlQprBe+F3yPGnv+JLFhIkAAg25TNN73fxGlyUpeooyXZQtgIU2IpoTHRyJzIHAJGgItcFzHENgSrSX9HETlsDAPLrj+EJRwO0AJMIiJyjAgGg3z5y1+mo6OD7Ozsj62nBO8I+TQJ3v5G8CorK2lubj7gP2JXiMVizJgxg7PPPhubzdatseytLdzGjs4dxJIxVrWu4pGljxBOhI/4+xa7iokmo7RH2j+x7siCkfTx9KE0qxSXxYXX7iWSiJDjyGFUwSgqvZWsaFnBS+tf4rji4zil/BRyHDn8deVfKc8q54O6D5i9czbjisYxJG8IJ5adiD/mpy5Qx0nlJ7GzcycDcgbwYeOH9Mvph9fuxWa2UeQqOuKfw4H01D4jPddB9ZlAAFteXqp+WxtkZXVhhNLT6PuMHCr1GTlUPanP+Hw+CgsLPzHB09DCEVJYWIjFYqGhoSHjekNDA6Wlpft9jcPhwOFw7HPdZrN1e4farSfFAlBsK6bYm1qw5oSKE5jcfzIbOzZSH6gHoCHYwLy6ecSSMRqDjTQEM/89it3FmDDhtrmJJ+MMyh3Eu9vfxWa28cez/0ilt5IcRw6bOzazoX0DreFWfrHgFzSGGjPu08fTB1/UR6GrkEJXIfPr96yWuqJlBStaVhxUe6Zvno7FZMHAIGkkM8pm181mdt1sHl/1ePraLxf9cr/3sZlt3DjmRqxmK3WddZRmldIvux+RRIQlTUuYWzeXe2vu5biS49KvMQyDefXzGJgzEKfViT/qp8RdgsVsOajYP05P6zPS8x2wz+x13WazZZzLsUvfZ+RQqc/IoeoJfeZg318J3hFit9s5/vjjmTlzJhdffDEAyWSSmTNncsstt3RvcL1YmaeMMk9ZxrVvjP0GAOF4mNc2vkZTsInmUDNnVp3JiRUn7nOPus46TCYTpVl7EvHq/Gqq86tJGkncNjebOjaR48hhTNEYRheNxmHJTMxXtayiNdzKVt9WmkJNvL/jfSq9lbSF22gMNjK8YDirW1ezxbcFALPJTLE7lajuTk73p9hdTEuohQJnAfmufNa0rtlvvVgyxsMfPnzAz2rqG1Ppn9OfLwz6AitbVvLe9vcIxUMZdfp4+jAgdwBNwSYKXYWMKx5HLBmjtrUWt83NmVVnckblGZ85CRQRERGRw0MJ3hF0xx13MHXqVMaPH88JJ5zAb3/7WwKBQHpVTelaTquTy4Zc9on1Ppog7s1sMnPJ4Es+8R7DC4anDipS//nWcd/ab71QPMSypmVUeavS7ztr+yze2fYOl1dfTlu4jZUtK7l2+LXYLXYgtQDM7oSqPlBPli2LhkBDaouJlU/w/o73KXIVkTASmEwmEskEreFWvHYvHpsHp9XJBzs/AGBTxyZ+vejXH9uO7Z3b2d65PX0+a8esjPLXNr4GpBLPYlcxk8on0S+7H4FYgLrOOhYFFjF79mwMk8GsHbOozqvm5rE30xnrBKDAVZAa8aybT9JIcnrl6RS4Cj7x8xURERGR/VOCdwRdccUVNDU1cc8991BfX8/YsWN54403KCkp6e7QpIdwWV1MLJuYce2UPqdwSp9T0uc15TUZ5XuPlu0eZfTavQD8cNIPD+p928PtvLH5DV7d8CoAVdlVnFZ5Go2BRmbvnE2WLYvjio9jadPS1DONBryz/R0glczFk3Faw63p+zUGG2kMNu53KuryLcvTx4sbF3P9m9d/bFyuBS5O73M65/U/j5ryGjb7NvP0mqf56qivUumt5NUNrxJLxjiv/3m4rK6DaquIiIjIsUQJ3hF2yy23aEqm9Di5zlyuHHolVw69cp+ya0dcmz6+mqszyoKxIG5bakVXwzBY1ryMLGsWnbFO/rr8ryxoWMCowlEE40EsWCjyF5FbmUuCBKOLRjN943Q2dGwg35mP3Wxne+d22iPtFLmKyHPmsbZtLa9vfp3XN79OlbeKlnALgViAl9a9RIWngh2dOwD4yZyf4La5Oan8JK4ceiXD8oel49ofwzCIG3FsZj1vISIiIr2bEjwROWh7J1Emk4kxRWPS5w+fmfnMXywWY/r06Zw/4fz0Q8Efnd6aNJIsa1rG4LzBuKwuZm2fxT0f3JN6ftG/NaPu7uQOUltm+KN+3tj8Bm9sfgOv3Ut5VjmBWIDPD/o840vG89O5PyXHkcP40vHMrZvLdv92rhl+DVcNu0qjfyIiItJrKcETkW5jNpkZWzw2fX5a5WnMvHwm69rW8Wzts5hNZi4dcilNwSbe3Pwm/qif+066j2giyoL6Bbyy4RXWtq2lNdxKbbQWgEeWPILZZE6vQrq4cXH6/r9b/Dt+t/h3jC8Zz0UDL+K8/uexuGExy5uXc+HACyn3lJM0kphN5i79HOQQWCxw2WV7jkVERCSDEjwR6VGsZivDCoZx74n37rlYAKdXnp5R78KBF3LhwAtJJBPMq59HW7iN9kg7j3z4CP6YH4C+2X3TK5XubWHDQhY2LOT+ufcTS6Y2tP/9kt8zvmQ8SxqX0Mfbh1+d/ivm7pzLsuZl/OTE1JTQ5U3LGZg78IDTQeUIczrh+ee7OwoREZEeSwmeiBzVLGYLJ5bv2e7ivP7n8Xzt84wsHMmJ5Sfy/fe/z2sbX+OPZ/+R93e8z/y6+QzIHcAHOz+gI9KRca+FDQsB2OzbzKWvXJq+PjB3IGOKxnDDjBvon9Off5z7D3KduV3SPhEREZFDoQRPRHqVfGc+N4y5IX3+s5N/xp0T7iTfmZ+RCEYSEW5/+3Zm7ZjFV0d9lVc3vEpDsGG/9/zT0j8RN+JAamuJ++fez/CC4by19S1uGnsTQ/OHcv1/rufE8hO5c8KdmuIpIiIi3UYJnoj0aiaTiXxn/j7XHRYHD3/uYTb7NjMgZwC3jruVf6z6B7mOXE6vPJ2/r/w70zZOI5aM0RRqynjtm1ve5M0tbwJw039v4qujvsrGjo1s7NhIaVYpU0dM7ZK2HZMCAfB4UsednZCV1b3xiIiI9DBK8ETkmGUxWxiYOzB9vndidutxt3LrcbdiGAb/WPUP/t/C/wfAl4d+mafWPJVxn78s/0v6+LGlj2E2mZm9czY/nvTj9Ab2IiIiIl1BCZ6IyAGYTCauGX4N9YF6nFYnt467lRGFI3hn2zuc3fds7p51d3rFToDOWCcPLXgIgGtev4ZXLn4Fp9WJCRMmk6mbWiEiIiLHCiV4IiKfwGwyc9cJd6XPLxp4ERcNvAiAZU3L+NfqfwFw3cjreHzF4+l6DcEGvvrmV9nRuYNxxeP4zem/UZInIiIiR5RWAhAR+QzuGH8HFw+6mCkDpnDz2JszyqwmK8ubl9MabmXm1pm8vP5l6jrreGXDK8ST8W6KWERERHozjeCJiHwGNrON+0+6P33+x7P/yPdnfZ/vTPgOK5pX8OTqJ9NlDy14iHA8TMJIsKplFXefcHd3hCwiIiK9mBI8EZHD6MTyE3nnincAOKXiFF7f9Dq+iI98Zz6NocZ0vSdXP0kimeAHk37QTZGKiIhIb6QET0TkCMlx5PDsBc/SGe2k3FPOF1/7Ilt8W9Llz9Q+Q74rn8uHXE6hq7AbIz2KWCxw/vl7jkVERCSDnsETETmCSrNKGZQ3CLfNzd8m/41LBl/Cv87/F9ePvB6AR5c8yhWvXkFTsOkT7iQAOJ0wbVrqy+ns7mhERER6HCV4IiJdpNhdzH0n3seYojF8Y+w3GF4wHIDGUCOXvXoZHzZ+yML6hRiGAUBHpINgLNidIYuIiMhRRlM0RUS6gd1i55/n/ZM1rWv43qzvsdW/lWtfvxaACwZcwNdGf42rp12Ny+biV6f9ijFFY7TFgoiIiHwijeCJiHQTu8XO6KLRPDXlKYbmD01ff23ja3z+35/HH/PTGGzkmtevYcrLU3iu9jk2tm/c5z5JI8mypmVEEpGuDL97BAKQlZX6CgS6OxoREZEeRyN4IiLdLMeRw1NTnmLOzjksa1rG/234P+oD9QAUuYpoCjWxzb+N++fej9lk5py+59AcamarbytD8ofgsDiYuXUmha5CflzzY06qOAmb2Za+f0ekA4/Ng8XcSxYlCWraqoiIyMdRgici0gPYzDZO7XMqp/Y5la+P/jpzds7BYXUwqWwSC+oXcOtbt5IwEoTiId7Y/Eb6dY079my90Bxq5ptvfZO+2X35XNXnmNx3Mmta13DvnHvJceRw/cjr+cqIr2iqp4iISC+mBE9EpIexW+ycVnla+nxC6QRmXTkLq9nKi2tf5HeLf8fIwpFcMOACnlj5BKtbV1OeVY7D6mBTxya2+Lbw+IrHeXzF4+l7dEQ6+PWiX/PEyicYkjeEKQOmMCx/GNX51d3RRBERETlClOCJiBwFrObUt+tLh1zKpUMuTV8/t/+5bGjfQFlWGR67h/ZwO29te4u5O+cyY+sM4sk4owtHc06/c/jVwl/RGm5lbt1c5tbNBeDmsTdzRfUV5Dnz2NyxmaZQExNKJ3RLG0VEROSzU4InInIUM5vMDM4bnD7PdeZyyeBLuGTwJXRGO2kKNVHprcRqtjKpbBILGxayvn09L697mYSR4JElj/DIkkfon9OfTR2bABhRMIIRBSMYkDuASWWTGJg7sLuaJyIiIodICZ6ISC/lsXvw2D3p8+r86vSUzHsm3cNTa57i3+v/zZrWNenkDmBly0pWtqwEwISJyf0mM7JwJB2RDq4fdT1ZtqyubYiIiIgcNCV4IiLHIJPJxFXDruKqYVexuWMzv1v8Ozb7NnPt8GsxmUzM2j6L9e3r2dixkTc2v5Fe2OWZNc9wcsXJ1JTXUOGpYFzxOGwW2ye822FkNsNpp+05FhERkQxK8EREjnH9cvrxmzN+k3Ht4kEXA1DbWss9H9zDqpZVAPhjfl7f/Dqvb34dgFxHLvnOfLx2L98e/23GFo09sqt0ulzwzjtH7v4iIiJHOSV4IiLysarzq/n7uX9nWdMyxhaPZWXLSt7d9i4zt85kZ+dO2iPttEfaAbj29WsZlj+MSeWTGFs0ltP6nNZ79t4TERE5SijBExGRA3JanZxQdgIA44rHMa54HLcdfxuxRIwlTUt4b/t7vLn5TRpDjaxuXc3q1tUAnFR+EjXlNYwtHsvowtHaf09ERKQLKMETEZFPxWaxMaF0AhNKJ/Dt8d+mJdTCO9ve4cPGD3llwyvM3jmb2TtnAzAodxCXDL6ECwdcSK4z99O/aSAA/fqljjdvhiwt+CIiIrI3JXgiInJYFLgK0vv0XTDwAl5Y+wLtkXaWNC5hfft6HlrwEP9v4f+jyFXExLKJfH/i9z/dipzNzYc/eBERkV5CCZ6IiBx2k8omMalsEgC+qI/pG6fz4roXWdO6hoZgA69seIUF9Quozq/mpPKTuKL6CtrCbcSMWDdHLiIicnRTgiciIkdUtj2bK4deyRXVV7C6dTW1rbX8dO5PqQvUUReo451t7/DXFX+lPlCP1+QlVBvi/IHn47K6cNvc3R2+iIjIUUUJnoiIdAmTycTwguEMLxjOxLKJLGpYRG1rLf9Y9Q/qA/UA+A0/Dy16iIcWPYTFZOEbY7/BNcOvwWlxkjAS+qElIiLyCfSzUkREuly5p5xyTzkXDryQK6qvYHHjYiyGhVmLZ7HZvZlVratIGAke/vBh/rL8L8SSMWxmGxO9I3l41z1iyRhduMW6iIjIUUEJnoiIdKvK7EoqsyuJxWIkViX46bk/xZ/w8+qGV/nX6n+lR/fiyTjz6uelX3fmc2cyqM8Yvjbqa9SU13RX+CIiIj2KEjwREelx8p35TB0xlS8N/RL/2fwfWsOtHF9yPP9c9CdW9t+EAQSTYRbUL2BB/QJGF43m8iGXM7xgOANzBmqDdREROWYpwRMRkR7LbrFz4cAL0+e/mPy/JDf8lqSR5FnfFp5Z8wwvrHuBZU3LWNa0DEjtuTdlwBQG5AxgQukEvHZvd4UvIiLS5ZTgiYjIUcVsMmM2mRmYO5AfTPoBN4y5gRfXvsg7295hbdta1rev53eLfweAw+JgYO5AXFYX2fZs7qm5h0JXYfc2QERE5AhSgiciIke1QlchN4y5gRvG3EBzqJmX1r3E+vb1rG5ZzWbfZla1rErXfXvb25RnlXPtiGsJx8OEE2FK3CWUZpVyfMnxuKyubmyJiIjIZ6cET0REjh7BIAwfnjpetQrcmfvkFboK+frorwNgGAZrWtewo3MHixsX89qG12iLtLEzsJMH5z+4z60H5AzgmQueUZInIiJHNSV4IiJy9DAM2LJlz/EBmEwmhhUMY1jBMM7qexbfGf8dWsOt/HPVP1natJRiVzEeu4f6QD1LmpawsWMjF758IaOLRjO8YDhV3irGl47HaraSbc/GF/VhN9txWp1d0FAREZFPRwmeiIgcE8wmM4WuQm4//vZ9yt7d9i63vX0bDcEGZmyZwYwtMzLK3VY3wXgQu9nOuJJx3DD6BsaXjAdSiaSIiEhPoQRPRESOeadVnsYrX3iFpU1L2di+kYZgA4sbFrO9czsAwXgQgGgyyry6ecyrm4fD4sBusXPz2Jv58tAvK9ETEZEeQQmeiIgIUOmtpNJbmXEtlowRS8SoD9RT4CpgefNy/rbibyyoX0AkESGSiPDg/Ad5tvZZit3FVHgqqCmv4Zy+52A2mbupJSIicixTgiciIvIxbGYbNrONAbkDADi54mROrjiZYCxIfbCe97a9xyNLHmFTxyY2dWwC4KV1L3EndzIgZwAJI0EoFqLcU86wgmGMKBiB2WRmaP5QBuYOxIRJI38iInJYKcETERE5RG6bmwE5AxiQM4AvDP4C0zZOoz5YT3u4nVc3vko8GWdjx8Z0/cZQI0ualuxzH6/NS0lWCTmOHG4eezMTSicAsLB+IbVttQzLH8agvEFk27O7qmkiInKUU4InIiJHD5NpzzYJPWTkK8eRw5eHfTl9ftOYm2gINtASaiHHkUNruJU1rWvY7NtMQ6CB9kg72zu3kzSS+GN+/O1+AG6ZeQtnVJ3B6pbVGckhwPElx3PRwIvom92XcDyMxWyhxF1C/5z+XdpWERHp+ZTgiYjI0cPthpUruzuKAyrzlFHmKcu4dk6/czLOm4JNtEfaSRpJGoONPLLkEVa2rGTaxmnpOsPyh7EzsJOOSAeLGhaxqGHRPu81tmgsuY5cLGYL1fnVDMkbwrjiceQ7849M40REpMdTgiciItLFitxFFLmLAKjOr2ZS2STe3vY2y5qWUeAqoF92P06vPB2Abf5t/Hv9v1nUsIiNHRvJdeQSS8bY0bkjY9rnzK0zgdR2EBWeCsqyyhhdNJoLBlxAoauQbHu2nvcTETkGKMETERHpZjaLjXP6nbPPSB9AVXYVtx536z7X5+ycw8qWleQ4cgjFQqxpXcPKlpVs7NjINv82tvm3Mb9+Pn9Z/hcA8p353HbcbYwoHMHihsW8t/091ratxTAMzul3DkPyhtA3uy/lnnJm7ZiF0+IkmogyJG8Io4pGHfHPQEREDg8leCIicvQIBmFCaiESFixITdk8RtWU11BTXpNxzTAM1ratpSnUxFbfVqZvms7K5pXEjTit4Vbu+eCe/d7rX6v/dcD3GpY/jJGFI+mb3Ze1bWup8lYxsWwifbx9WNSwiFgyRh9PH3xRH/1z+pNtz06PGBqGoZFDEZEupARPRESOHoYBq1btOZYMJpOJ6vxqqqmGCvjysC9jGAaRRISn1zzNY0sfw2wyk+/MZ3jBcM7uezZJI8msHbNoDjWzoX0DDcEGvHYvVd4qgvEgW3xbWN26mtWtqzPe6/dLfn/AWErcJQC0hFqYWD6Rq4ddzajCUdjMNty2YzcxFxE50pTgiYiI9GImkwmn1cl1I6/j2uHXYjaZ9xlRO7f/ueljf9SPx+ZJ11nbtpblTctZ176O/275Lw3BBvp4+rC9czsAg/MGk23PZkfnDgKxAP5oalXQhmBD+p6zd8xm9o7ZQOoZwSJXERaTBYvZQnlWOU6rk6H5QxmcN5j2cDs7OncQSUSwmq10xjrpiHSQSCao8FZwwYALGFEwIj06GDEidMY6ybPlHdHPUUTkaKEET0RE5BhhMVs+sY7X7s04H5I3hCF5QwC4+4S709fbw+0E40HKssoyEsZgLEgsGePDxg/JdeTisrp4as1TzN4xm4ZgA0kjmZH8bfNvA+Dd7e8eVBueXP0kXpuXck85DcHUthM/ff6nFLmLiCViOKwOit3FDM4dzKl9TmVAzgDm1M3hmTXPUOROJZYjCkZwyeBLKHYXY8KE1WxNtyEYC9IYbMRj95DjyMFmth1UXCIiPYUSPBERETlkuc5ccsnd5/ru6Ze7VwEFuO/E+0gaSVrDrUQTUdrCbRgY7OjcwcqWlWRZs1jQsIDNHZvJdmQztmgsdoudcDycmnaaV43ZZGZRwyLe2voW/pif2rba9P0NDBqDjamTCNQH6lnWtIwX172YEdvu/QU/2PkBf17+5/T10/qcxsOfe5hoMsrlr17OVv9WIJXsXlF9BbmOXLLt2bhtbj5X9TlsZhvBWJBnap+hwlPB4NzB9Mvph9lkPqjPriXUQkOwAYvJQr4zP72iqojI4XDUJHgPPPAA06ZNY8mSJdjtdtrb2/eps3XrVm666SbefvttPB4PU6dO5ec//zlW655mvvPOO9xxxx2sXLmSyspKfvjDH/KVr3wl4z6PPPIIv/zlL6mvr2fMmDE8/PDDnHDCCenycDjMt7/9bZ555hkikQiTJ0/m0UcfpaSk5JBiEREROVaYTWYKXYUAlHvKARhZOJLJ/SYDcAM3fOI9vlj9RYKxIJs6NlHbVktfT182ztvI+NPG0x5rpzPaSXuknXgyznvb32NDxwbqOuuwW+z0y+nHhQMuxGK28Fztc6xpXZO+77vb32X0P0bjtDgJJ8KYTebURvRRf3oV0t1O73M6Y4rHMK9uHnPr5qave+1ebj/+dqb0nwLA02ueZmPHRgblDqI51MyIghEUuAqYVzePx1c+TjwZT38u99bcyxcGf+EzfLoiInscNdlGNBrl8ssvp6amhr/+9a/7lCcSCaZMmUJpaSkffPABdXV1XHvttdhsNn72s58BsGnTJqZMmcKNN97Ik08+ycyZM/nqV79KWVkZkyenfsA8++yz3HHHHTz22GNMnDiR3/72t0yePJna2lqKi4sBuP3225k2bRrPP/88OTk53HLLLVxyySXMnj37oGMRERGRQ+e2uRlROIIRhSOIxWJsN22nj6cP/W39M+odKGG6fMjlxJNx/FE/D85/kOmbpgMQToQBuLfmXi4aeBHTN03n7W1vA/DW1rdIGAne2f4O72x/J32vvZPBn8z5CT+Z85NDak/SSHLPB/fwy4W/ZEjeEOoD9XTGOgnFQjgsDvrn9qcl1EKhq5Bh+cO4ccyNhOIhPDYPuc7cjHv5o362+LbgsXko85ThsDgOKRYR6R1MhnF0LUP2xBNPcNttt+0zgvf6669zwQUXsHPnzvRI2mOPPcZdd91FU1MTdrudu+66i2nTprFixYr066688kra29t54403AJg4cSITJkzg979PrQ6WTCaprKzkm9/8JnfffTcdHR0UFRXx1FNPcdlllwGwZs0ahg0bxpw5c5g0adJBxXIwfD4fOTk5dHR0kJ2d/Zk+t88qFosxffp0zj//fGw2PY8gn0x9Rg7VQfWZYBCGD08dr1p1TG+TIIfn+0w0EeW/W/5LrjOXUDxEniOPccXj9ru1wysbXuGDnR9gN9uxW+xMLJvI2X3PJhQP8dU3v8qypmXpurmOXCb3m0xruBWX1cWa1jVEE1H6ePswqWwSVw+7GgODa1+/luXNyw85bpvZxnHFxxFLxmiLtNEYbCQYC2KQ+rVuQM4A/nj2Hylxl/Cfzf9hQf0CCt2FhOIhWkItxJNx4sk4Fd4Krh95Pdn2bMKJMA6L46Cnmh6N9LNJDlVP6jMHmxscNSN4n2TOnDmMGjUqY5rk5MmTuemmm1i5ciXjxo1jzpw5nHXWWRmvmzx5MrfddhuQGiVctGgR3/ve99LlZrOZs846izlz5gCwaNEiYrFYxn2GDh1KVVVVOsE7mFj2JxKJEIlE0uc+nw9IdaxYLPYpP5nDY/f7d3cccvRQn5FDdVB9xmaDdev2ftERjkp6ssPxfcaEibMrz864Fo/H91v3vKrzOK/qvH1isGLlL2f+hWgiys7AThwWB6VZpQdcoCWZSALw8OkPU9tWS5Y1i7Xta/HavfTz9sNlcxGIBdLPDTYGG3l106usb1+fet9kjHn18z72/hs7NnL2C2fjsDiIJCIfWw/g8RWP47F56Ix14rK66J/dnxJ3CdFElDxnHl6bl2gyStJI4rV7yXXkMiR3CBNKJmCz7Gnj7jGDnrz/oX42yaHqSX3mYGPoNQlefX19RkIFpM/r6+sPWMfn8xEKhWhrayORSOy3zpo1a9L3sNvt5Obm7lPnk95n71j25+c//zn33XffPtfffPNN3D3kr9QzZszo7hDkKKM+I4dKfUYOVU/sM8s5tFG5JpqwYydChFpq9ykvoICpxlTas9vxmrw0JhqpS9ThMDloTbbiT/oZZR+F1+xlRXQFcyJz8Bv+dHI32jYaM2bcZjdZpixiRuoXxeWx5bQkW+iMdQIQiodY1bqKVa2rPjHmUnMp/a39sZqs7EzsZEt8Cw6TgyxTFq3JVuwmOwkjQZ45j2pbNXaTneZkMyc7TqbEUkLSSLIstoxN8U1UWaoos5RRaiklbIQxMDBjxmayYTUd/l9Xe2KfkZ6tJ/SZYDB4UPW6NcG7++67+cUvfnHAOqtXr2bo0KFdFFH3+t73vscdd9yRPvf5fFRWVnLOOef0iCmaM2bM4Oyzz+724Wk5OqjPyKFSn5FDpT5zYG3hNhpDjXjtXsqzyvdbJ2kkqQ/Ws92/nSF5Q5i+aTrv7XiPhJFgbNFYbGYb0WQUm9mGCRNNoSZWt65mVesq6pP11Ecz/3AdN+IEjED6GEjVi+yptzS2lIqsCprDzYTiIQAWsQggPZK4m8PiIMeeQ9yIE01EyXXk4rQ6cVlcVHmr0iucrm5bTWe0k0G5gxiUO4gqbxU5jhw6Ih2MKBiBy+oC1Gfk0PWkPrN7dt8n6dYE79vf/vY+K1h+1IABAw7qXqWlpcyfPz/jWkNDQ7ps9393X9u7TnZ2Ni6XC4vFgsVi2W+dve8RjUZpb2/PGMX7aJ1PimV/HA4HDse+D0TbbLZu71C79aRY5OigPiOH6oB9JhSCU09NHb/3HrhcXReY9Fj6PrN/xbZiir3Fn1ivr70vfXP7AjB11FSmjpr6ia+pD9Tz9ra3aQw2stW3lWJ3MZcOvhRf1Ec4EaY8q5wNHRtY3LAYi9lCfWc9rZFWFtUvIm7E2daZ2v8w257NqMJRBGIB1revz0juACKJCI2hxvT53uXLW/YdJV3YuHCfa0WuIs7tfy6GYZDvyGd+cD4NaxvIceYQSUSoyq6i0luJYRhk2bLwRX24rW4agg1s9W+lj6cPOY4cqvOrP/FzCcQCvLD2Bbb7t+OP+Tmp/CSmDJjSq59rPFb0hO8zB/v+3ZrgFRUVUVR0ePZ+qamp4YEHHqCxsTG92uWMGTPIzs5m+K4H8mtqapg+fXrG62bMmEFNTQ0Adrud448/npkzZ3LxxRcDqUVWZs6cyS233ALA8ccfj81mY+bMmVx66aUA1NbWsnXr1vR9DiYWERH5FJJJWLhwz7GIdIvSrFK+NPRLB6zTL6cfZ1admXEtloyxrGkZhmFQ5C6iLKsMuyW1+FwoHmJj+0aK3cU0hhppC7dRllWGP+rHbrHjtrrZ0bkDA4NNHZsIxoL4o35aw60MyB1AkauItW1r2dC+gW3+bbRH2vFFfTSFmvjnqn9mxDF36VwOVb/sflwz/Bo8Ng/Lm5ezvn091XnVRBIRoskoiWSC5c3L089NAkzbOI2HP3yYoflD8dq9TO43mVP7nJou3/u5RZHD5ah5Bm/r1q20traydetWEokES5YsAWDQoEF4PB7OOecchg8fzjXXXMNDDz1EfX09P/zhD7n55pvTo2I33ngjv//97/nud7/L//zP//DWW2/x3HPPMW3atPT73HHHHUydOpXx48dzwgkn8Nvf/pZAIMB1110HQE5ODtdffz133HEH+fn5ZGdn881vfpOamhomTZoEcFCxiIiIiBxrbGYbx5ccv98yl9XFiMIRAB+7+Xu/nH4AnFxx8kG9X3OomZfWvYQv4sPAoDHQSGtdK7mluUSSEaxmK1t8W9jUsYmEkch4rdPipCq7imAsyPbO7Wz2beb+ufdn1Nl7L8S923HJ4EuwmW08W/ssdYE66gJ1ALy64VW+WP3FdKLbEGigM9ZJriOX/jn90wv0GBiYMJFlyyLHkYNhGDSFmnBYHGz2bebK6is5rfI0kkaSF9e9SGe0EwMDf9TPOX3PYVjBsIP6fKR3OmoSvHvuuYe///3v6fPdK1G+/fbbnH766VgsFl577TVuuukmampqyMrKYurUqfzkJ3v2o+nfvz/Tpk3j9ttv53e/+x19+vThL3/5S3oPPIArrriCpqYm7rnnHurr6xk7dixvvPFGxqIpv/nNbzCbzVx66aUZG53vdjCxiIiIiMiRVegq5Oujv54+Ty95f/K+S96H4iGSRhK31U19oB6P3YPX7iVpJPnF/F+wqGERBgaJZIIyTxk1ZTUsb15OgauAHHsONosNh8XB5H6TKXanZnBdN/I6ljelRvve2/4eixsX82zts/vE2RZpo62x7aDbNXvHbAblDWJd27p9yl5c+yJ9s/uy2bcZt9XNBQMvIN+Zz6aOTcyrm4fFZMFj92C32KnyVlGWVYbH7mFEwQj6ePtgMVlY3ryc5lAzZpOZXEcuwwuGp9skPd9Rtw/esUT74MnRTH1GDtVB9ZlAADye1HFnJ2RldV2A0uPo+4wcqu7sM8FYkL8s/wvxZJyWcAvz6uZx7fBrOX/A+ezs3El9oJ5ALEBTqAlfxEdjqJFsezZJI4mBQZ4jj85YJ0+veXqfe9vMNsaXjGdO3ZwjFv/Zfc+mOq+a+mA9dYE6bGYbWbYsxhSNSe8HWeIuSU+53V/717atxWFxkDSSDMwdiNPqBODNzW/yxuY3aAm14Iv6OKPyDG4Zdwtmk5mOSAdvb3sbwzAYmDuQSm8lec68I9bOj+pJ32eOuX3wRERERER6KrfNza3H3brfskJXIaOLRh/Ufe6acBezdszCH/VjNpkxYeK8/udhMpnY2bmT/2z+D6VZpVR4Kpi9YzZb/VuJJ+O4rC6GFQyjwlNBS6iFWDJGS6iFnYGdNIWaWFi/kGgiioFBkauIAbkD8EV8rG5dDcCMLTOYsWXfrQKmbZzGz+b9DEglmtV51TisqSRufft6yrPKqQvU4YtmrgCZ78znjMozaI+0M3PrzIyy9e3rebb2WfKceWzxbckoy7Jl8b9n/C9eu5dALMDSpqWYTWZKs0rxRXysa0+Nau5OInePPLaGWlnbtpZwIoxhGHx+0OeZWDbxoD7zo40SPBERERGRo4TFbOH0ytP3W1buKee6kdelzw82adwtloiBKZWo7dYcaua52ufwR/0E40G8Ni8DcwcSToRZ1LCIWdtnEYwHsZltxJIxVrSsyLhnbXTPvo75znyiiSjBeJDWcCsvrnsxXZbnyOO7J3yXNS1r+Puqv+OL+jKSwuOKj2Nx42ICsQDXv3n9IbVrf6Zvms5vTv8N+a58Kr2VdEQ6iCaiNIWaGJo/lEJX4Wd+j+6iBE9ERI4uhUfvD10RkZ7MZtl3CmKhq5BvjP3Gfut/aeiXSCQT6W0gtvu3s7hxMUkjtcpx/5z+NIea8dg95DvzGZgzEIvZQkuohT8t+xPtkXY8Ng/5rnyuHnY1OY4cLhhwAadVnsb69vVE4hFawi1cNuQy+mb3pT5Qz+1v386q1lXkOnJxWBwMzB1IIpkgbsTxR/1Ueiup8FTQFm6jLlBHPJnaj9FlczE0byg5jhxeWPsCW/1bufXt/Y+oAlw25LJU4hfuwJvwftaPtkspwRMRkaNHVhY0NXV3FCIisovFbEkfV2ZXUpld+YmvKXAV8L2J3/vY8gmlE5hQOmGf66VZpTx9wdMYhvGZtpY4vuR4Hl36KEsbl5I0kukRyGx7Ni3hFgBeWPtCuv4X3V/81O/VHZTgiYiIiIjIUeOz7hs4umg0j531WPq8M9qJ1WzFaXWyonkFf1z6R0qySuiMdZJlySKvrusWdTkclOCJiIiIiMgxy2P3pI9HFo7k4TMfTp/vXkXzaGLu7gBEREQOWigEp5+e+gqFujsaERGRHkcjeCIicvRIJuHdd/cci4iISAaN4ImIiIiIiPQSSvBERERERER6CSV4IiIiIiIivYQSPBERERERkV5CCZ6IiIiIiEgvoVU0RUTk6OJ2d3cEIiIiPZYSPBEROXpkZUEg0N1RiIiI9FiaoikiIiIiItJLKMETERERERHpJZTgiYjI0SMchilTUl/hcHdHIyIi0uPoGTwRETl6JBIwffqeYxEREcmgETwREREREZFeQgmeiIiIiIhIL6EET0REREREpJdQgiciIiIiItJLKMETERERERHpJbSKZg9mGAYAPp+vmyOBWCxGMBjE5/Nhs9m6Oxw5CqjPyKE6qD4TCOw59vm0kuYxTt9n5FCpz8ih6kl9ZndOsDtH+DhK8Howv98PQGVlZTdHIiLSA5WXd3cEIiIiXc7v95OTk/Ox5Sbjk1JA6TbJZJKdO3fi9XoxmUzdGovP56OyspJt27aRnZ3drbHI0UF9Rg6V+owcKvUZOVTqM3KoelKfMQwDv99PeXk5ZvPHP2mnEbwezGw206dPn+4OI0N2dna3d245uqjPyKFSn5FDpT4jh0p9Rg5VT+kzBxq5202LrIiIiIiIiPQSSvBERERERER6CSV4clAcDgc//vGPcTgc3R2KHCXUZ+RQqc/IoVKfkUOlPiOH6mjsM1pkRUREREREpJfQCJ6IiIiIiEgvoQRPRERERESkl1CCJyIiIiIi0ksowRMREREREekllODJJ3rkkUfo168fTqeTiRMnMn/+/O4OSbrJz3/+cyZMmIDX66W4uJiLL76Y2trajDrhcJibb76ZgoICPB4Pl156KQ0NDRl1tm7dypQpU3C73RQXF3PnnXcSj8e7sinSDR588EFMJhO33XZb+pr6i+zPjh07uPrqqykoKMDlcjFq1CgWLlyYLjcMg3vuuYeysjJcLhdnnXUW69aty7hHa2srV111FdnZ2eTm5nL99dfT2dnZ1U2RLpBIJPjRj35E//79cblcDBw4kPvvv5+91xFUnzm2vffee1x44YWUl5djMpn497//nVF+uPrHsmXLOOWUU3A6nVRWVvLQQw8d6abtnyFyAM8884xht9uNv/3tb8bKlSuNr33ta0Zubq7R0NDQ3aFJN5g8ebLx+OOPGytWrDCWLFlinH/++UZVVZXR2dmZrnPjjTcalZWVxsyZM42FCxcakyZNMk488cR0eTweN0aOHGmcddZZxocffmhMnz7dKCwsNL73ve91R5Oki8yfP9/o16+fMXr0aONb3/pW+rr6i3xUa2ur0bdvX+MrX/mKMW/ePGPjxo3Gf/7zH2P9+vXpOg8++KCRk5Nj/Pvf/zaWLl1qXHTRRUb//v2NUCiUrnPuuecaY8aMMebOnWvMmjXLGDRokPGlL32pO5okR9gDDzxgFBQUGK+99pqxadMm4/nnnzc8Ho/xu9/9Ll1HfebYNn36dOMHP/iB8dJLLxmA8fLLL2eUH47+0dHRYZSUlBhXXXWVsWLFCuPpp582XC6X8cc//rGrmpmmBE8O6IQTTjBuvvnm9HkikTDKy8uNn//8590YlfQUjY2NBmC8++67hmEYRnt7u2Gz2Yznn38+XWf16tUGYMyZM8cwjNQ3WbPZbNTX16fr/OEPfzCys7ONSCTStQ2QLuH3+43BgwcbM2bMME477bR0gqf+Ivtz1113GSeffPLHlieTSaO0tNT45S9/mb7W3t5uOBwO4+mnnzYMwzBWrVplAMaCBQvSdV5//XXDZDIZO3bsOHLBS7eYMmWK8T//8z8Z1y655BLjqquuMgxDfUYyfTTBO1z949FHHzXy8vIyfjbdddddRnV19RFu0b40RVM+VjQaZdGiRZx11lnpa2azmbPOOos5c+Z0Y2TSU3R0dACQn58PwKJFi4jFYhl9ZujQoVRVVaX7zJw5cxg1ahQlJSXpOpMnT8bn87Fy5coujF66ys0338yUKVMy+gWov8j+vfLKK4wfP57LL7+c4uJixo0bx5///Od0+aZNm6ivr8/oNzk5OUycODGj3+Tm5jJ+/Ph0nbPOOguz2cy8efO6rjHSJU488URmzpzJ2rVrAVi6dCnvv/8+5513HqA+Iwd2uPrHnDlzOPXUU7Hb7ek6kydPpra2lra2ti5qTYq1S99NjirNzc0kEomMX6wASkpKWLNmTTdFJT1FMpnktttu46STTmLkyJEA1NfXY7fbyc3NzahbUlJCfX19us7++tTuMuldnnnmGRYvXsyCBQv2KVN/kf3ZuHEjf/jDH7jjjjv4/ve/z4IFC7j11lux2+1MnTo1/e++v36xd78pLi7OKLdareTn56vf9EJ33303Pp+PoUOHYrFYSCQSPPDAA1x11VUA6jNyQIerf9TX19O/f/997rG7LC8v74jEvz9K8ETkU7n55ptZsWIF77//fneHIj3Utm3b+Na3vsWMGTNwOp3dHY4cJZLJJOPHj+dnP/sZAOPGjWPFihU89thjTJ06tZujk57oueee48knn+Spp55ixIgRLFmyhNtuu43y8nL1GTkmaYqmfKzCwkIsFss+K9o1NDRQWlraTVFJT3DLLbfw2muv8fbbb9OnT5/09dLSUqLRKO3t7Rn19+4zpaWl++1Tu8uk91i0aBGNjY0cd9xxWK1WrFYr7777Lv/7v/+L1WqlpKRE/UX2UVZWxvDhwzOuDRs2jK1btwJ7/t0P9LOptLSUxsbGjPJ4PE5ra6v6TS905513cvfdd3PllVcyatQorrnmGm6//XZ+/vOfA+ozcmCHq3/0pJ9XSvDkY9ntdo4//nhmzpyZvpZMJpk5cyY1NTXdGJl0F8MwuOWWW3j55Zd566239pmKcPzxx2Oz2TL6TG1tLVu3bk33mZqaGpYvX57xjXLGjBlkZ2fv80udHN3OPPNMli9fzpIlS9Jf48eP56qrrkofq7/IR5100kn7bL+ydu1a+vbtC0D//v0pLS3N6Dc+n4958+Zl9Jv29nYWLVqUrvPWW2+RTCaZOHFiF7RCulIwGMRszvyV1mKxkEwmAfUZObDD1T9qamp47733iMVi6TozZsygurq6S6dnAtomQQ7smWeeMRwOh/HEE08Yq1atMr7+9a8bubm5GSvaybHjpptuMnJycox33nnHqKurS38Fg8F0nRtvvNGoqqoy3nrrLWPhwoVGTU2NUVNTky7fvez9OeecYyxZssR44403jKKiIi17f4zYexVNw1B/kX3Nnz/fsFqtxgMPPGCsW7fOePLJJw23223861//Std58MEHjdzcXOP//u//jGXLlhmf//zn97uk+bhx44x58+YZ77//vjF48GAted9LTZ061aioqEhvk/DSSy8ZhYWFxne/+910HfWZY5vf7zc+/PBD48MPPzQA49e//rXx4YcfGlu2bDEM4/D0j/b2dqOkpMS45pprjBUrVhjPPPOM4Xa7tU2C9EwPP/ywUVVVZdjtduOEE04w5s6d290hSTcB9vv1+OOPp+uEQiHjG9/4hpGXl2e43W7jC1/4glFXV5dxn82bNxvnnXee4XK5jMLCQuPb3/62EYvFurg10h0+muCpv8j+vPrqq8bIkSMNh8NhDB061PjTn/6UUZ5MJo0f/ehHRklJieFwOIwzzzzTqK2tzajT0tJifOlLXzI8Ho+RnZ1tXHfddYbf7+/KZkgX8fl8xre+9S2jqqrKcDqdxoABA4wf/OAHGcvVq88c295+++39/v4ydepUwzAOX/9YunSpcfLJJxsOh8OoqKgwHnzwwa5qYgaTYRhG144ZioiIiIiIyJGgZ/BERERERER6CSV4IiIiIiIivYQSPBERERERkV5CCZ6IiIiIiEgvoQRPRERERESkl1CCJyIiIiIi0ksowRMREREREekllOCJiIiIiIj0EkrwREREeiGTycS///3v7g5DRES6mBI8ERGRw+wrX/kKJpNpn69zzz23u0MTEZFeztrdAYiIiPRG5557Lo8//njGNYfD0U3RiIjIsUIjeCIiIkeAw+GgtLQ04ysvLw9ITZ/8wx/+wHnnnYfL5WLAgAG88MILGa9fvnw5n/vc53C5XBQUFPD1r3+dzs7OjDp/+9vfGDFiBA6Hg7KyMm655ZaM8ubmZr7whS/gdrsZPHgwr7zyypFttIiIdDsleCIiIt3gRz/6EZdeeilLly7lqquu4sorr2T16tUABAIBJk+eTF5eHgsWLOD555/nv//9b0YC94c//IGbb76Zr3/96yxfvpxXXnmFQYMGZbzHfffdxxe/+EWWLVvG+eefz1VXXUVra2uXtlNERLqWyTAMo7uDEBER6U2+8pWv8K9//Qun05lx/fvf/z7f//73MZlM3HjjjfzhD39Il02aNInjjjuORx99lD//+c/cddddbNu2jaysLACmT5/OhRdeyM6dOykpKaGiooLrrruOn/70p/uNwWQy8cMf/pD7778fSCWNHo+H119/Xc8Cioj0YnoGT0RE5Ag444wzMhI4gPz8/PRxTU1NRllNTQ1LliwBYPXq1YwZMyad3AGcdNJJJJNJamtrMZlM7Ny5kzPPPPOAMYwePTp9nJWVRXZ2No2NjZ+2SSIichRQgiciInIEZGVl7TNl8nBxuVwHVc9ms2Wcm0wmksnkkQhJRER6CD2DJyIi0g3mzp27z/mwYcMAGDZsGEuXLiUQCKTLZ8+ejdlsprq6Gq/XS79+/Zg5c2aXxiwiIj2fRvBERESOgEgkQn19fcY1q9VKYWEhAM8//zzjx4/n5JNP5sknn2T+/Pn89a9/BeCqq67ixz/+MVOnTuXee++lqamJb37zm1xzzTWUlJQAcO+993LjjTdSXFzMeeedh9/vZ/bs2Xzzm9/s2oaKiEiPogRPRETkCHjjjTcoKyvLuFZdXc2aNWuA1AqXzzzzDN/4xjcoKyvj6aefZvjw4QC43W7+85//8K1vfYsJEybgdru59NJL+fWvf52+19SpUwmHw/zmN7/hO9/5DoWFhVx22WVd10AREemRtIqmiIhIFzOZTLz88stcfPHF3R2KiIj0MnoGT0REREREpJdQgiciIiIiItJL6Bk8ERGRLqanI0RE5EjRCJ6IiIiIiEgvoQRPRERERESkl1CCJyIiIiIi0ksowRMREREREekllOCJiIiIiIj0EkrwREREREREegkleCIiIiIiIr2EEjwREREREZFe4v8DuC/z+NlaaZ0AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Convert the tensor to a list\n",
        "train_loss = [loss.item() for loss in train_losses]\n",
        "val_loss = [loss for loss in val_losses]\n",
        "val_loss_stretched = []\n",
        "for loss in val_loss:\n",
        "    val_loss_stretched.extend([loss]*5)  # Change the number accordingly\n",
        "\n",
        "diff = np.array(train_loss) - np.array(val_loss_stretched)\n",
        "\n",
        "# Find the epoch with minimum validation loss\n",
        "min_loss_index = np.argmin(val_loss)\n",
        "\n",
        "# Now plot the losses\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss_stretched)\n",
        "plt.plot(diff)\n",
        "plt.axvline(x=min_loss_index * 5, color='r', linestyle='--')  # Add vertical line at minimum validation loss\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.grid(True)\n",
        "plt.legend([\"Train Loss\", \"Validation Loss\", \"Difference\", \"Min Validation Loss\"])\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVySEHsPtNCz",
        "outputId": "0485c117-8ae5-49ca-ea1e-5e54f61374f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = GCN(128)\n",
        "\n",
        "model_save_path = save_path + \"/model_401.pt\"\n",
        "\n",
        "model.load_state_dict(torch.load(model_save_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVPYnkXtM88p"
      },
      "outputs": [],
      "source": [
        "fine_tune(model, V, data, train_edges=E_train, val_edges=valid_edges_in_V, optimizer=optimizer, drop_percent=0.2, patience=10, epochs = 10, test_active = True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
